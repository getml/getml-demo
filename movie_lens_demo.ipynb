{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens - Predicting a user's gender based on the movies they have watched\n",
    "\n",
    "...\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Prediction type: __Classification model__\n",
    "- Domain: __Entertainment__\n",
    "- Prediction target: __The gender of a user__ \n",
    "- Population size: __6039__\n",
    "\n",
    "_Author: Dr. Patrick Urbanke_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "...\n",
    "\n",
    "It has been downloaded from the [CTU Prague relational learning repository](https://relational.fit.cvut.cz/dataset/MovieLens) (Motl and Schulte, 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A web frontend for getML\n",
    "\n",
    "The getML monitor is a frontend built to support your work with getML. The getML monitor displays information such as the imported data frames, trained pipelines and allows easy data and feature exploration. You can launch the getML monitor [here](http://localhost:1709)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is this running?\n",
    "\n",
    "Your getML live session is running inside a docker container on [mybinder.org](https://mybinder.org/), a service built by the Jupyter community and funded by Google Cloud, OVH, GESIS Notebooks and the Turing Institute. As it is a free service, this session will shut down after 10 minutes of inactivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started with the analysis and set up your session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading pipelines...\n",
      "[========================================] 100%\n",
      "\n",
      "Connected to project 'MovieLens'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "from urllib import request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline  \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import getml\n",
    "\n",
    "getml.engine.set_project('MovieLens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning is effective at improving our results, but it takes quite long, so we want to make it optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FINE_TUNED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = getml.database.connect_mariadb(\n",
    "    host=\"relational.fit.cvut.cz\",\n",
    "    dbname=\"imdb_MovieLens\",\n",
    "    port=3306,\n",
    "    user=\"guest\",\n",
    "    password=\"relational\"\n",
    ")\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if_needed(name):\n",
    "    \"\"\"\n",
    "    Loads the data from the relational learning\n",
    "    repository, if the data frame has not already\n",
    "    been loaded.\n",
    "    \"\"\"\n",
    "    if not getml.data.exists(name):\n",
    "        data_frame = getml.data.DataFrame.from_db(\n",
    "            name=name,\n",
    "            table_name=name,\n",
    "            conn=conn\n",
    "        )\n",
    "        data_frame.save()\n",
    "    else:\n",
    "        data_frame = getml.data.load_data_frame(name)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = load_if_needed(\"users\")\n",
    "u2base = load_if_needed(\"u2base\")\n",
    "movies = load_if_needed(\"movies\")\n",
    "movies2directors = load_if_needed(\"movies2directors\")\n",
    "directors = load_if_needed(\"directors\")\n",
    "movies2actors = load_if_needed(\"movies2actors\")\n",
    "actors = load_if_needed(\"actors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare data for getML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getML requires that we define *roles* for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[\"target\"] = (users.u_gender == 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.set_role(\"userid\", getml.data.roles.join_key)\n",
    "users.set_role(\"age\", getml.data.roles.numerical)\n",
    "users.set_role(\"occupation\", getml.data.roles.categorical)\n",
    "users.set_role(\"target\", getml.data.roles.target)\n",
    "\n",
    "users.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u2base.set_role([\"userid\", \"movieid\"], getml.data.roles.join_key)\n",
    "u2base.set_role(\"rating\", getml.data.roles.numerical)\n",
    "\n",
    "u2base.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.set_role(\"movieid\", getml.data.roles.join_key)\n",
    "movies.set_role([\"year\", \"runningtime\"], getml.data.roles.numerical)\n",
    "movies.set_role([\"isEnglish\", \"country\"], getml.data.roles.categorical)\n",
    "\n",
    "movies.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies2directors.set_role([\"movieid\", \"directorid\"], getml.data.roles.join_key)\n",
    "movies2directors.set_role( \"genre\", getml.data.roles.categorical)\n",
    "\n",
    "movies2directors.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors.set_role(\"directorid\", getml.data.roles.join_key)\n",
    "directors.set_role([\"d_quality\", \"avg_revenue\"], getml.data.roles.numerical)\n",
    "\n",
    "directors.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies2actors.set_role([\"movieid\", \"actorid\"], getml.data.roles.join_key)\n",
    "movies2actors.set_role( \"cast_num\", getml.data.roles.numerical)\n",
    "\n",
    "movies2actors.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate our data set into a training, testing and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors.set_role(\"actorid\", getml.data.roles.join_key)\n",
    "actors.set_role(\"a_quality\", getml.data.roles.numerical)\n",
    "actors.set_role(\"a_gender\", getml.data.roles.categorical)\n",
    "\n",
    "actors.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = users.random()\n",
    "\n",
    "is_training = (random < 0.75)\n",
    "is_test = ~is_training\n",
    "\n",
    "data_train = users.where(\"data_train\", is_training)\n",
    "data_test = users.where(\"data_test\", is_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive modelling\n",
    "\n",
    "We loaded the data and defined the roles and units. Next, we create a getML pipeline for relational learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define relational model\n",
    "\n",
    "To get started with relational learning, we need to specify the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ph = getml.data.Placeholder('users')\n",
    "u2base_ph = getml.data.Placeholder('u2base')\n",
    "movies_ph = getml.data.Placeholder('movies')\n",
    "movies2directors_ph = getml.data.Placeholder('movies2directors')\n",
    "directors_ph = getml.data.Placeholder('directors')\n",
    "movies2actors_ph = getml.data.Placeholder('movies2actors')\n",
    "actors_ph = getml.data.Placeholder('actors')\n",
    "\n",
    "users_ph.join(\n",
    "    u2base_ph,\n",
    "    join_key='userid'\n",
    ")\n",
    "\n",
    "u2base_ph.join(\n",
    "    movies_ph,\n",
    "    join_key='movieid',\n",
    "    relationship=getml.data.relationship.many_to_one\n",
    ")\n",
    "\n",
    "movies_ph.join(\n",
    "    movies2directors_ph,\n",
    "    join_key='movieid'\n",
    ")\n",
    "\n",
    "movies2directors_ph.join(\n",
    "    directors_ph,\n",
    "    join_key='directorid',\n",
    "    relationship=getml.data.relationship.many_to_one\n",
    ")\n",
    "\n",
    "movies_ph.join(\n",
    "    movies2actors_ph,\n",
    "    join_key='movieid',\n",
    "    relationship=getml.data.relationship.propositionalization\n",
    ")\n",
    "\n",
    "movies2actors_ph.join(\n",
    "    actors_ph,\n",
    "    join_key='actorid',\n",
    "    relationship=getml.data.relationship.many_to_one\n",
    ")\n",
    "\n",
    "users_ph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 getML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### 2.1.1  -->\n",
    "__Set-up the feature learner & predictor__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either use the relboost default parameters or some more fine-tuned parameters. Fine-tuning these parameters in this way can increase our predictive accuracy to 85%, but the training time increases to over 4 hours. We therefore assume that we want to use the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast_prop = getml.feature_learning.FastPropModel(\n",
    "#    loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "#    n_most_frequent=3\n",
    "#)\n",
    "\n",
    "multirel = getml.feature_learning.MultirelModel(\n",
    "    loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "    num_features=50,\n",
    "    num_subfeatures=50\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Build the pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peripheral_ph = [\n",
    "    u2base_ph, \n",
    "    movies_ph, \n",
    "    movies2directors_ph, \n",
    "    directors_ph, \n",
    "    movies2actors_ph,\n",
    "    actors_ph\n",
    "]\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['multirel'],\n",
    "    population=users_ph,\n",
    "    peripheral=peripheral_ph,\n",
    "    feature_learners=[multirel],\n",
    "    predictors=[predictor]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peripheral = {\n",
    "    \"u2base\": u2base, \n",
    "    \"movies\": movies, \n",
    "    \"movies2directors\": movies2directors,\n",
    "    \"directors\": directors,\n",
    "    \"movies2actors\": movies2actors,\n",
    "    \"actors\": actors\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.check(data_train, peripheral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(data_train, peripheral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "pipe.score(data_test, peripheral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Studying features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature correlations__\n",
    "\n",
    "We want to analyze how the features are correlated with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, correlations = pipe.features.correlations()\n",
    "\n",
    "plt.subplots(figsize=(20, 10))\n",
    "\n",
    "plt.bar(names, correlations, color='#6829c2')\n",
    "\n",
    "plt.title('Feature Correlations')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Correlations')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.features.to_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature importances__\n",
    " \n",
    "Feature importances are calculated by analyzing the improvement in predictive accuracy on each node of the trees in the XGBoost predictor. They are then normalized, so that all importances add up to 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "names, importances = pipe.features.importances()\n",
    "\n",
    "plt.subplots(figsize=(20, 10))\n",
    "\n",
    "plt.bar(names, importances, color='#6829c2')\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importances')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "most_important = names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Column importances__\n",
    "\n",
    "Because getML uses relational learning, we can apply the principles we used to calculate the feature importances to individual columns as well.\n",
    "\n",
    "As we can see, most of the predictive accuracy is drawn from the roles played by the actors. This suggests that the text fields contained in this relational database have a higher impact on predictive accuracy than for most other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, importances = pipe.columns.importances()\n",
    "\n",
    "plt.subplots(figsize=(20, 10))\n",
    "\n",
    "plt.bar(names, importances, color='#6829c2')\n",
    "\n",
    "plt.title('Columns importances')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Importances')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "most_important = names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Transpiling the learned features__\n",
    "\n",
    "We can also transpile the learned features to SQLite3 code. We want to show the two most important features. That is why we call the `.features.importances().` method again. The names that are returned are already sorted by importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, _ = pipe.features.importances()\n",
    "\n",
    "pipe.features.to_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, _ = pipe.features.importances()\n",
    "\n",
    "pipe.features.to_sql()[names[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "In this notebook we have demonstrated how getML can be applied to text fields. We have demonstrated the our  approach outperforms state-of-the-art relational learning algorithms on the IMdb dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "Motl, Jan, and Oliver Schulte. \"The CTU prague relational learning repository.\" arXiv preprint arXiv:1511.03086 (2015).\n",
    "    \n",
    "Neville, Jennifer, and David Jensen. \"Relational dependency networks.\" Journal of Machine Learning Research 8.Mar (2007): 653-692.\n",
    "    \n",
    "Neville, Jennifer, and David Jensen. \"Collective classification with relational dependency networks.\" Workshop on Multi-Relational Data Mining (MRDM-2003). 2003.\n",
    "    \n",
    "Neville, Jennifer, et al. \"Learning relational probability trees.\" Proceedings of the Ninth ACM SIGKDD international conference on Knowledge discovery and data mining. 2003.\n",
    "    \n",
    "Perov≈°ek, Matic, et al. \"Wordification: Propositionalization by unfolding relational data into bags of words.\" Expert Systems with Applications 42.17-18 (2015): 6442-6456."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "This tutorial went through the basics of applying getML to relational data. If you want to learn more about getML, here are some additional tutorials and articles that will help you:\n",
    "\n",
    "__Tutorials:__\n",
    "* [Loan default prediction: Introduction to relational learning](loans_demo.ipynb)\n",
    "* [Occupancy detection: A multivariate time series example](occupancy_demo.ipynb)  \n",
    "* [Expenditure categorization: Why relational learning matters](consumer_expenditures_demo.ipynb)\n",
    "* [Disease lethality prediction: Feature engineering and the curse of dimensionality](atherosclerosis_demo.ipynb)\n",
    "* [Traffic volume prediction: Feature engineering on multivariate time series](interstate94_demo.ipynb)\n",
    "* [Air pollution prediction: Why feature learning outperforms brute-force approaches](air_pollution_demo.ipynb) \n",
    "\n",
    "\n",
    "__User Guides__ (from our [documentation](https://docs.getml.com/latest/)):\n",
    "* [Feature learning with Multirel](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#multirel)\n",
    "* [Feature learning with Relboost](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#relboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get in contact\n",
    "\n",
    "If you have any question schedule a [call with Alex](https://go.getml.com/meetings/alexander-uhlig/getml-demo), the co-founder of getML, or write us an [email](team@getml.com). Prefer a private demo of getML? Just contact us to make an appointment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
