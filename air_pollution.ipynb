{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "source": [
    "# Why feature learning is better than simple propositionalization\n",
    "\n",
    "**NOTE: Due to featuretools's and tsfresh's memory requirements, this notebook will not run on MyBinder when RUN_FEATURETOOLS=True RUN_TSFRESH=True.**\n",
    "\n",
    "In this notebook we will compare getML to featuretools and tsfresh, both of which open-source libraries for feature engineering. We find that advanced algorithms featured in getML yield significantly better predictions on this dataset. We then discuss why that is.\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Prediction type: __Regression model__\n",
    "- Domain: __Air pollution__\n",
    "- Prediction target: __pm 2.5 concentration__ \n",
    "- Source data: __Multivariate time series__\n",
    "- Population size: __41757__\n",
    "\n",
    "*Author: Dr. Patrick Urbanke*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Many data scientists and AutoML tools use propositionalization methods for feature engineering. These propositionalization methods usually work as follows:\n",
    "\n",
    "- Generate a large number of hard-coded features\n",
    "- Use feature selection to pick a percentage of these features\n",
    "\n",
    "By contrast, getML (https://getml.com/product) contains approaches for feature learning: Feature learning adapts machine learning approaches such as decision trees or gradient boosting to the problem of extracting features from relational data and time series.\n",
    "\n",
    "In this notebook, we will benchmark getML (https://getml.com/product) against featuretools (https://www.featuretools.com/) and tsfresh (https://tsfresh.readthedocs.io/en/latest/). Both of these libaries use propositionalization approaches for feature engineering.\n",
    "\n",
    "As our example dataset, we use a publicly available dataset on air pollution in Beijing, China (https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data). The data set has been originally used in the following study:\n",
    "\n",
    "Liang, X., Zou, T., Guo, B., Li, S., Zhang, H., Zhang, S., Huang, H. and Chen, S. X. (2015). Assessing Beijing's PM2.5 pollution: severity, weather impact, APEC and winter heating. Proceedings of the Royal Society A, 471, 20150257.\n",
    "\n",
    "We find that getML significantly outperforms featuretools and tsfresh in terms of predictive accuracy (**R-squared of 62.3%** vs **R-squared of 50.4%**).\n",
    "\n",
    "Our findings indicate that getML's feature learning algorithms are better at adapting to data sets and are also more scalable due to their lower memory requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A web frontend for getML\n",
    "\n",
    "The getML monitor is a frontend built to support your work with getML. The getML monitor displays information such as the imported data frames, trained pipelines and allows easy data and feature exploration. You can launch the getML monitor [here](http://localhost:1709)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "\n",
    "import getml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FEATURETOOLS = True\n",
    "RUN_TSFRESH = True\n",
    "\n",
    "if RUN_FEATURETOOLS:\n",
    "    from utils import FTTimeSeriesBuilder\n",
    "\n",
    "if RUN_TSFRESH:\n",
    "    from utils import TSFreshBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data from the UCI Machine Learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURETOOLS_FILES = [\n",
    "    \"featuretools_training.csv\",\n",
    "    \"featuretools_test.csv\"\n",
    "]\n",
    "\n",
    "if not RUN_FEATURETOOLS:\n",
    "    for fname in FEATURETOOLS_FILES:\n",
    "        if not os.path.exists(fname):\n",
    "            fname, res = request.urlretrieve(\n",
    "                \"https://static.getml.com/datasets/air_pollution/featuretools/\" + fname, \n",
    "                fname\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSFRESH_FILES = [\n",
    "    \"tsfresh_training.csv\",\n",
    "    \"tsfresh_test.csv\"\n",
    "]\n",
    "\n",
    "if not RUN_TSFRESH:\n",
    "    for fname in TSFRESH_FILES:\n",
    "        if not os.path.exists(fname):\n",
    "            fname, res = request.urlretrieve(\n",
    "                \"https://static.getml.com/datasets/air_pollution/tsfresh/\" + fname, \n",
    "                fname\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "    fname, res = request.urlretrieve(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/\" + fname, \n",
    "        fname\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare data for tsfresh and getML\n",
    "\n",
    "Our our goal is to predict the pm2.5 concentration from factors such as weather or time of day. However, there are some **missing entries** for pm2.5, so we get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_pandas = pd.read_csv(fname)\n",
    "\n",
    "data_full_pandas = data_full_pandas[\n",
    "    data_full_pandas[\"pm2.5\"] == data_full_pandas[\"pm2.5\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsfresh requires a date column, so we build one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_leading_zero(val):\n",
    "    if len(str(val)) == 1:\n",
    "        return \"0\" + str(val)\n",
    "    return str(val)\n",
    "\n",
    "data_full_pandas[\"month\"] = [\n",
    "    add_leading_zero(val) for val in data_full_pandas[\"month\"]\n",
    "]\n",
    "\n",
    "data_full_pandas[\"day\"] = [\n",
    "    add_leading_zero(val) for val in data_full_pandas[\"day\"]\n",
    "]\n",
    "\n",
    "data_full_pandas[\"hour\"] = [\n",
    "    add_leading_zero(val) for val in data_full_pandas[\"hour\"]\n",
    "]\n",
    "\n",
    "def make_date(year, month, day, hour):\n",
    "    return year + \"-\" + month + \"-\" + day + \" \" + hour + \":00:00\"\n",
    "\n",
    "data_full_pandas[\"date\"] = [\n",
    "    make_date(str(year), month, day, hour) \\\n",
    "    for year, month, day, hour in zip(\n",
    "        data_full_pandas[\"year\"],\n",
    "        data_full_pandas[\"month\"],\n",
    "        data_full_pandas[\"day\"],\n",
    "        data_full_pandas[\"hour\"],\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsfresh also requires the time series to have ids. Since there is only a single time series, that series has the same id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_pandas[\"id\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset now contains many columns that we do not need or that tsfresh cannot process. For instance, *cbwd* might actually contain useful information, but it is a categorical variable, which is difficult to handle for tsfresh, so we remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to split our data into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_pandas = data_full_pandas[data_full_pandas[\"year\"] < 2014]\n",
    "data_test_pandas = data_full_pandas[data_full_pandas[\"year\"] == 2014]\n",
    "data_full_pandas = data_full_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_columns(df):\n",
    "    del df[\"cbwd\"]\n",
    "    del df[\"year\"]\n",
    "    del df[\"month\"]\n",
    "    del df[\"day\"]\n",
    "    del df[\"hour\"]\n",
    "    del df[\"No\"]\n",
    "    return df\n",
    "\n",
    "data_full_pandas = remove_unwanted_columns(data_full_pandas)\n",
    "data_train_pandas = remove_unwanted_columns(data_train_pandas)\n",
    "data_test_pandas = remove_unwanted_columns(data_test_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 19:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 21:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43822</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 22:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41757 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm2.5  DEWP  TEMP    PRES     Iws  Is  Ir                 date  id\n",
       "24     129.0   -16  -4.0  1020.0    1.79   0   0  2010-01-02 00:00:00   1\n",
       "25     148.0   -15  -4.0  1020.0    2.68   0   0  2010-01-02 01:00:00   1\n",
       "26     159.0   -11  -5.0  1021.0    3.57   0   0  2010-01-02 02:00:00   1\n",
       "27     181.0    -7  -5.0  1022.0    5.36   1   0  2010-01-02 03:00:00   1\n",
       "28     138.0    -7  -5.0  1022.0    6.25   2   0  2010-01-02 04:00:00   1\n",
       "...      ...   ...   ...     ...     ...  ..  ..                  ...  ..\n",
       "43819    8.0   -23  -2.0  1034.0  231.97   0   0  2014-12-31 19:00:00   1\n",
       "43820   10.0   -22  -3.0  1034.0  237.78   0   0  2014-12-31 20:00:00   1\n",
       "43821   10.0   -22  -3.0  1034.0  242.70   0   0  2014-12-31 21:00:00   1\n",
       "43822    8.0   -22  -4.0  1034.0  246.72   0   0  2014-12-31 22:00:00   1\n",
       "43823   12.0   -21  -3.0  1034.0  249.85   0   0  2014-12-31 23:00:00   1\n",
       "\n",
       "[41757 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then **load the data into the getML engine**. We begin by setting a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connected to project 'air_pollution'\n"
     ]
    }
   ],
   "source": [
    "getml.engine.set_project('air_pollution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = getml.data.DataFrame.from_pandas(data_full_pandas, name='full')\n",
    "df_train = getml.data.DataFrame.from_pandas(data_train_pandas, name='train')\n",
    "df_test = getml.data.DataFrame.from_pandas(data_test_pandas, name='test')\n",
    "\n",
    "df_full[\"date\"] = df_full[\"date\"].as_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to **assign roles** to the columns, such as defining the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_roles(df):\n",
    "    df.set_role([\"date\"], getml.data.roles.time_stamp)\n",
    "    df.set_role([\"pm2.5\"], getml.data.roles.target)\n",
    "    df.set_role([\n",
    "        \"DEWP\", \n",
    "        \"TEMP\",\n",
    "        \"PRES\",\n",
    "        \"Iws\",\n",
    "        \"Is\",\n",
    "        \"Ir\"], getml.data.roles.numerical)\n",
    "\n",
    "set_roles(df_full)\n",
    "set_roles(df_train)\n",
    "set_roles(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictive modelling\n",
    "\n",
    "\n",
    "### 3.1 Pipeline 1: Complex features, 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first experiment, we will learn complex features and allow a memory of up to seven days. That means at every given point in time, the algorithm is allowed to back seven days into the past.\n",
    "\n",
    "getML uses relational learning to build construct the pipelines. Even though there is a simpler time series API, the relational API is more flexible which is why decide to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"height:100px;width:660px;position:relative;\"><svg height=\"90\" width=\"650\"><rect y=\"0\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">peripheral</text><rect x=\"51\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"10\" x2=\"67.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"10\" x2=\"83.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"26.0\" x2=\"99\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"42.0\" x2=\"99\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"0\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">population</text><rect x=\"551\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"10\" x2=\"567.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"10\" x2=\"583.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"26.0\" x2=\"599\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"42.0\" x2=\"599\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"150\" y1=\"43.0\" x2=\"490\" y2=\"43.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 43.0 490, 37.0 490, 49.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"10.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"40.0\"\" x=\"324.0\" font-size=\"7pt\" >date <= date</tspan><tspan y=\"50.0\"\" x=\"324.0\" font-size=\"7pt\" >Memory: 7.0 days</tspan></text></svg></div>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   join keys used     memory   \n",
       "population    peripheral          False                  0.0                        604800.0   \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   other time stamps used   relationship   time stamps used   \n",
       "                       date                     many-to-many   date               \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   upper time stamps used   \n",
       "                                                "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(7)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['RelMTModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['RelMTModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relmt = getml.feature_learning.RelMTModel(\n",
    "    num_features=10,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor(n_jobs=1)\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 7d', 'complex features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[relmt],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to always check your data model first, even though `check(...)` is also called by `fit(...)`. That enables us to make last-minute changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit our data on the training set and evaluate our findings, both in-sample and out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "RelMT: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelMT: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:4m:48.03673\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['RelMTModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)</pre><br><pre>url: <a href=\"http://localhost:1709/#/getpipeline/air_pollution/EixHEE/0/\" target=\"_blank\">http://localhost:1709/#/getpipeline/air_pollution/EixHEE/0/</a></pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['RelMTModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)\n",
       "\n",
       "url: http://localhost:1709/#/getpipeline/air_pollution/EixHEE/0/"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RelMT: Building features...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: left;border-right:1pt solid LightGray;\"> </th><th style=\"text-align: right;\">date time          </th><th style=\"text-align: right;\">set used</th><th style=\"text-align: right;\">target</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">rsquared</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td style=\"border-right:1pt solid LightGray;\"><b>0</b></td><td>2021-02-24 10:50:01</td><td>train   </td><td>pm2.5 </td><td> 35.27219</td><td> 51.11251</td><td> 0.69007</td></tr><tr><td style=\"border-right:1pt solid LightGray;\"><b>1</b></td><td>2021-02-24 10:50:12</td><td>test    </td><td>pm2.5 </td><td> 40.05860</td><td> 57.79037</td><td> 0.62263</td></tr></tbody></table>"
      ],
      "text/plain": [
       "    date time             set used   target         mae        rmse   rsquared\n",
       "0   2021-02-24 10:50:01   train      pm2.5     35.27219    51.11251    0.69007\n",
       "1   2021-02-24 10:50:12   test       pm2.5     40.05860    57.79037    0.62263"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(df_test, [df_full])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pipeline 2: Complex features, 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"height:100px;width:660px;position:relative;\"><svg height=\"90\" width=\"650\"><rect y=\"0\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">peripheral</text><rect x=\"51\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"10\" x2=\"67.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"10\" x2=\"83.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"26.0\" x2=\"99\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"42.0\" x2=\"99\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"0\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">population</text><rect x=\"551\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"10\" x2=\"567.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"10\" x2=\"583.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"26.0\" x2=\"599\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"42.0\" x2=\"599\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"150\" y1=\"43.0\" x2=\"490\" y2=\"43.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 43.0 490, 37.0 490, 49.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"10.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"40.0\"\" x=\"324.0\" font-size=\"7pt\" >date <= date</tspan><tspan y=\"50.0\"\" x=\"324.0\" font-size=\"7pt\" >Memory: 1.0 days</tspan></text></svg></div>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   join keys used    memory   \n",
       "population    peripheral          False                  0.0                        86400.0   \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   other time stamps used   relationship   time stamps used   \n",
       "                       date                     many-to-many   date               \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   upper time stamps used   \n",
       "                                                "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(1)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['RelMTModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['RelMTModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relmt = getml.feature_learning.RelMTModel(\n",
    "    num_features=10,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor(n_jobs=1)\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 1d', 'complex features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[relmt],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "RelMT: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelMT: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:2m:7.974977\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['RelMTModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)</pre><br><pre>url: <a href=\"http://localhost:1709/#/getpipeline/air_pollution/Mtbw8M/0/\" target=\"_blank\">http://localhost:1709/#/getpipeline/air_pollution/Mtbw8M/0/</a></pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['RelMTModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)\n",
       "\n",
       "url: http://localhost:1709/#/getpipeline/air_pollution/Mtbw8M/0/"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RelMT: Building features...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: left;border-right:1pt solid LightGray;\"> </th><th style=\"text-align: right;\">date time          </th><th style=\"text-align: right;\">set used</th><th style=\"text-align: right;\">target</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">rsquared</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td style=\"border-right:1pt solid LightGray;\"><b>0</b></td><td>2021-02-24 10:52:29</td><td>train   </td><td>pm2.5 </td><td> 38.75185</td><td> 56.17597</td><td> 0.62551</td></tr><tr><td style=\"border-right:1pt solid LightGray;\"><b>1</b></td><td>2021-02-24 10:52:37</td><td>test    </td><td>pm2.5 </td><td> 44.40302</td><td> 66.13360</td><td> 0.51528</td></tr></tbody></table>"
      ],
      "text/plain": [
       "    date time             set used   target         mae        rmse   rsquared\n",
       "0   2021-02-24 10:52:29   train      pm2.5     38.75185    56.17597    0.62551\n",
       "1   2021-02-24 10:52:37   test       pm2.5     44.40302    66.13360    0.51528"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(df_test, [df_full])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pipeline 3: Simple features, 7 days\n",
    "\n",
    "For our third experiment, we will learn simple features and allow a memory of up to seven days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"height:100px;width:660px;position:relative;\"><svg height=\"90\" width=\"650\"><rect y=\"0\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">peripheral</text><rect x=\"51\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"10\" x2=\"67.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"10\" x2=\"83.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"26.0\" x2=\"99\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"42.0\" x2=\"99\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"0\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">population</text><rect x=\"551\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"10\" x2=\"567.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"10\" x2=\"583.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"26.0\" x2=\"599\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"42.0\" x2=\"599\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"150\" y1=\"43.0\" x2=\"490\" y2=\"43.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 43.0 490, 37.0 490, 49.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"10.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"40.0\"\" x=\"324.0\" font-size=\"7pt\" >date <= date</tspan><tspan y=\"50.0\"\" x=\"324.0\" font-size=\"7pt\" >Memory: 7.0 days</tspan></text></svg></div>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   join keys used     memory   \n",
       "population    peripheral          False                  0.0                        604800.0   \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   other time stamps used   relationship   time stamps used   \n",
       "                       date                     many-to-many   date               \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   upper time stamps used   \n",
       "                                                "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(7)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['FastPropModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['FastPropModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_prop = getml.feature_learning.FastPropModel(\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    num_features=40,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor(n_jobs=1)\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 7d', 'simple features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[fast_prop],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "FastProp: Trying 72 features...\n",
      "[========================================] 100%\n",
      "\n",
      "FastProp: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:0m:27.943497\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['FastPropModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)</pre><br><pre>url: <a href=\"http://localhost:1709/#/getpipeline/air_pollution/nrPJoh/0/\" target=\"_blank\">http://localhost:1709/#/getpipeline/air_pollution/nrPJoh/0/</a></pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['FastPropModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)\n",
       "\n",
       "url: http://localhost:1709/#/getpipeline/air_pollution/nrPJoh/0/"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FastProp: Building features...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: left;border-right:1pt solid LightGray;\"> </th><th style=\"text-align: right;\">date time          </th><th style=\"text-align: right;\">set used</th><th style=\"text-align: right;\">target</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">rsquared</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td style=\"border-right:1pt solid LightGray;\"><b>0</b></td><td>2021-02-24 10:53:13</td><td>train   </td><td>pm2.5 </td><td> 39.14191</td><td> 55.00419</td><td> 0.66066</td></tr><tr><td style=\"border-right:1pt solid LightGray;\"><b>1</b></td><td>2021-02-24 10:53:16</td><td>test    </td><td>pm2.5 </td><td> 48.50128</td><td> 68.62869</td><td> 0.48425</td></tr></tbody></table>"
      ],
      "text/plain": [
       "    date time             set used   target         mae        rmse   rsquared\n",
       "0   2021-02-24 10:53:13   train      pm2.5     39.14191    55.00419    0.66066\n",
       "1   2021-02-24 10:53:16   test       pm2.5     48.50128    68.62869    0.48425"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(df_test, [df_full])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Pipeline 4: Simple features, 1 day\n",
    "\n",
    "For our fourth experiment, we will learn simple features and allow a memory of up to one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"height:100px;width:660px;position:relative;\"><svg height=\"90\" width=\"650\"><rect y=\"0\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">peripheral</text><rect x=\"51\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"10\" x2=\"67.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"10\" x2=\"83.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"26.0\" x2=\"99\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"42.0\" x2=\"99\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"0\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\"\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">population</text><rect x=\"551\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"10\" x2=\"567.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"10\" x2=\"583.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"26.0\" x2=\"599\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"42.0\" x2=\"599\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"150\" y1=\"43.0\" x2=\"490\" y2=\"43.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 43.0 490, 37.0 490, 49.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"10.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"40.0\"\" x=\"324.0\" font-size=\"7pt\" >date <= date</tspan><tspan y=\"50.0\"\" x=\"324.0\" font-size=\"7pt\" >Memory: 1.0 days</tspan></text></svg></div>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   join keys used    memory   \n",
       "population    peripheral          False                  0.0                        86400.0   \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   other time stamps used   relationship   time stamps used   \n",
       "                       date                     many-to-many   date               \n",
       "\n",
       "\n",
       "\n",
       "other join keys used   upper time stamps used   \n",
       "                                                "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(1)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['FastPropModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['FastPropModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_prop = getml.feature_learning.FastPropModel(\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    num_features=40,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor(n_jobs=1)\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 1d', 'simple features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[fast_prop],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "FastProp: Trying 72 features...\n",
      "[========================================] 100%\n",
      "\n",
      "FastProp: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:0m:15.773669\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['FastPropModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)</pre><br><pre>url: <a href=\"http://localhost:1709/#/getpipeline/air_pollution/LfOp2P/0/\" target=\"_blank\">http://localhost:1709/#/getpipeline/air_pollution/LfOp2P/0/</a></pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['FastPropModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)\n",
       "\n",
       "url: http://localhost:1709/#/getpipeline/air_pollution/LfOp2P/0/"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FastProp: Building features...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: left;border-right:1pt solid LightGray;\"> </th><th style=\"text-align: right;\">date time          </th><th style=\"text-align: right;\">set used</th><th style=\"text-align: right;\">target</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">rsquared</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td style=\"border-right:1pt solid LightGray;\"><b>0</b></td><td>2021-02-24 10:53:40</td><td>train   </td><td>pm2.5 </td><td> 40.79000</td><td> 58.38303</td><td> 0.60263</td></tr><tr><td style=\"border-right:1pt solid LightGray;\"><b>1</b></td><td>2021-02-24 10:53:41</td><td>test    </td><td>pm2.5 </td><td> 46.54800</td><td> 65.88426</td><td> 0.51142</td></tr></tbody></table>"
      ],
      "text/plain": [
       "    date time             set used   target         mae        rmse   rsquared\n",
       "0   2021-02-24 10:53:40   train      pm2.5     40.79000    58.38303    0.60263\n",
       "1   2021-02-24 10:53:41   test       pm2.5     46.54800    65.88426    0.51142"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(df_test, [df_full])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Using featuretools\n",
    "\n",
    "To make things a bit easier, we have written a high-level wrapper around featuretools which we placed in a separate module (`utils`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuretools: Trying features...\n",
      "Time taken: 0h:1m:37.306428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_FEATURETOOLS:\n",
    "    ft_builder = FTTimeSeriesBuilder(\n",
    "        num_features=40,\n",
    "        horizon=pd.Timedelta(days=0),\n",
    "        memory=pd.Timedelta(days=1),\n",
    "        column_id=\"id\",\n",
    "        time_stamp=\"date\",\n",
    "        target=\"pm2.5\")\n",
    "    #\n",
    "    featuretools_training = ft_builder.fit(data_train_pandas)\n",
    "    featuretools_test = ft_builder.transform(data_test_pandas)\n",
    "    #\n",
    "    featuretools_training.to_csv(\"featuretools_training.csv\", index=False)\n",
    "    featuretools_test.to_csv(\"featuretools_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_FEATURETOOLS:\n",
    "    featuretools_training = pd.read_csv(\"featuretools_training.csv\")\n",
    "    featuretools_test = pd.read_csv(\"featuretools_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_featuretools_training = getml.data.DataFrame.from_pandas(featuretools_training, name='featuretools_training')\n",
    "df_featuretools_test = getml.data.DataFrame.from_pandas(featuretools_test, name='featuretools_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_roles_featuretools(df):\n",
    "    df[\"date\"] = df[\"date\"].as_ts()\n",
    "    df.set_role([\"pm2.5\"], getml.data.roles.target)\n",
    "    df.set_role([\"date\"], getml.data.roles.time_stamp)\n",
    "    df.set_role(df.unused_names, getml.data.roles.numerical)\n",
    "    df.set_role([\"id\"], getml.data.roles.unused_float)\n",
    "    return df\n",
    "\n",
    "df_featuretools_training = set_roles_featuretools(df_featuretools_training)\n",
    "df_featuretools_test = set_roles_featuretools(df_featuretools_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], <br>         include_categorical=False, peripheral=[], population='POPULATION', <br>         predictors=['XGBoostRegressor'], tags=['featuretools', 'memory: 1d'], <br>         share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], \n",
       "         include_categorical=False, peripheral=[], population='POPULATION', \n",
       "         predictors=['XGBoostRegressor'], tags=['featuretools', 'memory: 1d'], \n",
       "         share_selected_features=0.5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = getml.predictors.XGBoostRegressor()\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['featuretools', 'memory: 1d'],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_featuretools_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:0m:4.410858\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], <br>         include_categorical=False, peripheral=[], population='POPULATION', <br>         predictors=['XGBoostRegressor'], tags=['featuretools', 'memory: 1d'], <br>         share_selected_features=0.5)</pre><br><pre>url: <a href=\"http://localhost:1709/#/getpipeline/air_pollution/vYBEQb/0/\" target=\"_blank\">http://localhost:1709/#/getpipeline/air_pollution/vYBEQb/0/</a></pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], \n",
       "         include_categorical=False, peripheral=[], population='POPULATION', \n",
       "         predictors=['XGBoostRegressor'], tags=['featuretools', 'memory: 1d'], \n",
       "         share_selected_features=0.5)\n",
       "\n",
       "url: http://localhost:1709/#/getpipeline/air_pollution/vYBEQb/0/"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_featuretools_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: left;border-right:1pt solid LightGray;\"> </th><th style=\"text-align: right;\">date time          </th><th style=\"text-align: right;\">set used             </th><th style=\"text-align: right;\">target</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">rsquared</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td style=\"border-right:1pt solid LightGray;\"><b>0</b></td><td>2021-02-24 10:55:50</td><td>featuretools_training</td><td>pm2.5 </td><td> 40.73829</td><td> 57.75336</td><td> 0.61230</td></tr><tr><td style=\"border-right:1pt solid LightGray;\"><b>1</b></td><td>2021-02-24 10:55:50</td><td>featuretools_test    </td><td>pm2.5 </td><td> 46.85966</td><td> 66.42585</td><td> 0.50410</td></tr></tbody></table>"
      ],
      "text/plain": [
       "    date time             set used                target         mae        rmse   rsquared\n",
       "0   2021-02-24 10:55:50   featuretools_training   pm2.5     40.73829    57.75336    0.61230\n",
       "1   2021-02-24 10:55:50   featuretools_test       pm2.5     46.85966    66.42585    0.50410"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(df_featuretools_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Using tsfresh\n",
    "\n",
    "tsfresh is a rather low-level library. To make things a bit easier, we have written a high-level wrapper which we placed in a separate module (`utils`).\n",
    "\n",
    "To limit the memory consumption, we undertake the following steps:\n",
    "\n",
    "- We limit ourselves to a memory of 1 day from any point in time. This is necessary, because tsfresh duplicates records for every time stamp. That means that looking back 7 days instead of one day, the memory consumption would be  seven times as high.\n",
    "- We extract only tsfresh's **MinimalFCParameters** and **IndexBasedFCParameters** (the latter is a superset of **TimeBasedFCParameters**).\n",
    "\n",
    "In order to make sure that tsfresh's features can be compared to getML's features, we also do the following:\n",
    "\n",
    "- We apply tsfresh's built-in feature selection algorithm.\n",
    "- Of the remaining features, we only keep the 40 features most correlated with the target (in terms of the absolute value of the correlation).\n",
    "- We add the original columns as additional features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>22.0</td>\n",
       "      <td>-19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>114.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 19:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>18.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>119.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>125.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 21:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>130.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 22:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>137.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33096 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm2.5  DEWP  TEMP    PRES     Iws  Is  Ir                 date  id\n",
       "24     129.0   -16  -4.0  1020.0    1.79   0   0  2010-01-02 00:00:00   1\n",
       "25     148.0   -15  -4.0  1020.0    2.68   0   0  2010-01-02 01:00:00   1\n",
       "26     159.0   -11  -5.0  1021.0    3.57   0   0  2010-01-02 02:00:00   1\n",
       "27     181.0    -7  -5.0  1022.0    5.36   1   0  2010-01-02 03:00:00   1\n",
       "28     138.0    -7  -5.0  1022.0    6.25   2   0  2010-01-02 04:00:00   1\n",
       "...      ...   ...   ...     ...     ...  ..  ..                  ...  ..\n",
       "35059   22.0   -19   7.0  1013.0  114.87   0   0  2013-12-31 19:00:00   1\n",
       "35060   18.0   -21   7.0  1014.0  119.79   0   0  2013-12-31 20:00:00   1\n",
       "35061   23.0   -21   7.0  1014.0  125.60   0   0  2013-12-31 21:00:00   1\n",
       "35062   20.0   -21   6.0  1014.0  130.52   0   0  2013-12-31 22:00:00   1\n",
       "35063   23.0   -20   7.0  1014.0  137.67   0   0  2013-12-31 23:00:00   1\n",
       "\n",
       "[33096 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the issues about tsfresh is that is actually requires more memory than allowed by MyBinder. We therefore have to remove the parts that relate to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 20/20 [01:22<00:00,  4.14s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:47<00:00,  2.38s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [01:27<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0h:4m:1.47543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 20/20 [00:15<00:00,  1.25it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:13<00:00,  1.49it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:27<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "if RUN_TSFRESH:\n",
    "    tsfresh_builder = TSFreshBuilder(\n",
    "        num_features=40,\n",
    "        memory=24,\n",
    "        column_id=\"id\",\n",
    "        time_stamp=\"date\",\n",
    "        target=\"pm2.5\")\n",
    "    #\n",
    "    tsfresh_training = tsfresh_builder.fit(data_train_pandas)\n",
    "    tsfresh_test = tsfresh_builder.transform(data_test_pandas)\n",
    "    #\n",
    "    tsfresh_training.to_csv(\"tsfresh_training.csv\", index=False)\n",
    "    tsfresh_test.to_csv(\"tsfresh_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsfresh does not contain built-in machine learning algorithms. In order to ensure a fair comparison, we use the exact same machine learning algorithm we have also used for getML: An XGBoost regressor with all hyperparameters set to their default value.\n",
    "\n",
    "In order to do so, we load the tsfresh features into the getML engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_TSFRESH:\n",
    "    tsfresh_training = pd.read_csv(\"tsfresh_training.csv\")\n",
    "    tsfresh_test = pd.read_csv(\"tsfresh_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsfresh_training = getml.data.DataFrame.from_pandas(tsfresh_training, name='tsfresh_training')\n",
    "df_tsfresh_test = getml.data.DataFrame.from_pandas(tsfresh_test, name='tsfresh_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we need to set roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_roles_tsfresh(df):\n",
    "    df[\"date\"] = df[\"date\"].as_ts()\n",
    "    df.set_role([\"pm2.5\"], getml.data.roles.target)\n",
    "    df.set_role([\"date\"], getml.data.roles.time_stamp)\n",
    "    df.set_role(df.unused_names, getml.data.roles.numerical)\n",
    "    df.set_role([\"id\"], getml.data.roles.unused_float)\n",
    "    return df\n",
    "\n",
    "df_tsfresh_training = set_roles_tsfresh(df_tsfresh_training)\n",
    "df_tsfresh_test = set_roles_tsfresh(df_tsfresh_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our pipeline is very simple. It only consists of a single XGBoostRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], <br>         include_categorical=False, peripheral=[], population='POPULATION', <br>         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], <br>         share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], \n",
       "         include_categorical=False, peripheral=[], population='POPULATION', \n",
       "         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], \n",
       "         share_selected_features=0.5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = getml.predictors.XGBoostRegressor()\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['tsfresh', 'memory: 1d'],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_tsfresh_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:0m:5.822567\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], <br>         include_categorical=False, peripheral=[], population='POPULATION', <br>         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], <br>         share_selected_features=0.5)</pre><br><pre>url: <a href=\"http://localhost:1709/#/getpipeline/air_pollution/2Ux4wt/0/\" target=\"_blank\">http://localhost:1709/#/getpipeline/air_pollution/2Ux4wt/0/</a></pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], \n",
       "         include_categorical=False, peripheral=[], population='POPULATION', \n",
       "         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], \n",
       "         share_selected_features=0.5)\n",
       "\n",
       "url: http://localhost:1709/#/getpipeline/air_pollution/2Ux4wt/0/"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df_tsfresh_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: left;border-right:1pt solid LightGray;\"> </th><th style=\"text-align: right;\">date time          </th><th style=\"text-align: right;\">set used        </th><th style=\"text-align: right;\">target</th><th style=\"text-align: right;\">      mae</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">rsquared</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td style=\"border-right:1pt solid LightGray;\"><b>0</b></td><td>2021-02-24 11:01:05</td><td>tsfresh_training</td><td>pm2.5 </td><td> 41.12497</td><td> 58.45320</td><td> 0.60130</td></tr><tr><td style=\"border-right:1pt solid LightGray;\"><b>1</b></td><td>2021-02-24 11:01:05</td><td>tsfresh_test    </td><td>pm2.5 </td><td> 46.66552</td><td> 66.26759</td><td> 0.50394</td></tr></tbody></table>"
      ],
      "text/plain": [
       "    date time             set used           target         mae        rmse   rsquared\n",
       "0   2021-02-24 11:01:05   tsfresh_training   pm2.5     41.12497    58.45320    0.60130\n",
       "1   2021-02-24 11:01:05   tsfresh_test       pm2.5     46.66552    66.26759    0.50394"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(df_tsfresh_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussion\n",
    "\n",
    "We have seen that getML outperforms tsfresh by more than 10 percentage points in terms of R-squared. We now want to analyze why that is.\n",
    "\n",
    "There are two possible hypotheses:\n",
    "\n",
    "- getML outperforms featuretools and tsfresh, because it using feature learning and is able to produce more complex features\n",
    "- getML outperforms featuretools and tsfresh, because it makes better use of memory and is able to look back further.\n",
    "\n",
    "Let's summarize our findings:\n",
    "\n",
    "\n",
    "Name         | Memory  | Feature complexity | R-squared | RMSE | Time taken\n",
    "------------ | ------- | ------------------ | --------- | ---- | -----------------------\n",
    "Pipeline 1   |  7 days |            complex |     62.3% | 57.8 | ~4 minutes 48 seconds\n",
    "Pipeline 2   |   1 day |            complex |     51.5% | 66.1 | ~2 minutes 7 seconds\n",
    "Pipeline 3   |  7 days |             simple |     48.4% | 68.6 | ~27 seconds\n",
    "Pipeline 4   |   1 day |             simple |     51.1% | 65.8 | ~15 seconds\n",
    "featuretools |   1 day |             simple |     50.4% | 66.4 | ~1 minute 40 seconds\n",
    "tsfresh      |   1 day |             simple |     50.4% | 66.3 | ~4 minutes\n",
    "\n",
    "\n",
    "We have built simple features and complex features and we also differentiate between am memory of 1 day and a memory of 7 days. When we have a memory of one day and allow only simple features, getML produces features that are very similar to featuertools and tsfresh. It is therefore unsurprising that their performance is roughly on par with the performance of featuretools and tsfresh, even though getML is several orders of magnitude faster. It is about seven times faster than featuretools (15 seconds vs 1 minute 40 seconds) and about 20 times faster than tsfresh (15 seconds vs 4 minutes).\n",
    "\n",
    "The summary table shows that combination of both of our hypotheses explains why getML outperforms featuretools and tsfresh. Complex features do better than simple features with a memory of one day. With a memory of seven days, simple features actually get worse. But when you look back seven days and allow more complex features, you get good results.\n",
    "\n",
    "This suggests that getML outperforms featuretools and tsfresh, because it can make more efficient use of memory and thus look back further. Because getML uses feature learning and can build more complex features it can make better use of the greater look-back window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "We have compared getML's feature learning algorithms to tsfresh's brute-force feature engineering approaches on a data set related to air pollution in China. We found that getML significantly outperforms featuretools and tsfresh. These results are consistent with the view that feature learning can yield significant improvements over simple propositionalization approaches.\n",
    "\n",
    "However, there are other datasets on which simple propositionalization performs well. Our suggestion is therefore to think of algorithms like `FastProp` and `RelMT` as tools in a toolbox. If a simple tool like `FastProp` gets the job done, then use that. But when you need more advanced approaches, like `RelMT`, you should have them at your disposal as well.\n",
    "\n",
    "You are encouraged to reproduce these results. You will need getML (https://getml.com/product) and tsfresh (https://tsfresh.readthedocs.io/en/latest/). You can download both for free. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
