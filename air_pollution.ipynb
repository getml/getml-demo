{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "source": [
    "# Why feature learning is better than brute-force feature engineering\n",
    "\n",
    "In this notebook we will compare **getML** to **tsfresh**, an open-source library that generates features for time series. tsfresh uses a **brute-force approach** to feature engineering, whereas getML uses **feature learning**. We find that getML generates **significantly better predictions** and **consumes roughly 2% of the memory that tsfresh requires**. We then discuss **why that is**.\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Prediction type: __Regression model__\n",
    "- Domain: __Air pollution__\n",
    "- Prediction target: __pm 2.5 concentration__ \n",
    "- Source data: __Multivariate time series__\n",
    "- Population size: __41757__\n",
    "\n",
    "*Author: Patrick Urbanke*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Many data scientists and AutoML tools use **brute-force methods** for feature engineering. These brute-force methods usually work as follows:\n",
    "\n",
    "- Generate a large number of hard-coded features\n",
    "- Use feature selection to pick a small percentage of these features\n",
    "\n",
    "By contrast, getML (https://getml.com/product) uses **feature learning**: Feature learning **adapts machine learning approaches** such as decision trees or gradient boosting **to the problem of extracting features** from relational data and time series.\n",
    "\n",
    "In this notebook, we will **benchmark getML** (https://getml.com/product) **against tsfresh** (https://tsfresh.readthedocs.io/en/latest/). tsfresh is a popular Python library that uses brute-force methods as described above to **generate features for time series**.\n",
    "\n",
    "As our example dataset, we use a **publicly available dataset on air pollution in Beijing, China** (https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data). The data set has been originally used in the following study:\n",
    "\n",
    "Liang, X., Zou, T., Guo, B., Li, S., Zhang, H., Zhang, S., Huang, H. and Chen, S. X. (2015). Assessing Beijing's PM2.5 pollution: severity, weather impact, APEC and winter heating. Proceedings of the Royal Society A, 471, 20150257.\n",
    "\n",
    "We find that:\n",
    "\n",
    "- getML significantly outperforms tsfresh in terms of predictive accuracy (**R-squared of 60.9%** vs **R-squared of 48.7%**).\n",
    "- getML consumes **considerably less memory** than tsfresh (**0.08 GB** vs **3.63 GB**).\n",
    "\n",
    "Our findings indicate that feature learning algorithms are **better at adapting to data sets** and are also **more scalable** due to their lower memory requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A web frontend for getML\n",
    "\n",
    "The getML monitor is a frontend built to support your work with getML. The getML monitor displays information such as the imported data frames, trained pipelines and allows easy data and feature exploration. You can launch the getML monitor [here](http://localhost:1709)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from urllib import request\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import getml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import tsfresh\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data from the UCI Machine Learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "    fname, res = request.urlretrieve(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/\" + fname, \n",
    "        fname\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare data for tsfresh and getML\n",
    "\n",
    "Our our goal is to predict the pm2.5 concentration from factors such as weather or time of day. However, there are some **missing entries** for pm2.5, so we get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_pandas = pd.read_csv(fname)\n",
    "\n",
    "data_full_pandas = data_full_pandas[\n",
    "    data_full_pandas[\"pm2.5\"] == data_full_pandas[\"pm2.5\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsfresh requires a date column, so we build one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_leading_zero(val):\n",
    "    if len(str(val)) == 1:\n",
    "        return \"0\" + str(val)\n",
    "    return str(val)\n",
    "\n",
    "data_full_pandas[\"month\"] = [\n",
    "    add_leading_zero(val) for val in data_full_pandas[\"month\"]\n",
    "]\n",
    "\n",
    "data_full_pandas[\"day\"] = [\n",
    "    add_leading_zero(val) for val in data_full_pandas[\"day\"]\n",
    "]\n",
    "\n",
    "data_full_pandas[\"hour\"] = [\n",
    "    add_leading_zero(val) for val in data_full_pandas[\"hour\"]\n",
    "]\n",
    "\n",
    "def make_date(year, month, day, hour):\n",
    "    return year + \"-\" + month + \"-\" + day + \" \" + hour + \":00:00\"\n",
    "\n",
    "data_full_pandas[\"date\"] = [\n",
    "    make_date(str(year), month, day, hour) \\\n",
    "    for year, month, day, hour in zip(\n",
    "        data_full_pandas[\"year\"],\n",
    "        data_full_pandas[\"month\"],\n",
    "        data_full_pandas[\"day\"],\n",
    "        data_full_pandas[\"hour\"],\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsfresh also requires the time series to have ids. Since there is only a single time series, that series has the same id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_pandas[\"id\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset now contains many columns that we do not need or that tsfresh cannot process. For instance, *cbwd* might actually contain useful information, but it is a categorical variable, which is difficult to handle for tsfresh, so we remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to split our data into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_pandas = data_full_pandas[data_full_pandas[\"year\"] < 2014]\n",
    "data_test_pandas = data_full_pandas[data_full_pandas[\"year\"] == 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_columns(df):\n",
    "    del df[\"cbwd\"]\n",
    "    del df[\"year\"]\n",
    "    del df[\"month\"]\n",
    "    del df[\"day\"]\n",
    "    del df[\"hour\"]\n",
    "    del df[\"No\"]\n",
    "    return df\n",
    "\n",
    "data_full_pandas = remove_unwanted_columns(data_full_pandas)\n",
    "data_train_pandas = remove_unwanted_columns(data_train_pandas)\n",
    "data_test_pandas = remove_unwanted_columns(data_test_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 19:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 21:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43822</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 22:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41757 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm2.5  DEWP  TEMP    PRES     Iws  Is  Ir                 date  id\n",
       "24     129.0   -16  -4.0  1020.0    1.79   0   0  2010-01-02 00:00:00   1\n",
       "25     148.0   -15  -4.0  1020.0    2.68   0   0  2010-01-02 01:00:00   1\n",
       "26     159.0   -11  -5.0  1021.0    3.57   0   0  2010-01-02 02:00:00   1\n",
       "27     181.0    -7  -5.0  1022.0    5.36   1   0  2010-01-02 03:00:00   1\n",
       "28     138.0    -7  -5.0  1022.0    6.25   2   0  2010-01-02 04:00:00   1\n",
       "...      ...   ...   ...     ...     ...  ..  ..                  ...  ..\n",
       "43819    8.0   -23  -2.0  1034.0  231.97   0   0  2014-12-31 19:00:00   1\n",
       "43820   10.0   -22  -3.0  1034.0  237.78   0   0  2014-12-31 20:00:00   1\n",
       "43821   10.0   -22  -3.0  1034.0  242.70   0   0  2014-12-31 21:00:00   1\n",
       "43822    8.0   -22  -4.0  1034.0  246.72   0   0  2014-12-31 22:00:00   1\n",
       "43823   12.0   -21  -3.0  1034.0  249.85   0   0  2014-12-31 23:00:00   1\n",
       "\n",
       "[41757 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then **load the data into the getML engine**. We begin by setting a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new project 'air_pollution'\n"
     ]
    }
   ],
   "source": [
    "getml.engine.set_project('air_pollution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = getml.data.DataFrame.from_pandas(data_full_pandas, name='full')\n",
    "df_train = getml.data.DataFrame.from_pandas(data_train_pandas, name='train')\n",
    "df_test = getml.data.DataFrame.from_pandas(data_test_pandas, name='test')\n",
    "\n",
    "df_full[\"date\"] = df_full[\"date\"].as_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to **assign roles** to the columns, such as defining the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_roles(df):\n",
    "    df.set_role([\"date\"], getml.data.roles.time_stamp)\n",
    "    df.set_role([\"pm2.5\"], getml.data.roles.target)\n",
    "    df.set_role([\n",
    "        \"DEWP\", \n",
    "        \"TEMP\",\n",
    "        \"PRES\",\n",
    "        \"Iws\",\n",
    "        \"Is\",\n",
    "        \"Ir\"], getml.data.roles.numerical)\n",
    "\n",
    "set_roles(df_full)\n",
    "set_roles(df_train)\n",
    "set_roles(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tracking memory consumption\n",
    "\n",
    "A major issue about brute-force is their memory consumption. We would therefore like to be able to measure the memory consumption of different algorithms.\n",
    "\n",
    "We will do so by tracking the **overall system memory usage** and then substracting the **peak system memory usage** from the **initial memory usage**. This gives a good approximation **as long as we do not start any other memory-heavy processes while training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryTracker():\n",
    "    \"\"\"\n",
    "    The MemoryTracker measures the system's memory consumption\n",
    "    once every second. It can be used to get an approximation of \n",
    "    the overall memory consumption of certain algorithms.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._initial_usage = 0\n",
    "        self._max_usage = 0\n",
    "        \n",
    "        self._stop = False\n",
    "        \n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        self.th = threading.Thread(\n",
    "            target=self._measure_memory_usage,\n",
    "        )\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.stop()\n",
    "        \n",
    "    def _get_memory_usage(self):\n",
    "        return psutil.virtual_memory().used\n",
    "\n",
    "    def _measure_memory_usage(self):\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "            \n",
    "            self.lock.acquire()\n",
    "                                    \n",
    "            if self._stop:\n",
    "                self.lock.release()\n",
    "                break\n",
    "            \n",
    "            current_usage = self._get_memory_usage()\n",
    "            \n",
    "            if current_usage > self._max_usage:\n",
    "                self._max_usage = current_usage\n",
    "            \n",
    "            self.lock.release()\n",
    "\n",
    "    @property\n",
    "    def peak_consumption(self):\n",
    "        \"\"\"\n",
    "        The peak system memory consumption, in GB\n",
    "        \"\"\"\n",
    "        self.lock.acquire()\n",
    "        \n",
    "        p_con = self._max_usage - self._initial_usage\n",
    "        \n",
    "        self.lock.release()\n",
    "        \n",
    "        p_con /= 1e9\n",
    "        \n",
    "        return p_con\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Starts measuring the memory consumption.\n",
    "        \"\"\"\n",
    "        self.lock.acquire()\n",
    "        \n",
    "        self._initial_usage = self._get_memory_usage()\n",
    "        \n",
    "        self._max_usage = self._initial_usage\n",
    "        \n",
    "        self._stop = False\n",
    "        \n",
    "        self.th = threading.Thread(\n",
    "            target=self._measure_memory_usage,\n",
    "        )\n",
    "        \n",
    "        self.th.start()\n",
    "        \n",
    "        self.lock.release()\n",
    "        \n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Stops measuring the memory consumption.\n",
    "        \"\"\"\n",
    "        self.lock.acquire()\n",
    "        self._stop = True\n",
    "        self.lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_tracker = MemoryTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictive modelling\n",
    "\n",
    "\n",
    "### 3.1 Pipeline 1: Complex features, 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first experiment, we will learn **complex features** and allow a memory of **up to seven days**. That means at every given point in time, the algorithm is allowed to **look back seven days into the past**.\n",
    "\n",
    "getML uses relational learning to build construct the pipelines. Even though there is a simpler time series API, the relational API is **more flexible** which is why decide to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>604800.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   \n",
       "population    peripheral          False                  0.0       \n",
       "\n",
       "\n",
       "\n",
       "join keys used     memory   other join keys used   other time stamps used   \n",
       "                 604800.0                          date                     \n",
       "\n",
       "\n",
       "\n",
       "join keys used   relationship   time stamps used   ...   \n",
       "                 many-to-many   date               ...   "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(7)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set up the features. We will use two different feature learning algorithms, namely **MultirelModel** and **RelboostModel**. Because we want **complex features**, we set *max_length* and *max_depth* to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregations = [\n",
    "    getml.feature_learning.aggregations.Avg,\n",
    "    getml.feature_learning.aggregations.Sum,\n",
    "    getml.feature_learning.aggregations.Min,\n",
    "    getml.feature_learning.aggregations.Max,\n",
    "    getml.feature_learning.aggregations.Median,\n",
    "    getml.feature_learning.aggregations.Stddev\n",
    "]\n",
    "\n",
    "multirel = getml.feature_learning.MultirelModel(\n",
    "    aggregation=aggregations,\n",
    "    num_features=10,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    max_length=7\n",
    ")\n",
    "\n",
    "relboost = getml.feature_learning.RelboostModel(\n",
    "    num_features=10,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    max_depth=7\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor()\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 7d', 'complex features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[multirel, relboost],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to always **check your data model first**, even though `check(...)` is also called by `fit(...)`. That enables us to make last-minute changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit our data on the training set and evaluate our findings, both in-sample and out of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "MultirelModel: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:14m:31.59573\n",
      "\n",
      "Memory consumption: \n",
      "0.07745536\n"
     ]
    }
   ],
   "source": [
    "memory_tracker.start()\n",
    "pipe.fit(df_train, [df_full])\n",
    "memory_tracker.stop()\n",
    "\n",
    "print(\"Memory consumption: \")\n",
    "print(memory_tracker.peak_consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "In sample: {'mae': [30.921433475676267], 'rmse': [43.9544175981943], 'rsquared': [0.7706751157318166]}\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "Out of sample: {'mae': [40.097575759601405], 'rmse': [58.56721852677215], 'rsquared': [0.6085457300725953]}\n"
     ]
    }
   ],
   "source": [
    "in_sample = pipe.score(df_train, [df_full])\n",
    "print('In sample:', in_sample)\n",
    "\n",
    "out_of_sample = pipe.score(df_test, [df_full])\n",
    "print('Out of sample:', out_of_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pipeline 2: Complex features, 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>86400.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   \n",
       "population    peripheral          False                  0.0       \n",
       "\n",
       "\n",
       "\n",
       "join keys used    memory   other join keys used   other time stamps used   \n",
       "                 86400.0                          date                     \n",
       "\n",
       "\n",
       "\n",
       "join keys used   relationship   time stamps used   ...   \n",
       "                 many-to-many   date               ...   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(1)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregations = [\n",
    "    getml.feature_learning.aggregations.Avg,\n",
    "    getml.feature_learning.aggregations.Sum,\n",
    "    getml.feature_learning.aggregations.Min,\n",
    "    getml.feature_learning.aggregations.Max,\n",
    "    getml.feature_learning.aggregations.Median,\n",
    "    getml.feature_learning.aggregations.Stddev\n",
    "]\n",
    "\n",
    "multirel = getml.feature_learning.MultirelModel(\n",
    "    aggregation=aggregations,\n",
    "    num_features=10,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    max_length=0\n",
    ")\n",
    "\n",
    "relboost = getml.feature_learning.RelboostModel(\n",
    "    num_features=10,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor()\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 1d', 'complex features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[multirel, relboost],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "MultirelModel: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:3m:15.85154\n",
      "\n",
      "Memory consumption: \n",
      "0.024039424\n"
     ]
    }
   ],
   "source": [
    "memory_tracker.start()\n",
    "pipe.fit(df_train, [df_full])\n",
    "memory_tracker.stop()\n",
    "\n",
    "print(\"Memory consumption: \")\n",
    "print(memory_tracker.peak_consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "In sample: {'mae': [38.17490033531624], 'rmse': [54.7799460058], 'rsquared': [0.6442914910608807]}\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "RelboostModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "Out of sample: {'mae': [44.95119658580155], 'rmse': [66.09828658228155], 'rsquared': [0.5018899991896832]}\n"
     ]
    }
   ],
   "source": [
    "in_sample = pipe.score(df_train, [df_full])\n",
    "print('In sample:', in_sample)\n",
    "\n",
    "out_of_sample = pipe.score(df_test, [df_full])\n",
    "print('Out of sample:', out_of_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pipeline 3: Simple features, 7 days\n",
    "\n",
    "For our third experiment, we will learn **simple features** and allow a memory of up to seven days.\n",
    "\n",
    "This simplicity is accomplished by learning 20 features using **MultirelModel** with a *max_length* of 0. That means that **MultirelModel is not allowed to learn any conditions**. The resulting features can expected to be **very similar to features produced by tsfresh**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>604800.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   \n",
       "population    peripheral          False                  0.0       \n",
       "\n",
       "\n",
       "\n",
       "join keys used     memory   other join keys used   other time stamps used   \n",
       "                 604800.0                          date                     \n",
       "\n",
       "\n",
       "\n",
       "join keys used   relationship   time stamps used   ...   \n",
       "                 many-to-many   date               ...   "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(7)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['MultirelModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregations = [\n",
    "    getml.feature_learning.aggregations.Avg,\n",
    "    getml.feature_learning.aggregations.Sum,\n",
    "    getml.feature_learning.aggregations.Min,\n",
    "    getml.feature_learning.aggregations.Max,\n",
    "    getml.feature_learning.aggregations.Median,\n",
    "    getml.feature_learning.aggregations.Stddev\n",
    "]\n",
    "\n",
    "multirel = getml.feature_learning.MultirelModel(\n",
    "    aggregation=aggregations,\n",
    "    num_features=20,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    max_length=0\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor()\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 7d', 'simple features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[multirel],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "MultirelModel: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:2m:1.505907\n",
      "\n",
      "Memory consumption: \n",
      "0.065253376\n"
     ]
    }
   ],
   "source": [
    "memory_tracker.start()\n",
    "pipe.fit(df_train, [df_full])\n",
    "memory_tracker.stop()\n",
    "\n",
    "print(\"Memory consumption: \")\n",
    "print(memory_tracker.peak_consumption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Pipeline 4: Simple features, 1 day\n",
    "\n",
    "For our fourth experiment, we will learn **simple features** and allow a memory of **up to one day**.\n",
    "\n",
    "As we will see, **tsfresh consumes a lot of memory**. Looking further into the past increases the memory requirement to the point that **looking back to up to 7 days is not feasible on a normal desktop computer**. For reasons we will discuss later, we want to replicate the tsfresh features using getML's greedy approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "In sample: {'mae': [44.39174692957318], 'rmse': [62.05820701761394], 'rsquared': [0.5578533318605543]}\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "Out of sample: {'mae': [51.86212120127656], 'rmse': [71.42298768943652], 'rsquared': [0.4305880166321852]}\n"
     ]
    }
   ],
   "source": [
    "in_sample = pipe.score(df_train, [df_full])\n",
    "print('In sample:', in_sample)\n",
    "\n",
    "out_of_sample = pipe.score(df_test, [df_full])\n",
    "print('Out of sample:', out_of_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>86400.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"
      ],
      "text/plain": [
       "placeholder   other placeholder   allow lagged targets   horizon   \n",
       "population    peripheral          False                  0.0       \n",
       "\n",
       "\n",
       "\n",
       "join keys used    memory   other join keys used   other time stamps used   \n",
       "                 86400.0                          date                     \n",
       "\n",
       "\n",
       "\n",
       "join keys used   relationship   time stamps used   ...   \n",
       "                 many-to-many   date               ...   "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = getml.data.Placeholder('population')\n",
    "\n",
    "peripheral = getml.data.Placeholder('peripheral')\n",
    "\n",
    "population.join(\n",
    "    peripheral,\n",
    "    time_stamp='date',\n",
    "    memory=getml.data.time.days(1)\n",
    ")\n",
    "\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=['MultirelModel'], \n",
       "         feature_selectors=[], include_categorical=False, \n",
       "         peripheral=['peripheral'], population='population', \n",
       "         predictors=['XGBoostRegressor'], \n",
       "         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregations = [\n",
    "    getml.feature_learning.aggregations.Avg,\n",
    "    getml.feature_learning.aggregations.Sum,\n",
    "    getml.feature_learning.aggregations.Min,\n",
    "    getml.feature_learning.aggregations.Max,\n",
    "    getml.feature_learning.aggregations.Median,\n",
    "    getml.feature_learning.aggregations.Stddev\n",
    "]\n",
    "\n",
    "multirel = getml.feature_learning.MultirelModel(\n",
    "    aggregation=aggregations,\n",
    "    num_features=20,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    seed=4367,\n",
    "    max_length=0\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor()\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['memory: 1d', 'simple features'],\n",
    "    population=population,\n",
    "    peripheral=[peripheral],\n",
    "    feature_learners=[multirel],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "pipe.check(df_train, [df_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "MultirelModel: Training features...\n",
      "[========================================] 100%\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:1m:24.239231\n",
      "\n",
      "Memory consumption: \n",
      "0.00169984\n"
     ]
    }
   ],
   "source": [
    "memory_tracker.start()\n",
    "pipe.fit(df_train, [df_full])\n",
    "memory_tracker.stop()\n",
    "\n",
    "print(\"Memory consumption: \")\n",
    "print(memory_tracker.peak_consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "In sample: {'mae': [44.076551880232735], 'rmse': [62.61924427999326], 'rsquared': [0.5377020375473408]}\n",
      "\n",
      "MultirelModel: Building features...\n",
      "[========================================] 100%\n",
      "\n",
      "Out of sample: {'mae': [48.43578703042721], 'rmse': [68.2086724841597], 'rsquared': [0.4713164136964429]}\n"
     ]
    }
   ],
   "source": [
    "in_sample = pipe.score(df_train, [df_full])\n",
    "print('In sample:', in_sample)\n",
    "\n",
    "out_of_sample = pipe.score(df_test, [df_full])\n",
    "print('Out of sample:', out_of_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Using tsfresh\n",
    "\n",
    "tsfresh is a rather low-level library. To make things a bit easier, we write a high-level wrapper.\n",
    "\n",
    "To **limit the memory consumption**, we undertake the following steps:\n",
    "\n",
    "- We limit ourselves to a memory of **1 day from any point in time**. This is necessary, because tsfresh duplicates records for every time stamp. That means that looking back 7 days instead of one day, the memory consumption would be  **seven times as high**.\n",
    "- We extract only tsfresh's **MinimalFCParameters** and **IndexBasedFCParameters** (the latter is a superset of **TimeBasedFCParameters**).\n",
    "\n",
    "In order to make sure that tsfresh's features can be compared to getML's features, we also do the following:\n",
    "\n",
    "- We apply **tsfresh's built-in feature selection** algorithm.\n",
    "- Of the remaining features, we only keep the **20 features most correlated with the target** (in terms of the absolute value of the correlation).\n",
    "- We add the **original columns as additional features**.\n",
    "\n",
    "We do this, because we used getML to train 20 features, but have also kept the original columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSFreshBuilder():\n",
    "    \n",
    "    def __init__(self, num_features, memory, column_id, time_stamp, target):\n",
    "        \"\"\"\n",
    "        Scikit-learn style feature builder based on TSFresh.\n",
    "        \n",
    "        Args:\n",
    "            \n",
    "            num_features: The (maximum) number of features to build.\n",
    "            \n",
    "            memory: How much back in time you want to go until the\n",
    "                    feature builder starts \"forgetting\" data.\n",
    "                    \n",
    "            column_id: The name of the column containing the ids.\n",
    "            \n",
    "            time_stamp: The name of the column containing the time stamps.\n",
    "            \n",
    "            target: The name of the target column.\n",
    "        \"\"\"\n",
    "        self.num_features = num_features\n",
    "        self.memory = memory\n",
    "        self.column_id = column_id\n",
    "        self.time_stamp = time_stamp\n",
    "        self.target = target\n",
    "        \n",
    "        self.selected_features = []\n",
    "        \n",
    "    def _add_original_columns(self, original_df, df_selected):\n",
    "        for colname in original_df.columns:\n",
    "            df_selected[colname] = np.asarray(\n",
    "                original_df[colname])\n",
    "                    \n",
    "        return df_selected\n",
    "\n",
    "    def _extract_features(self, df):\n",
    "        df_rolled = roll_time_series(\n",
    "            df, \n",
    "            column_id=self.column_id, \n",
    "            column_sort=self.time_stamp,\n",
    "            max_timeshift=self.memory\n",
    "        )\n",
    "\n",
    "        extracted_minimal = tsfresh.extract_features(\n",
    "            df_rolled,\n",
    "            column_id=self.column_id, \n",
    "            column_sort=self.time_stamp,\n",
    "            default_fc_parameters=tsfresh.feature_extraction.MinimalFCParameters()\n",
    "        )\n",
    "        \n",
    "        extracted_index_based = tsfresh.extract_features(\n",
    "            df_rolled,\n",
    "            column_id=self.column_id, \n",
    "            column_sort=self.time_stamp,\n",
    "            default_fc_parameters=tsfresh.feature_extraction.settings.IndexBasedFCParameters()\n",
    "        )\n",
    "        \n",
    "        extracted_features = pd.concat(\n",
    "            [extracted_minimal, extracted_index_based], axis=1\n",
    "        )\n",
    "        del extracted_minimal\n",
    "        del extracted_index_based\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        extracted_features[\n",
    "            extracted_features != extracted_features] = 0.0  \n",
    "        \n",
    "        extracted_features[\n",
    "            np.isinf(extracted_features)] = 0.0 \n",
    "        \n",
    "        return extracted_features\n",
    "        \n",
    "    def _print_time_taken(self, begin, end):\n",
    "\n",
    "        seconds = end - begin\n",
    "\n",
    "        hours = int(seconds / 3600)\n",
    "        seconds -= float(hours * 3600)\n",
    "\n",
    "        minutes = int(seconds / 60)\n",
    "        seconds -= float(minutes * 60)\n",
    "\n",
    "        seconds = round(seconds, 6)\n",
    "\n",
    "        print(\n",
    "            \"Time taken: \" + str(hours) + \"h:\" +\n",
    "            str(minutes) + \"m:\" + str(seconds)\n",
    "        )\n",
    "\n",
    "        print(\"\")\n",
    "        \n",
    "    def _remove_target_column(self, df):\n",
    "        colnames = np.asarray(df.columns)\n",
    "        \n",
    "        if self.target not in colnames:\n",
    "            return df\n",
    "        \n",
    "        colnames = colnames[colnames != self.target]\n",
    "        \n",
    "        return df[colnames]\n",
    "        \n",
    "    def _select_features(self, df, target):\n",
    "        df_selected = tsfresh.select_features(\n",
    "            df, \n",
    "            target\n",
    "        )\n",
    "        \n",
    "        colnames = np.asarray(df_selected.columns)\n",
    "\n",
    "        correlations = np.asarray([\n",
    "            np.abs(pearsonr(target, df_selected[col]))[0] for col in colnames\n",
    "        ])\n",
    "        \n",
    "        # [::-1] is somewhat unintuitive syntax,\n",
    "        # but it reverses the entire column.\n",
    "        self.selected_features = colnames[\n",
    "            np.argsort(correlations)\n",
    "        ][::-1][:self.num_features]\n",
    "\n",
    "        return df_selected[self.selected_features]\n",
    "        \n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        Fits the features.\n",
    "        \"\"\"\n",
    "        begin = time.time()\n",
    "\n",
    "        target = np.asarray(df[self.target])\n",
    "        \n",
    "        df_without_target = self._remove_target_column(df)\n",
    "        \n",
    "        df_extracted = self._extract_features(\n",
    "            df_without_target)\n",
    "        \n",
    "        df_selected = self._select_features(\n",
    "            df_extracted, target)\n",
    "                \n",
    "        del df_extracted\n",
    "        gc.collect()\n",
    "        \n",
    "        df_selected = self._add_original_columns(df, df_selected)\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        self._print_time_taken(begin, end)\n",
    "        \n",
    "        return df_selected\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        Transforms the raw data into a set of features.\n",
    "        \"\"\"\n",
    "        df_extracted = self._extract_features(df)\n",
    "        \n",
    "        df_selected = df_extracted[self.selected_features]\n",
    "        \n",
    "        del df_extracted\n",
    "        gc.collect()\n",
    "        \n",
    "        df_selected = self._add_original_columns(df, df_selected)\n",
    "                                         \n",
    "        return df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-02 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>22.0</td>\n",
       "      <td>-19</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>114.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 19:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>18.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>119.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>125.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 21:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>130.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 22:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>137.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-12-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33096 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pm2.5  DEWP  TEMP    PRES     Iws  Is  Ir                 date  id\n",
       "24     129.0   -16  -4.0  1020.0    1.79   0   0  2010-01-02 00:00:00   1\n",
       "25     148.0   -15  -4.0  1020.0    2.68   0   0  2010-01-02 01:00:00   1\n",
       "26     159.0   -11  -5.0  1021.0    3.57   0   0  2010-01-02 02:00:00   1\n",
       "27     181.0    -7  -5.0  1022.0    5.36   1   0  2010-01-02 03:00:00   1\n",
       "28     138.0    -7  -5.0  1022.0    6.25   2   0  2010-01-02 04:00:00   1\n",
       "...      ...   ...   ...     ...     ...  ..  ..                  ...  ..\n",
       "35059   22.0   -19   7.0  1013.0  114.87   0   0  2013-12-31 19:00:00   1\n",
       "35060   18.0   -21   7.0  1014.0  119.79   0   0  2013-12-31 20:00:00   1\n",
       "35061   23.0   -21   7.0  1014.0  125.60   0   0  2013-12-31 21:00:00   1\n",
       "35062   20.0   -21   6.0  1014.0  130.52   0   0  2013-12-31 22:00:00   1\n",
       "35063   23.0   -20   7.0  1014.0  137.67   0   0  2013-12-31 23:00:00   1\n",
       "\n",
       "[33096 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = TSFreshBuilder(\n",
    "    num_features=20,\n",
    "    memory=24,\n",
    "    column_id=\"id\",\n",
    "    time_stamp=\"date\",\n",
    "    target=\"pm2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the issues about tsfresh is that is actually requires **more memory than allowed by MyBinder**. We therefore have to **uncomment** the parts that relate to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 20/20 [02:20<00:00,  7.04s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:28<00:00,  1.43s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [01:50<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0h:5m:52.049123\n",
      "\n",
      "Memory consumption: \n",
      "3.629481984\n"
     ]
    }
   ],
   "source": [
    "# memory_tracker.start()\n",
    "# tsfresh_training = builder.fit(data_train_pandas)\n",
    "# memory_tracker.stop()\n",
    "\n",
    "print(\"Memory consumption: \")\n",
    "print(memory_tracker.peak_consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling: 100%|██████████| 20/20 [00:26<00:00,  1.31s/it]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:08<00:00,  2.27it/s]\n",
      "Feature Extraction: 100%|██████████| 20/20 [00:33<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# tsfresh_test = builder.transform(data_test_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tsfresh does not contain built-in machine learning algorithms. In order to ensure a fair comparison, we use the exact same machine learning algorithm we have also used for getML: An **XGBoost regressor** with all **hyperparameters set to their default value**.\n",
    "\n",
    "In order to do so, we **load the tsfresh features into the getML engine**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tsfresh_training = getml.data.DataFrame.from_pandas(tsfresh_training, name='tsfresh_training')\n",
    "# df_tsfresh_test = getml.data.DataFrame.from_pandas(tsfresh_test, name='tsfresh_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we need to set roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_roles_tsfresh(df):\n",
    "    df[\"date\"] = df[\"date\"].as_ts()\n",
    "    df.set_role([\"pm2.5\"], getml.data.roles.target)\n",
    "    df.set_role([\"date\"], getml.data.roles.time_stamp)\n",
    "    df.set_role(df.unused_names, getml.data.roles.numerical)\n",
    "    df.set_role([\"id\"], getml.data.roles.unused_float)\n",
    "    return df\n",
    "\n",
    "# df_tsfresh_training = set_roles_tsfresh(df_tsfresh_training)\n",
    "# df_tsfresh_test = set_roles_tsfresh(df_tsfresh_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our pipeline is very simple. It only consists of a **single XGBoostRegressor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], <br>         include_categorical=False, peripheral=[], population='POPULATION', <br>         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], <br>         share_selected_features=0.5)</pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], \n",
       "         include_categorical=False, peripheral=[], population='POPULATION', \n",
       "         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], \n",
       "         share_selected_features=0.5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = getml.predictors.XGBoostRegressor()\n",
    "\n",
    "pipe = getml.pipeline.Pipeline(\n",
    "    tags=['tsfresh', 'memory: 1d'],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n"
     ]
    }
   ],
   "source": [
    "# pipe.check(df_tsfresh_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data model...\n",
      "OK.\n",
      "\n",
      "XGBoost: Training as predictor...\n",
      "[========================================] 100%\n",
      "\n",
      "Trained pipeline.\n",
      "Time taken: 0h:0m:3.615267\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], <br>         include_categorical=False, peripheral=[], population='POPULATION', <br>         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], <br>         share_selected_features=0.5)</pre><br><pre>url: <a href=\"http://localhost:1709/getpipeline/atiwQ2/0/\" target=\"_blank\">http://localhost:1709/getpipeline/atiwQ2/0/</a></pre>"
      ],
      "text/plain": [
       "Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], \n",
       "         include_categorical=False, peripheral=[], population='POPULATION', \n",
       "         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], \n",
       "         share_selected_features=0.5)\n",
       "\n",
       "url: http://localhost:1709/getpipeline/atiwQ2/0/"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipe.fit(df_tsfresh_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In sample: {'mae': [43.32127850700565], 'rmse': [61.29317266819693], 'rsquared': [0.5603691612933817]}\n",
      "\n",
      "Out of sample: {'mae': [48.12565174316881], 'rmse': [67.39082520271661], 'rsquared': [0.48664403611977386]}\n"
     ]
    }
   ],
   "source": [
    "# in_sample = pipe.score(df_tsfresh_training)\n",
    "# print('In sample:', in_sample)\n",
    "\n",
    "# out_of_sample = pipe.score(df_tsfresh_test)\n",
    "# print('Out of sample:', out_of_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussion\n",
    "\n",
    "We have seen that **getML outperforms tsfresh** by **more than 10 percentage points** in terms of R-squared. We now want to analyze **why that is**.\n",
    "\n",
    "There are two possible hypotheses:\n",
    "\n",
    "- getML outperforms tsfresh, because it using **feature learning** and is able to produce **more complex features**.\n",
    "- getML outperforms tsfresh, because it makes **better use of memory** and is able to **look back further**.\n",
    "\n",
    "Let's summarize our findings:\n",
    "\n",
    "\n",
    "Name       | Look-back | Feature complexity | R-squared | RMSE | Memory usage\n",
    "---------- | --------- | ------------------ | --------- | ---- | ------------ \n",
    "Pipeline 1 |    7 days |            complex |     60.9% | 58.6 | 0.08 GB\n",
    "Pipeline 2 |     1 day |            complex |     50.2% | 66.1 | 0.02 GB\n",
    "Pipeline 3 |    7 days |             simple |     43.0% | 71.4 | 0.07 GB\n",
    "Pipeline 4 |     1 day |             simple |     47.1% | 68.2 | 0.07 GB\n",
    "tsfresh    |     1 day |             simple |     48.7% | 67.4 | 3.63 GB\n",
    "\n",
    "\n",
    "We have built **simple features** and **complex features** and we also differentiate between **looking back 1 day** and **looking back 7 days**. When we **look back one day and allow only simple features**, getML produces features that are **very similar to tsfresh**. It is therefore unsurprising that their performance is **about on par with the performance of tsfresh**. It is actually a bit worse, because getML uses a **greedy algorithm** and there is a price we pay for that. But since the greedy algorithms also allows us to build more complex feature **the benefits of the greedy algorithm outweigh its costs**.\n",
    "\n",
    "Let's also compare the memory consumption: Even Pipeline 1, which has the highest memory consumption of all of getML's pipelines, only consumes **about 2.2% percent of the memory that tsfresh needs**. This is in part due to the way tsfresh is implemented, but it is also an inherent problem: If your approach is to **generate many features to then select a small share, you will need a lot of memory**. In theory, it is possible to write a more memory-efficient implementation of tsfresh and then use a look-back of 7 days, but when we compare Pipeline 3 and Pipeline 4, we can conclude that it is unlikely that this would improve tsfresh's predictive performance.\n",
    "\n",
    "The summary table shows that **a combination of both of our hypotheses** explains why getML outperforms tsfresh. Complex features do better than simple features when looking back one day. When looking back seven days, simple features **actually get worse**. But when you look back seven days and allow more complex features, you really get good results.\n",
    "\n",
    "This suggests that getML outperforms tsfresh, because it can make **more efficient use of memory and thus look back further**. Because **getML uses feature learning** and can **build more complex features** it can make **better use of the greater look-back window**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "We have compared **getML's feature learning algorithms** to **tsfresh's brute-force feature engineering** approaches on a data set related to air pollution in China. We found that **getML significantly outperforms tsfresh**. These results are consistent with the view that **feature learning is better than brute-force feature engineering**.\n",
    "\n",
    "You are **encouraged to reproduce these results**. You will need **getML** (https://getml.com/product) and **tsfresh** (https://tsfresh.readthedocs.io/en/latest/). You can **download both for free**. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
