{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORA: getML performance breaks record\n",
    "\n",
    "Graph Neural Networks (GNNs) are renowned for their outstanding performance on graph-structured data, excelling in tasks like node classification and link prediction. However, deploying GNNs is often complex. Tasks such as graph preprocessing, optimizing architectures, tuning hyperparameters, and ensuring convergence are non-trivial challenges when working with neural network based approaches, requiring considerable time investment.\n",
    "\n",
    "**getML** offers a faster and more user-friendly alternative. Leveraging **getML FastProp**, the fastest open-source tool for propositionalization-based automation of feature engineering on relational data and time series, FastProp transforms relational data into a single feature table suitable for standard machine learning models by efficiently computing a wide range of statistical and temporal aggregates. When combined with models like **XGBoost**, getML delivers a straightforward yet highly performant approach to predictive modeling. This method eliminates the need for complex GNN-based approaches while ensuring coding efficiency, computational speed, and high model accuracy.\n",
    "\n",
    "This notebook demonstrates how **getML** surpasses the previous record on the CORA dataset—set by the GNN-based approach of [Izadi et al. (2020)](https://paperswithcode.com/sota/node-classification-on-cora)—with minimal code and configuration.\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Prediction type: __Classification model__\n",
    "- Domain: __Academia__\n",
    "- Prediction target: __The category of a paper__ \n",
    "- Source data: __Relational data set, 3 tables__\n",
    "- Population size: __2,708__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let some boilerplate code run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"getml==1.5.0\" \"ipywidgets==8.1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getML API version: 1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import getml\n",
    "\n",
    "print(f\"getML API version: {getml.__version__}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching ./getML --allow-push-notifications=true --allow-remote-ips=false --home-directory=/home/user/.getML --in-memory=true --install=false --launch-browser=true --log=false --project-directory=/home/user/.getML/projects in /home/user/.getML/getml-enterprise-1.5.0-amd64-linux...\n",
      "Launched the getML Engine. The log output will be stored in /home/user/.getML/logs/getml_20241119160445.log\n",
      "\u001b[2K  Loading pipelines... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[?25h"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connected to project <span style=\"color: #008000; text-decoration-color: #008000\">'cora_sota'</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connected to project \u001b[32m'cora_sota'\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getml.engine.launch()\n",
    "getml.engine.set_project(\"cora_sota\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Connection(dbname='CORA', dialect='mysql', host='relational.fel.cvut.cz', port=3306)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = getml.database.connect_mysql(\n",
    "    host=\"relational.fel.cvut.cz\",\n",
    "    dbname=\"CORA\",\n",
    "    port=3306,\n",
    "    user=\"guest\",\n",
    "    password=\"ctu-relational\",\n",
    ")\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if_needed(name):\n",
    "    \"\"\"\n",
    "    Loads the data from the relational learning\n",
    "    repository, if the data frame has not already\n",
    "    been loaded.\n",
    "    \"\"\"\n",
    "    if not getml.data.exists(name):\n",
    "        data_frame = getml.data.DataFrame.from_db(name=name, table_name=name, conn=conn)\n",
    "        data_frame.save()\n",
    "    else:\n",
    "        data_frame = getml.data.load_data_frame(name)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = load_if_needed(\"paper\")\n",
    "cites = load_if_needed(\"cites\")\n",
    "content = load_if_needed(\"content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we deviate from the regular procedure by introducing the exact same train test split as the [current top seed](https://paperswithcode.com/paper/optimization-of-graph-neural-networks-with). While we contend, that testing on a single split is not sufficient to demonstrate performance of an algorithm on a specific data set, we proceed as such in order to maximize comparability with the current incumbent of the Leader Board. For a more extensive investigation of the getML performance on the CORA dataset, checkout [our other notebooks](https://getml.com/latest/examples/enterprise-notebooks/kaggle_notebooks/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve the identical split we first need to match papers and their associated word matrix across data sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"assets/zuordnung.json\"):\n",
    "    !pip install torch\n",
    "    !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "    from utils.zuordnung import run_zuordnung\n",
    "\n",
    "    # may take 90 minutes or longer to run\n",
    "    run_zuordnung(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"assets/zuordnung.json\", \"r\") as f:\n",
    "    zuordnung = json.load(f)\n",
    "\n",
    "paper_df = paper.to_pandas()\n",
    "paper_df[\"paper_id\"] = paper_df[\"paper_id\"].astype(int)\n",
    "zuo_df = pd.DataFrame(zuordnung)\n",
    "zuo_df[0] = zuo_df[0].astype(int)\n",
    "paper_df = paper_df.merge(zuo_df, left_on=\"paper_id\", right_on=0).sort_values(by=1)\n",
    "paper_df = paper_df[[\"class_label\", \"paper_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the sorted data set according to the instructions in the Izadi et al. paper (see:  IV. Experiments, A. Datasets, third split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_train = getml.data.DataFrame.from_pandas(paper_df[:1707], name=\"train\")\n",
    "paper_val = getml.data.DataFrame.from_pandas(\n",
    "    paper_df[1707 : 1707 + 500], name=\"validation\"\n",
    ")\n",
    "paper_test = getml.data.DataFrame.from_pandas(paper_df[1707 + 500 :], name=\"test\")\n",
    "\n",
    "paper, split = getml.data.split.concat(\n",
    "    \"population\", train=paper_train, validation=paper_val, test=paper_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Prepare data for getML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getML requires that we define *roles* for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "paper.set_role(\"class_label\", getml.data.roles.categorical)\n",
    "cites.set_role([\"cited_paper_id\", \"citing_paper_id\"], getml.data.roles.join_key)\n",
    "content.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "content.set_role(\"word_cited_id\", getml.data.roles.categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict seven different labels. We generate a target column for each of those labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = getml.data.make_target_columns(paper, \"class_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin-top: 15px;'>\n",
       "<div style='float: left; margin-right: 50px;'>\n",
       "<div style='margin-bottom: 10px; font-size: 1rem;'>population</div>\n",
       "    <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">subset    </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">name      </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"int\">rows</th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">type</th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">test</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">500</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">train</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">1708</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">validation</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">500</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div style='float: left;'>\n",
       "<div style='margin-bottom: 10px; font-size: 1rem;'>peripheral</div>\n",
       "    <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">alias  </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">name      </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> rows</th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">type     </th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">5429</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">49216</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">2708</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "population\n",
       "    subset       name         rows   type\n",
       "0   test         population    500   View\n",
       "1   train        population   1708   View\n",
       "2   validation   population    500   View\n",
       "\n",
       "peripheral\n",
       "    alias     name          rows   type     \n",
       "0   cites     cites         5429   DataFrame\n",
       "1   content   content      49216   DataFrame\n",
       "2   paper     population    2708   DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = getml.data.Container(population=data_full, split=split)\n",
    "container.add(cites=cites, content=content, paper=paper)\n",
    "container.freeze()\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive modeling\n",
    "\n",
    "We loaded the data and defined the roles and units. Next, we create a getML pipeline for relational learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define relational model\n",
    "\n",
    "To get started with relational learning, we need to specify the data model. Even though the data set itself is quite simple with only three tables and six columns in total, the resulting data model is actually quite complicated.\n",
    "\n",
    "That is because the class label can be predicting using three different pieces of information:\n",
    "\n",
    "- The keywords used by the paper\n",
    "- The keywords used by papers it cites and by papers that cite the paper\n",
    "- The class label of papers it cites and by papers that cite the paper\n",
    "\n",
    "The main challenge here is that `cites` is used twice, once to connect the _cited_ papers and then to connect the _citing_ papers. To resolve this, we need two placeholders on `cites`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "            <div style='margin-top: 15px; margin-bottom: 5px;'>\n",
       "            <div style='margin-bottom: 10px; font-size: 1rem;'>diagram</div>\n",
       "            <div style=\"height:540px;width:1160px;position:relative;\"><svg height=\"530\" width=\"1150\"><rect y=\"0\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"51\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"10\" x2=\"67.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"10\" x2=\"83.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"26.0\" x2=\"99\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"42.0\" x2=\"99\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"110\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"183.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">paper</text><rect x=\"51\" y=\"120\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"120\" x2=\"67.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"120\" x2=\"83.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"136.0\" x2=\"99\" y2=\"136.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"152.0\" x2=\"99\" y2=\"152.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"110\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"183.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">cites</text><rect x=\"551\" y=\"120\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"120\" x2=\"567.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"120\" x2=\"583.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"136.0\" x2=\"599\" y2=\"136.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"152.0\" x2=\"599\" y2=\"152.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"220\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"293.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"51\" y=\"230\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"230\" x2=\"67.0\" y2=\"278\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"230\" x2=\"83.0\" y2=\"278\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"246.0\" x2=\"99\" y2=\"246.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"262.0\" x2=\"99\" y2=\"262.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"330\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"403.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">paper</text><rect x=\"51\" y=\"340\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"340\" x2=\"67.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"340\" x2=\"83.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"356.0\" x2=\"99\" y2=\"356.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"372.0\" x2=\"99\" y2=\"372.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"330\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"403.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">cites</text><rect x=\"551\" y=\"340\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"340\" x2=\"567.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"340\" x2=\"583.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"356.0\" x2=\"599\" y2=\"356.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"372.0\" x2=\"599\" y2=\"372.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"440\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"513.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"551\" y=\"450\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"450\" x2=\"567.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"450\" x2=\"583.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"466.0\" x2=\"599\" y2=\"466.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"482.0\" x2=\"599\" y2=\"482.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"440\" x=\"1000\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"513.8\" x=\"1075.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">population</text><rect x=\"1051\" y=\"450\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"1067.0\" y1=\"450\" x2=\"1067.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1083.0\" y1=\"450\" x2=\"1083.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1051\" y1=\"466.0\" x2=\"1099\" y2=\"466.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1051\" y1=\"482.0\" x2=\"1099\" y2=\"482.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"150\" y1=\"43.0\" x2=\"573.0\" y2=\"43.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"573.0\" y1=\"41.0\" x2=\"573.0\" y2=\"100\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"573.0, 110 567.0, 100 579.0, 100 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"10.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"45.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = citing_paper_id</tspan></text><line x1=\"150\" y1=\"153.0\" x2=\"490\" y2=\"153.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 153.0 490, 147.0 490, 159.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"120.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"150.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = citing_paper_id</tspan><tspan y=\"160.0\" x=\"324.0\" font-size=\"7pt\" >Relationship: many-to-one</tspan></text><line x1=\"150\" y1=\"263.0\" x2=\"573.0\" y2=\"263.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"573.0\" y1=\"261.0\" x2=\"573.0\" y2=\"320\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"573.0, 330 567.0, 320 579.0, 320 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"230.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"265.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = cited_paper_id</tspan></text><line x1=\"150\" y1=\"373.0\" x2=\"490\" y2=\"373.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 373.0 490, 367.0 490, 379.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"340.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"370.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = cited_paper_id</tspan><tspan y=\"380.0\" x=\"324.0\" font-size=\"7pt\" >Relationship: many-to-one</tspan></text><line x1=\"650\" y1=\"153.0\" x2=\"1073.0\" y2=\"153.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"1073.0\" y1=\"151.0\" x2=\"1073.0\" y2=\"430\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1073.0, 440 1067.0, 430 1079.0, 430 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"120.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"155.0\" x=\"824.0\" font-size=\"7pt\" >cited_paper_id = paper_id</tspan></text><line x1=\"650\" y1=\"373.0\" x2=\"1073.0\" y2=\"373.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"1073.0\" y1=\"371.0\" x2=\"1073.0\" y2=\"430\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1073.0, 440 1067.0, 430 1079.0, 430 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"340.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"375.0\" x=\"824.0\" font-size=\"7pt\" >citing_paper_id = paper_id</tspan></text><line x1=\"650\" y1=\"483.0\" x2=\"990\" y2=\"483.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1000, 483.0 990, 477.0 990, 489.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"450.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"485.0\" x=\"824.0\" font-size=\"7pt\" >paper_id = paper_id</tspan></text></svg></div>\n",
       "            </div>\n",
       "\n",
       "            <div style='margin-top: 15px;'>\n",
       "            <div style='margin-bottom: 10px; font-size: 1rem;'>staging</div>\n",
       "            <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">data frames </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">staging table              </th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">POPULATION__STAGING_TABLE_1</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites, paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CITES__STAGING_TABLE_2</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites, paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CITES__STAGING_TABLE_3</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>3</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CONTENT__STAGING_TABLE_4</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "population:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'cites'\n",
       "    on: \n",
       "    - (population.paper_id, cites.cited_paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'cites'\n",
       "    on: \n",
       "    - (population.paper_id, cites.citing_paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'content'\n",
       "    on: \n",
       "    - (population.paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "\n",
       "cites:\n",
       "  columns:\n",
       "  - cited_paper_id: join_key\n",
       "  - citing_paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'content'\n",
       "    on: \n",
       "    - (cites.citing_paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'paper'\n",
       "    on: \n",
       "    - (cites.citing_paper_id, paper.paper_id)\n",
       "    relationship: 'many-to-one'\n",
       "    lagged_targets: False\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "paper:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "cites:\n",
       "  columns:\n",
       "  - cited_paper_id: join_key\n",
       "  - citing_paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'content'\n",
       "    on: \n",
       "    - (cites.cited_paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'paper'\n",
       "    on: \n",
       "    - (cites.cited_paper_id, paper.paper_id)\n",
       "    relationship: 'many-to-one'\n",
       "    lagged_targets: False\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "paper:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = getml.data.DataModel(paper.to_placeholder(\"population\"))\n",
    "\n",
    "# We need two different placeholders for cites.\n",
    "dm.add(getml.data.to_placeholder(cites=[cites] * 2, content=content, paper=paper))\n",
    "\n",
    "dm.population.join(dm.cites[0], on=(\"paper_id\", \"cited_paper_id\"))\n",
    "\n",
    "dm.cites[0].join(dm.content, on=(\"citing_paper_id\", \"paper_id\"))\n",
    "\n",
    "dm.cites[0].join(\n",
    "    dm.paper,\n",
    "    on=(\"citing_paper_id\", \"paper_id\"),\n",
    "    relationship=getml.data.relationship.many_to_one,\n",
    ")\n",
    "\n",
    "dm.population.join(dm.cites[1], on=(\"paper_id\", \"citing_paper_id\"))\n",
    "\n",
    "dm.cites[1].join(dm.content, on=(\"cited_paper_id\", \"paper_id\"))\n",
    "\n",
    "dm.cites[1].join(\n",
    "    dm.paper,\n",
    "    on=(\"cited_paper_id\", \"paper_id\"),\n",
    "    relationship=getml.data.relationship.many_to_one,\n",
    ")\n",
    "\n",
    "dm.population.join(dm.content, on=\"paper_id\")\n",
    "\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hyperparameter Search\n",
    "To mimic the approach of the GNN paper, we conduct a small Hyperparameter search, train on the train data, validate on the validate data and use the untouched test data as holdout set to get an unbiased estimate of the true performance.\n",
    "For expediency, we make a grit search along two dimensions and keep the number of levels deliberately small:\n",
    " \n",
    "    num_features: 250, 300, 350\n",
    "    built-in aggregation sets: minimal, default, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = getml.preprocessors.Mapping()\n",
    "predictor = getml.predictors.XGBoostClassifier()\n",
    "\n",
    "actual_labels_val = paper[split == \"validation\"].class_label.to_numpy()\n",
    "actual_labels_test = paper[split == \"test\"].class_label.to_numpy()\n",
    "class_label = paper.class_label.unique()\n",
    "\n",
    "pipe1 = getml.pipeline.Pipeline(\n",
    "    data_model=dm, preprocessors=[mapping], predictors=[predictor]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_acc(prob, actual_labels, class_label) -> float:\n",
    "    ix_max = np.argmax(prob, axis=1)\n",
    "    predicted_labels = np.asarray([class_label[ix] for ix in ix_max])\n",
    "    return (actual_labels == predicted_labels).sum() / len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "parameter_sweep = {}\n",
    "i = 0\n",
    "for num_feat in [250, 300, 350]:\n",
    "    for aggregation_set in [\n",
    "        getml.feature_learning.aggregations.FASTPROP.Minimal,\n",
    "        getml.feature_learning.aggregations.FASTPROP.Default,\n",
    "        getml.feature_learning.aggregations.FASTPROP.All,\n",
    "    ]:\n",
    "        fast_prop = getml.feature_learning.FastProp(\n",
    "            loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "            aggregation=aggregation_set,\n",
    "            num_features=num_feat,\n",
    "        )\n",
    "\n",
    "        pipe1.feature_learners = [fast_prop]\n",
    "\n",
    "        pipe1.fit(container.train)\n",
    "\n",
    "        probs_val = pipe1.predict(container.validation)\n",
    "        val_acc = prob_to_acc(probs_val, actual_labels_val, class_label)\n",
    "\n",
    "        parameter_sweep[i] = {\n",
    "            \"num_feat\": num_feat,\n",
    "            \"agg_set\": aggregation_set,\n",
    "            \"val_acc\": val_acc,\n",
    "        }\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc_comb = list(\n",
    "    sorted(parameter_sweep.items(), key=lambda item: item[1][\"val_acc\"], reverse=True)\n",
    ")[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.876\n",
      "Number of features used: 300\n",
      "Aggregation set used: frozenset({'MAX', 'SUM', 'AVG', 'COUNT', 'MIN'})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on validation set: {best_val_acc_comb['val_acc']}\")\n",
    "print(f\"Number of features used: {best_val_acc_comb['num_feat']}\")\n",
    "print(f\"Aggregation set used: {best_val_acc_comb['agg_set']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we identified the parameter combination that yields the highest accuracy on the validation set, let's use the same parameters on the hold out data to attain an unbiased estimate of the model's predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Checking data model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Checking data model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K  Staging... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  Preprocessing... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[?25h"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The pipeline check generated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> issues labeled INFO and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> issues labeled WARNING.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The pipeline check generated \u001b[1;36m3\u001b[0m issues labeled INFO and \u001b[1;36m0\u001b[0m issues labeled WARNING.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To see the issues in full, run <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.check</span><span style=\"font-weight: bold\">()</span> on the pipeline.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "To see the issues in full, run \u001b[1;35m.check\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m on the pipeline.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K  Staging... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  Preprocessing... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  Retrieving features from cache... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  FastProp: Building subfeatures... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  FastProp: Building subfeatures... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  FastProp: Building features... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[?25h"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Trained pipeline.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Trained pipeline.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:00:00.518892.\n",
      "\n",
      "\u001b[2K  Staging... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  Preprocessing... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  FastProp: Building subfeatures... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  FastProp: Building subfeatures... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[2K  FastProp: Building features... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% • 00:00\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "fast_prop = getml.feature_learning.FastProp(\n",
    "    loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "    aggregation=best_val_acc_comb[\"agg_set\"],\n",
    "    num_features=best_val_acc_comb[\"num_feat\"],\n",
    ")\n",
    "\n",
    "pipe1.feature_learners = [fast_prop]\n",
    "\n",
    "pipe1.fit(container.train)\n",
    "\n",
    "probs_test = pipe1.predict(container.test)\n",
    "test_acc = prob_to_acc(probs_test, actual_labels_test, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.906\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on the test set: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how **getML**, powered by its **FastProp** feature engineering algorithm and **XGBoost**, surpasses the current state-of-the-art on the CORA dataset. By replicating the data split and hyperparameter optimization methods of Izadi et al., we achieve a record-breaking accuracy of **90.6%**, exceeding their previous benchmark of 90.16%.\n",
    "\n",
    "At the core of this success is **FastProp**, which automates feature creation for relational datasets by efficiently generating statistical and temporal aggregates.\n",
    "\n",
    "This example highlights how cutting-edge performance can be achieved without the need for manual feature engineering or complex GNN-based approaches, enabling faster iteration and greater model interpretability.\n",
    "\n",
    "By incorporating getML into their workflows, data scientists can achieve superior results with less effort, seamlessly combining efficiency with state-of-the-art performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Izadi, Fang, Stevenson, Lin (2020): Optimization of Graph Neural Networks with Natural Gradient Descent   \n",
    "https://arxiv.org/pdf/2008.09624v1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
