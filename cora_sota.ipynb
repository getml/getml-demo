{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous notebooks we have analysed the performance of getML on the CORA dataset, and benchmarked it extensively against alternative approaches. \n",
    "In this short notebook, we demonstrate, how getML outperforms the State of the Art performance with just a little tweak in its configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let some boilerplate code run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing /home/jan-meyer/Documents/gitlab/monorepo/src/python-api\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jinja2 (from getml==1.5.0)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting numpy~=1.22 (from getml==1.5.0)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas (from getml==1.5.0)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pyarrow~=16.0 (from getml==1.5.0)\n",
      "  Using cached pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting rich~=13.0 (from getml==1.5.0)\n",
      "  Using cached rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./.venv/lib/python3.11/site-packages (from getml==1.5.0) (4.12.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich~=13.0->getml==1.5.0)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich~=13.0->getml==1.5.0) (2.18.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->getml==1.5.0)\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->getml==1.5.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->getml==1.5.0)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->getml==1.5.0)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich~=13.0->getml==1.5.0)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->getml==1.5.0) (1.16.0)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: getml\n",
      "  Building wheel for getml (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for getml: filename=getml-1.5.0-py3-none-any.whl size=359647 sha256=a926c8eb049994b8e27b331bfc89b12af4f7934be85685c0e324c46e70031be7\n",
      "  Stored in directory: /home/jan-meyer/.cache/pip/wheels/f9/41/ea/72f967c5d3c155fbc2b69b55fe2cf1d2cdedb226e79aaea439\n",
      "Successfully built getml\n",
      "Installing collected packages: pytz, tzdata, numpy, mdurl, MarkupSafe, pyarrow, pandas, markdown-it-py, jinja2, rich, getml\n",
      "Successfully installed MarkupSafe-2.1.5 getml-1.5.0 jinja2-3.1.4 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.26.4 pandas-2.2.3 pyarrow-16.1.0 pytz-2024.2 rich-13.8.1 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "%pip install -q  \"ipywidgets==8.1.5\"\n",
    "!pip install /home/jan-meyer/Documents/gitlab/monorepo/src/python-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getML API version: 1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import getml\n",
    "\n",
    "print(f\"getML API version: {getml.__version__}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching ./getML --allow-push-notifications=true --allow-remote-ips=true --home-directory=/home/jan-meyer --in-memory=true --install=false --launch-browser=true --log=false --token=token in /home/jan-meyer/.getML/getml-1.5.0-x64-linux...\n",
      "Launched the getML Engine. The log output will be stored in /home/jan-meyer/.getML/logs/20240930155539.log.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Connected to project <span style=\"color: #008000; text-decoration-color: #008000\">'cora_sota'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Connected to project \u001b[32m'cora_sota'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getml.engine.launch(allow_remote_ips=True, token=\"token\")\n",
    "getml.engine.set_project(\"cora_sota\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Connection(dbname='CORA', dialect='mysql', host='db.relational-data.org', port=3306)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = getml.database.connect_mysql(\n",
    "    host=\"db.relational-data.org\",\n",
    "    dbname=\"CORA\",\n",
    "    port=3306,\n",
    "    user=\"guest\",\n",
    "    password=\"relational\",\n",
    ")\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if_needed(name):\n",
    "    \"\"\"\n",
    "    Loads the data from the relational learning\n",
    "    repository, if the data frame has not already\n",
    "    been loaded.\n",
    "    \"\"\"\n",
    "    if not getml.data.exists(name):\n",
    "        data_frame = getml.data.DataFrame.from_db(name=name, table_name=name, conn=conn)\n",
    "        data_frame.save()\n",
    "    else:\n",
    "        data_frame = getml.data.load_data_frame(name)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = load_if_needed(\"paper\")\n",
    "cites = load_if_needed(\"cites\")\n",
    "content = load_if_needed(\"content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we deviate from the regular procedure by introducing the exact same train test split as the [current top seed](https://paperswithcode.com/paper/optimization-of-graph-neural-networks-with). While we contend, that testing on a single split is not sufficient to demonstrate performance of an algorithm on a specific data set, we proceed as such in order to maximize comparability with the current incumbent of the Leader Board. For a more extensive investigation of the getML performance on the CORA dataset, checkout our other notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve the identical split we first need to match papers and their associated word matrix across data sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"assets/zuordnung.txt\"):\n",
    "    from zuordnung import run_zuordnung\n",
    "\n",
    "    # may take 90 minutes or longer to run\n",
    "    run_zuordnung(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"assets/zuordnung.txt\", \"r\")\n",
    "zuordnung = f.read()\n",
    "zuordnung = eval(zuordnung)\n",
    "\n",
    "\n",
    "paper_df = paper.to_pandas()\n",
    "paper_df[\"paper_id\"] = paper_df[\"paper_id\"].astype(int)\n",
    "zuo_df = pd.DataFrame(zuordnung)\n",
    "zuo_df[0] = zuo_df[0].astype(int)\n",
    "paper_df = paper_df.merge(zuo_df, left_on=\"paper_id\", right_on=0).sort_values(by=1)\n",
    "paper_df = paper_df[[\"class_label\", \"paper_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the sorted data set according to the instructions in the GNN paper (see:  IV. Experiments, A. Datasets, third split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_train = getml.data.DataFrame.from_pandas(paper_df[:1707], name=\"train\")\n",
    "paper_val = getml.data.DataFrame.from_pandas(\n",
    "    paper_df[1707 : 1707 + 500], name=\"validation\"\n",
    ")\n",
    "paper_test = getml.data.DataFrame.from_pandas(paper_df[1707 + 500 :], name=\"test\")\n",
    "\n",
    "paper, split = getml.data.split.concat(\n",
    "    \"population\", train=paper_train, validation=paper_val, test=paper_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how the paper proceeded, we let a hyperparameter optimization run, and pick the parameters that perform best on the validation set. The performance on the test set serves as our benchmark value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Prepare data for getML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getML requires that we define *roles* for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "paper.set_role(\"class_label\", getml.data.roles.categorical)\n",
    "cites.set_role([\"cited_paper_id\", \"citing_paper_id\"], getml.data.roles.join_key)\n",
    "content.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "content.set_role(\"word_cited_id\", getml.data.roles.categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict seven different labels. We generate a target column for each of those labels. We also have to separate the data set into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = getml.data.make_target_columns(paper, \"class_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin-top: 15px;'>\n",
       "<div style='float: left; margin-right: 50px;'>\n",
       "<div style='margin-bottom: 10px; font-size: 1rem;'>population</div>\n",
       "    <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">subset    </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">name      </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"int\">rows</th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">type</th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">test</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">500</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">train</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">1708</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">validation</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">500</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div style='float: left;'>\n",
       "<div style='margin-bottom: 10px; font-size: 1rem;'>peripheral</div>\n",
       "    <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">alias  </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">name      </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> rows</th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">type     </th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">5429</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">49216</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">2708</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "population\n",
       "    subset       name         rows   type\n",
       "0   test         population    500   View\n",
       "1   train        population   1708   View\n",
       "2   validation   population    500   View\n",
       "\n",
       "peripheral\n",
       "    alias     name          rows   type     \n",
       "0   cites     cites         5429   DataFrame\n",
       "1   content   content      49216   DataFrame\n",
       "2   paper     population    2708   DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = getml.data.Container(population=data_full, split=split)\n",
    "container.add(cites=cites, content=content, paper=paper)\n",
    "container.freeze()\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive modeling\n",
    "\n",
    "We loaded the data and defined the roles and units. Next, we create a getML pipeline for relational learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define relational model\n",
    "\n",
    "To get started with relational learning, we need to specify the data model. Even though the data set itself is quite simple with only three tables and six columns in total, the resulting data model is actually quite complicated.\n",
    "\n",
    "That is because the class label can be predicting using three different pieces of information:\n",
    "\n",
    "- The keywords used by the paper\n",
    "- The keywords used by papers it cites and by papers that cite the paper\n",
    "- The class label of papers it cites and by papers that cite the paper\n",
    "\n",
    "The main challenge here is that `cites` is used twice, once to connect the _cited_ papers and then to connect the _citing_ papers. To resolve this, we need two placeholders on `cites`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "            <div style='margin-top: 15px; margin-bottom: 5px;'>\n",
       "            <div style='margin-bottom: 10px; font-size: 1rem;'>diagram</div>\n",
       "            <div style=\"height:540px;width:1160px;position:relative;\"><svg height=\"530\" width=\"1150\"><rect y=\"0\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"51\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"10\" x2=\"67.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"10\" x2=\"83.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"26.0\" x2=\"99\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"42.0\" x2=\"99\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"110\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"183.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">paper</text><rect x=\"51\" y=\"120\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"120\" x2=\"67.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"120\" x2=\"83.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"136.0\" x2=\"99\" y2=\"136.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"152.0\" x2=\"99\" y2=\"152.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"110\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"183.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">cites</text><rect x=\"551\" y=\"120\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"120\" x2=\"567.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"120\" x2=\"583.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"136.0\" x2=\"599\" y2=\"136.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"152.0\" x2=\"599\" y2=\"152.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"220\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"293.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"51\" y=\"230\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"230\" x2=\"67.0\" y2=\"278\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"230\" x2=\"83.0\" y2=\"278\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"246.0\" x2=\"99\" y2=\"246.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"262.0\" x2=\"99\" y2=\"262.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"330\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"403.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">paper</text><rect x=\"51\" y=\"340\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"340\" x2=\"67.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"340\" x2=\"83.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"356.0\" x2=\"99\" y2=\"356.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"372.0\" x2=\"99\" y2=\"372.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"330\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"403.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">cites</text><rect x=\"551\" y=\"340\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"340\" x2=\"567.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"340\" x2=\"583.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"356.0\" x2=\"599\" y2=\"356.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"372.0\" x2=\"599\" y2=\"372.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"440\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"513.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"551\" y=\"450\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"450\" x2=\"567.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"450\" x2=\"583.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"466.0\" x2=\"599\" y2=\"466.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"482.0\" x2=\"599\" y2=\"482.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"440\" x=\"1000\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"513.8\" x=\"1075.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">population</text><rect x=\"1051\" y=\"450\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"1067.0\" y1=\"450\" x2=\"1067.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1083.0\" y1=\"450\" x2=\"1083.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1051\" y1=\"466.0\" x2=\"1099\" y2=\"466.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1051\" y1=\"482.0\" x2=\"1099\" y2=\"482.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"150\" y1=\"43.0\" x2=\"573.0\" y2=\"43.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"573.0\" y1=\"41.0\" x2=\"573.0\" y2=\"100\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"573.0, 110 567.0, 100 579.0, 100 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"10.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"45.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = citing_paper_id</tspan></text><line x1=\"150\" y1=\"153.0\" x2=\"490\" y2=\"153.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 153.0 490, 147.0 490, 159.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"120.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"150.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = citing_paper_id</tspan><tspan y=\"160.0\" x=\"324.0\" font-size=\"7pt\" >Relationship: many-to-one</tspan></text><line x1=\"150\" y1=\"263.0\" x2=\"573.0\" y2=\"263.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"573.0\" y1=\"261.0\" x2=\"573.0\" y2=\"320\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"573.0, 330 567.0, 320 579.0, 320 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"230.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"265.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = cited_paper_id</tspan></text><line x1=\"150\" y1=\"373.0\" x2=\"490\" y2=\"373.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 373.0 490, 367.0 490, 379.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"340.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"370.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = cited_paper_id</tspan><tspan y=\"380.0\" x=\"324.0\" font-size=\"7pt\" >Relationship: many-to-one</tspan></text><line x1=\"650\" y1=\"153.0\" x2=\"1073.0\" y2=\"153.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"1073.0\" y1=\"151.0\" x2=\"1073.0\" y2=\"430\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1073.0, 440 1067.0, 430 1079.0, 430 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"120.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"155.0\" x=\"824.0\" font-size=\"7pt\" >cited_paper_id = paper_id</tspan></text><line x1=\"650\" y1=\"373.0\" x2=\"1073.0\" y2=\"373.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"1073.0\" y1=\"371.0\" x2=\"1073.0\" y2=\"430\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1073.0, 440 1067.0, 430 1079.0, 430 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"340.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"375.0\" x=\"824.0\" font-size=\"7pt\" >citing_paper_id = paper_id</tspan></text><line x1=\"650\" y1=\"483.0\" x2=\"990\" y2=\"483.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1000, 483.0 990, 477.0 990, 489.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"450.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"485.0\" x=\"824.0\" font-size=\"7pt\" >paper_id = paper_id</tspan></text></svg></div>\n",
       "            </div>\n",
       "\n",
       "            <div style='margin-top: 15px;'>\n",
       "            <div style='margin-bottom: 10px; font-size: 1rem;'>staging</div>\n",
       "            <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">data frames </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">staging table              </th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">POPULATION__STAGING_TABLE_1</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites, paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CITES__STAGING_TABLE_2</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites, paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CITES__STAGING_TABLE_3</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>3</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CONTENT__STAGING_TABLE_4</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "population:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'cites'\n",
       "    on: (population.paper_id, cites.cited_paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'cites'\n",
       "    on: (population.paper_id, cites.citing_paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'content'\n",
       "    on: (population.paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "\n",
       "cites:\n",
       "  columns:\n",
       "  - cited_paper_id: join_key\n",
       "  - citing_paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'content'\n",
       "    on: (cites.citing_paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'paper'\n",
       "    on: (cites.citing_paper_id, paper.paper_id)\n",
       "    relationship: 'many-to-one'\n",
       "    lagged_targets: False\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "paper:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "cites:\n",
       "  columns:\n",
       "  - cited_paper_id: join_key\n",
       "  - citing_paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'content'\n",
       "    on: (cites.cited_paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'paper'\n",
       "    on: (cites.cited_paper_id, paper.paper_id)\n",
       "    relationship: 'many-to-one'\n",
       "    lagged_targets: False\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "paper:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = getml.data.DataModel(paper.to_placeholder(\"population\"))\n",
    "\n",
    "# We need two different placeholders for cites.\n",
    "dm.add(getml.data.to_placeholder(cites=[cites] * 2, content=content, paper=paper))\n",
    "\n",
    "dm.population.join(dm.cites[0], on=(\"paper_id\", \"cited_paper_id\"))\n",
    "\n",
    "dm.cites[0].join(dm.content, on=(\"citing_paper_id\", \"paper_id\"))\n",
    "\n",
    "dm.cites[0].join(\n",
    "    dm.paper,\n",
    "    on=(\"citing_paper_id\", \"paper_id\"),\n",
    "    relationship=getml.data.relationship.many_to_one,\n",
    ")\n",
    "\n",
    "dm.population.join(dm.cites[1], on=(\"paper_id\", \"citing_paper_id\"))\n",
    "\n",
    "dm.cites[1].join(dm.content, on=(\"cited_paper_id\", \"paper_id\"))\n",
    "\n",
    "dm.cites[1].join(\n",
    "    dm.paper,\n",
    "    on=(\"cited_paper_id\", \"paper_id\"),\n",
    "    relationship=getml.data.relationship.many_to_one,\n",
    ")\n",
    "\n",
    "dm.population.join(dm.content, on=\"paper_id\")\n",
    "\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hyperparameter Search\n",
    "To mimic the approach of the GNN paper, we conduct a small Hyperparameter search, training on the train data, validate on the validate data and use the untouched test data as holdout set to get an unbiased estimate of the true performance.\n",
    "For expediency, we make a grit search along two dimensions and keep the number of levels deliberately small:\n",
    " \n",
    "    num_features: 250, 300, 350\n",
    "    built-in aggregation sets: minimal, default, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = getml.preprocessors.Mapping()\n",
    "predictor = getml.predictors.XGBoostClassifier()\n",
    "\n",
    "actual_labels_val = paper[split == \"validation\"].class_label.to_numpy()\n",
    "actual_labels_test = paper[split == \"test\"].class_label.to_numpy()\n",
    "class_label = paper.class_label.unique()\n",
    "\n",
    "pipe1 = getml.pipeline.Pipeline(\n",
    "    data_model=dm, preprocessors=[mapping], predictors=[predictor]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_acc(prob, actual_labels, class_label) -> float:\n",
    "    ix_max = np.argmax(prob, axis=1)\n",
    "    predicted_labels = np.asarray([class_label[ix] for ix in ix_max])\n",
    "    return (actual_labels == predicted_labels).sum() / len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "parameter_sweep = {}\n",
    "i = 0\n",
    "for num_feat in [250, 300, 350]:\n",
    "    for aggregation_set in [\n",
    "        getml.feature_learning.aggregations.FASTPROP.Minimal,\n",
    "        getml.feature_learning.aggregations.FASTPROP.Default,\n",
    "        getml.feature_learning.aggregations.FASTPROP.All,\n",
    "    ]:\n",
    "        fast_prop = getml.feature_learning.FastProp(\n",
    "            loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "            aggregation=aggregation_set,\n",
    "            num_features=num_feat,\n",
    "        )\n",
    "\n",
    "        pipe1.feature_learners = [fast_prop]\n",
    "\n",
    "        pipe1.fit(container.train)\n",
    "\n",
    "        probs_val = pipe1.predict(container.validation)\n",
    "        val_acc = prob_to_acc(probs_val, actual_labels_val, class_label)\n",
    "\n",
    "        parameter_sweep[i] = {\n",
    "            \"num_feat\": num_feat,\n",
    "            \"agg_set\": aggregation_set,\n",
    "            \"val_acc\": val_acc,\n",
    "        }\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc_comb = list(\n",
    "    sorted(parameter_sweep.items(), key=lambda item: item[1][\"val_acc\"], reverse=True)\n",
    ")[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.874\n",
      "Number of features used: 300\n",
      "Aggregation set used: frozenset({'AVG', 'MIN', 'MAX', 'SUM', 'COUNT'})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on validation set: {best_val_acc_comb['val_acc']}\")\n",
    "print(f\"Number of features used: {best_val_acc_comb['num_feat']}\")\n",
    "print(f\"Aggregation set used: {best_val_acc_comb['agg_set']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we identified the parameter combination that yields the highest accuracy on the validation set, let's use the same parameters on the hold out data to attain an unbiased estimate of the model's predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Checking data model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Checking data model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124a185842c4456aae45e21aeaa24d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The pipeline check generated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> issues labeled INFO and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> issues labeled WARNING.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The pipeline check generated \u001b[1;36m3\u001b[0m issues labeled INFO and \u001b[1;36m0\u001b[0m issues labeled WARNING.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To see the issues in full, run <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.check</span><span style=\"font-weight: bold\">()</span> on the pipeline.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "To see the issues in full, run \u001b[1;35m.check\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m on the pipeline.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33d37208b4e41ec970c400a988d3505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Trained pipeline.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Trained pipeline.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:00:01.034566.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2746ffa55ef84a32a93888ef3938ea84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast_prop = getml.feature_learning.FastProp(\n",
    "    loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "    aggregation=best_val_acc_comb[\"agg_set\"],\n",
    "    num_features=best_val_acc_comb[\"num_feat\"],\n",
    ")\n",
    "\n",
    "pipe1.feature_learners = [fast_prop]\n",
    "\n",
    "pipe1.fit(container.train)\n",
    "\n",
    "probs_test = pipe1.predict(container.test)\n",
    "test_acc = prob_to_acc(probs_test, actual_labels_test, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.906\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on the test set: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook sought out to attain a new record predictive performance on the well known Cora data set by using exclusively getML's feature learning framework. To maximize comparability we mimicked the methodology of the current record holder.\n",
    "\n",
    "We replicated the exact split used in their research paper and we ran a hyperparameter similar to how they did.\n",
    "On the hold out data set we achieved an accuracy of 90.6% which compares favorably to the 90.16% of the hitherto record holder. Hence our approach can now be considered the new state-of-the-art solution on this popular benchmarking data set.\n",
    "\n",
    "Remarkable is the ease of implementation. Requiring only minimal tweaking of parameters, getML beat an advanced Graph Neural Network algorithm. Cutting edge predictive performance is now within reach of every Data Scientist by simply incorporating getML in their prediction pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3,\n",
       "  {'num_feat': 300,\n",
       "   'agg_set': frozenset({'AVG', 'COUNT', 'MAX', 'MIN', 'SUM'}),\n",
       "   'val_acc': 0.874}),\n",
       " (6,\n",
       "  {'num_feat': 350,\n",
       "   'agg_set': frozenset({'AVG', 'COUNT', 'MAX', 'MIN', 'SUM'}),\n",
       "   'val_acc': 0.874}),\n",
       " (0,\n",
       "  {'num_feat': 250,\n",
       "   'agg_set': frozenset({'AVG', 'COUNT', 'MAX', 'MIN', 'SUM'}),\n",
       "   'val_acc': 0.872}),\n",
       " (4,\n",
       "  {'num_feat': 300,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'FIRST',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TREND'}),\n",
       "   'val_acc': 0.87}),\n",
       " (7,\n",
       "  {'num_feat': 350,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'FIRST',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TREND'}),\n",
       "   'val_acc': 0.866}),\n",
       " (1,\n",
       "  {'num_feat': 250,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'FIRST',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TREND'}),\n",
       "   'val_acc': 0.864}),\n",
       " (5,\n",
       "  {'num_feat': 300,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT DISTINCT OVER COUNT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'EWMA_1D',\n",
       "              'EWMA_1H',\n",
       "              'EWMA_1M',\n",
       "              'EWMA_1S',\n",
       "              'EWMA_30D',\n",
       "              'EWMA_365D',\n",
       "              'EWMA_7D',\n",
       "              'EWMA_90D',\n",
       "              'EWMA_TREND_1D',\n",
       "              'EWMA_TREND_1H',\n",
       "              'EWMA_TREND_1M',\n",
       "              'EWMA_TREND_1S',\n",
       "              'EWMA_TREND_30D',\n",
       "              'EWMA_TREND_365D',\n",
       "              'EWMA_TREND_7D',\n",
       "              'EWMA_TREND_90D',\n",
       "              'FIRST',\n",
       "              'KURTOSIS',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'NUM MAX',\n",
       "              'NUM MIN',\n",
       "              'Q1',\n",
       "              'Q10',\n",
       "              'Q25',\n",
       "              'Q5',\n",
       "              'Q75',\n",
       "              'Q90',\n",
       "              'Q95',\n",
       "              'Q99',\n",
       "              'SKEW',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TIME SINCE FIRST MAXIMUM',\n",
       "              'TIME SINCE FIRST MINIMUM',\n",
       "              'TIME SINCE LAST MAXIMUM',\n",
       "              'TIME SINCE LAST MINIMUM',\n",
       "              'TREND',\n",
       "              'VAR',\n",
       "              'VARIATION COEFFICIENT'}),\n",
       "   'val_acc': 0.862}),\n",
       " (8,\n",
       "  {'num_feat': 350,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT DISTINCT OVER COUNT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'EWMA_1D',\n",
       "              'EWMA_1H',\n",
       "              'EWMA_1M',\n",
       "              'EWMA_1S',\n",
       "              'EWMA_30D',\n",
       "              'EWMA_365D',\n",
       "              'EWMA_7D',\n",
       "              'EWMA_90D',\n",
       "              'EWMA_TREND_1D',\n",
       "              'EWMA_TREND_1H',\n",
       "              'EWMA_TREND_1M',\n",
       "              'EWMA_TREND_1S',\n",
       "              'EWMA_TREND_30D',\n",
       "              'EWMA_TREND_365D',\n",
       "              'EWMA_TREND_7D',\n",
       "              'EWMA_TREND_90D',\n",
       "              'FIRST',\n",
       "              'KURTOSIS',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'NUM MAX',\n",
       "              'NUM MIN',\n",
       "              'Q1',\n",
       "              'Q10',\n",
       "              'Q25',\n",
       "              'Q5',\n",
       "              'Q75',\n",
       "              'Q90',\n",
       "              'Q95',\n",
       "              'Q99',\n",
       "              'SKEW',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TIME SINCE FIRST MAXIMUM',\n",
       "              'TIME SINCE FIRST MINIMUM',\n",
       "              'TIME SINCE LAST MAXIMUM',\n",
       "              'TIME SINCE LAST MINIMUM',\n",
       "              'TREND',\n",
       "              'VAR',\n",
       "              'VARIATION COEFFICIENT'}),\n",
       "   'val_acc': 0.854}),\n",
       " (2,\n",
       "  {'num_feat': 250,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT DISTINCT OVER COUNT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'EWMA_1D',\n",
       "              'EWMA_1H',\n",
       "              'EWMA_1M',\n",
       "              'EWMA_1S',\n",
       "              'EWMA_30D',\n",
       "              'EWMA_365D',\n",
       "              'EWMA_7D',\n",
       "              'EWMA_90D',\n",
       "              'EWMA_TREND_1D',\n",
       "              'EWMA_TREND_1H',\n",
       "              'EWMA_TREND_1M',\n",
       "              'EWMA_TREND_1S',\n",
       "              'EWMA_TREND_30D',\n",
       "              'EWMA_TREND_365D',\n",
       "              'EWMA_TREND_7D',\n",
       "              'EWMA_TREND_90D',\n",
       "              'FIRST',\n",
       "              'KURTOSIS',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'NUM MAX',\n",
       "              'NUM MIN',\n",
       "              'Q1',\n",
       "              'Q10',\n",
       "              'Q25',\n",
       "              'Q5',\n",
       "              'Q75',\n",
       "              'Q90',\n",
       "              'Q95',\n",
       "              'Q99',\n",
       "              'SKEW',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TIME SINCE FIRST MAXIMUM',\n",
       "              'TIME SINCE FIRST MINIMUM',\n",
       "              'TIME SINCE LAST MAXIMUM',\n",
       "              'TIME SINCE LAST MINIMUM',\n",
       "              'TREND',\n",
       "              'VAR',\n",
       "              'VARIATION COEFFICIENT'}),\n",
       "   'val_acc': 0.848})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    sorted(parameter_sweep.items(), key=lambda item: item[1][\"val_acc\"], reverse=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
