{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent years have shown an incredible proliferation of sophisticated Machine Learning algorithms. Keeping up with that development has become a full time job. Wouldn't it be nice to have a tool that fits all and still provides cutting edge results?! Look no further: getML to the rescue!\n",
    "\n",
    "In previous notebooks we have analysed the performance of getML on the CORA dataset, and benchmarked it extensively against alternative approaches. \n",
    "In this short notebook, we demonstrate, how getML outperforms the State of the Art performance with just a little tweak in its configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let some boilerplate code run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing /home/jan-meyer/Documents/gitlab/monorepo/src/python-api\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jinja2 (from getml==1.5.0)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting numpy~=1.22 (from getml==1.5.0)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas (from getml==1.5.0)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pyarrow~=16.0 (from getml==1.5.0)\n",
      "  Using cached pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting rich~=13.0 (from getml==1.5.0)\n",
      "  Using cached rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./.venv/lib/python3.11/site-packages (from getml==1.5.0) (4.12.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich~=13.0->getml==1.5.0)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich~=13.0->getml==1.5.0) (2.18.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->getml==1.5.0)\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->getml==1.5.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->getml==1.5.0)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->getml==1.5.0)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich~=13.0->getml==1.5.0)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->getml==1.5.0) (1.16.0)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: getml\n",
      "  Building wheel for getml (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for getml: filename=getml-1.5.0-py3-none-any.whl size=361543 sha256=8c3bd51ffa562e7155202fdf5f34a2c2a30b03798672483adbd5f40e9cccbdeb\n",
      "  Stored in directory: /home/jan-meyer/.cache/pip/wheels/f9/41/ea/72f967c5d3c155fbc2b69b55fe2cf1d2cdedb226e79aaea439\n",
      "Successfully built getml\n",
      "Installing collected packages: pytz, tzdata, numpy, mdurl, MarkupSafe, pyarrow, pandas, markdown-it-py, jinja2, rich, getml\n",
      "Successfully installed MarkupSafe-2.1.5 getml-1.5.0 jinja2-3.1.4 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.26.4 pandas-2.2.3 pyarrow-16.1.0 pytz-2024.2 rich-13.8.1 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"ipywidgets==8.1.5\"\n",
    "!pip install /home/jan-meyer/Documents/gitlab/monorepo/src/python-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getML API version: 1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import getml\n",
    "\n",
    "print(f\"getML API version: {getml.__version__}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not find getML executable in any of the following locations:\n['/home/jan-meyer/.getML', '/usr/local/getML', '/home/jan-meyer/Documents/github/getml-demo/.venv/lib/python3.11/site-packages/getml/.getML']\n\nRefer to the installation documentation for more information:\nhttps://getml.com/latest/install/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#getml.engine.shutdown()|\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgetml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallow_remote_ips\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m getml\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mset_project(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcora_sota\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/github/getml-demo/.venv/lib/python3.11/site-packages/getml/engine/_launch.py:274\u001b[0m, in \u001b[0;36mlaunch\u001b[0;34m(allow_push_notifications, allow_remote_ips, home_directory, http_port, in_memory, install, launch_browser, log, project_directory, proxy_url, token, quiet)\u001b[0m\n\u001b[1;32m    272\u001b[0m executable_path \u001b[38;5;241m=\u001b[39m locate_executable()\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m executable_path:\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    275\u001b[0m         COULD_NOT_FIND_EXECUTABLE_ERROR_MSG_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    276\u001b[0m             install_locations\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m INSTALL_LOCATIONS],\n\u001b[1;32m    277\u001b[0m             install_docs_url\u001b[38;5;241m=\u001b[39mINSTALL_DOCS_URL,\n\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m getml_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    281\u001b[0m     Path(home_directory) \u001b[38;5;28;01mif\u001b[39;00m home_directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m Path\u001b[38;5;241m.\u001b[39mhome() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.getML\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m )\n\u001b[1;32m    283\u001b[0m project_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    284\u001b[0m     Path(project_directory)\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m project_directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m getml_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m )\n",
      "\u001b[0;31mOSError\u001b[0m: Could not find getML executable in any of the following locations:\n['/home/jan-meyer/.getML', '/usr/local/getML', '/home/jan-meyer/Documents/github/getml-demo/.venv/lib/python3.11/site-packages/getml/.getML']\n\nRefer to the installation documentation for more information:\nhttps://getml.com/latest/install/"
     ]
    }
   ],
   "source": [
    "#getml.engine.shutdown()|\n",
    "getml.engine.launch(allow_remote_ips=True, token=\"token\")\n",
    "getml.engine.set_project(\"cora_sota\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Connection(dbname='CORA', dialect='mysql', host='db.relational-data.org', port=3306)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = getml.database.connect_mysql(\n",
    "    host=\"db.relational-data.org\",\n",
    "    dbname=\"CORA\",\n",
    "    port=3306,\n",
    "    user=\"guest\",\n",
    "    password=\"relational\",\n",
    ")\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if_needed(name):\n",
    "    \"\"\"\n",
    "    Loads the data from the relational learning\n",
    "    repository, if the data frame has not already\n",
    "    been loaded.\n",
    "    \"\"\"\n",
    "    if not getml.data.exists(name):\n",
    "        data_frame = getml.data.DataFrame.from_db(name=name, table_name=name, conn=conn)\n",
    "        data_frame.save()\n",
    "    else:\n",
    "        data_frame = getml.data.load_data_frame(name)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = load_if_needed(\"paper\")\n",
    "cites = load_if_needed(\"cites\")\n",
    "content = load_if_needed(\"content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we deviate from the regular procedure by introducing the exact same train test split as the [current top seed](https://paperswithcode.com/paper/optimization-of-graph-neural-networks-with). While we contend, that testing on a single split is not sufficient to demonstrate performance of an algorithm on a specific data set, we proceed as such in order to maximize comparability with the current incumbent of the Leader Board. For a more extensive investigation of the getML performance on the CORA dataset, checkout our other notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve the identical split we first need to match papers and their associated word matrix across data sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"assets/zuordnung.txt\"):\n",
    "    from zuordnung import run_zuordnung\n",
    "\n",
    "    # may take 90 minutes or longer to run\n",
    "    run_zuordnung(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"assets/zuordnung.txt\", \"r\")\n",
    "zuordnung = f.read()\n",
    "zuordnung = eval(zuordnung)\n",
    "\n",
    "\n",
    "paper_df = paper.to_pandas()\n",
    "paper_df[\"paper_id\"] = paper_df[\"paper_id\"].astype(int)\n",
    "zuo_df = pd.DataFrame(zuordnung)\n",
    "zuo_df[0] = zuo_df[0].astype(int)\n",
    "paper_df = paper_df.merge(zuo_df, left_on=\"paper_id\", right_on=0).sort_values(by=1)\n",
    "paper_df = paper_df[[\"class_label\", \"paper_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the sorted data set according to the instructions in the GNN paper (see:  IV. Experiments, A. Datasets, third split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_train = getml.data.DataFrame.from_pandas(paper_df[:1707], name=\"train\")\n",
    "paper_val = getml.data.DataFrame.from_pandas(\n",
    "    paper_df[1707 : 1707 + 500], name=\"validation\"\n",
    ")\n",
    "paper_test = getml.data.DataFrame.from_pandas(paper_df[1707 + 500 :], name=\"test\")\n",
    "\n",
    "paper, split = getml.data.split.concat(\n",
    "    \"population\", train=paper_train, validation=paper_val, test=paper_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the approach in the paper, we perform hyperparameter optimization and select the parameters that perform best on the validation set. The performance on the test set serves as our benchmark value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Prepare data for getML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getML requires that we define *roles* for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "paper.set_role(\"class_label\", getml.data.roles.categorical)\n",
    "cites.set_role([\"cited_paper_id\", \"citing_paper_id\"], getml.data.roles.join_key)\n",
    "content.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "content.set_role(\"word_cited_id\", getml.data.roles.categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict seven different labels. We generate a target column for each of those labels. We also have to separate the data set into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = getml.data.make_target_columns(paper, \"class_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin-top: 15px;'>\n",
       "<div style='float: left; margin-right: 50px;'>\n",
       "<div style='margin-bottom: 10px; font-size: 1rem;'>population</div>\n",
       "    <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">subset    </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">name      </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"int\">rows</th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">type</th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">test</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">500</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">train</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">1708</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">validation</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">500</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">View</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div style='float: left;'>\n",
       "<div style='margin-bottom: 10px; font-size: 1rem;'>peripheral</div>\n",
       "    <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">alias  </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">name      </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> rows</th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">type     </th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">5429</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">49216</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"int\">2708</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">DataFrame</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "population\n",
       "    subset       name         rows   type\n",
       "0   test         population    500   View\n",
       "1   train        population   1708   View\n",
       "2   validation   population    500   View\n",
       "\n",
       "peripheral\n",
       "    alias     name          rows   type     \n",
       "0   cites     cites         5429   DataFrame\n",
       "1   content   content      49216   DataFrame\n",
       "2   paper     population    2708   DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = getml.data.Container(population=data_full, split=split)\n",
    "container.add(cites=cites, content=content, paper=paper)\n",
    "container.freeze()\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive modeling\n",
    "\n",
    "We loaded the data and defined the roles and units. Next, we create a getML pipeline for relational learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define relational model\n",
    "\n",
    "To get started with relational learning, we need to specify the data model. Even though the data set itself is quite simple with only three tables and six columns in total, the resulting data model is actually quite complicated.\n",
    "\n",
    "That is because the class label can be predicting using three different pieces of information:\n",
    "\n",
    "- The keywords used by the paper\n",
    "- The keywords used by papers it cites and by papers that cite the paper\n",
    "- The class label of papers it cites and by papers that cite the paper\n",
    "\n",
    "The main challenge here is that `cites` is used twice, once to connect the _cited_ papers and then to connect the _citing_ papers. To resolve this, we need two placeholders on `cites`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "            <div style='margin-top: 15px; margin-bottom: 5px;'>\n",
       "            <div style='margin-bottom: 10px; font-size: 1rem;'>diagram</div>\n",
       "            <div style=\"height:540px;width:1160px;position:relative;\"><svg height=\"530\" width=\"1150\"><rect y=\"0\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"73.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"51\" y=\"10\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"10\" x2=\"67.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"10\" x2=\"83.0\" y2=\"58\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"26.0\" x2=\"99\" y2=\"26.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"42.0\" x2=\"99\" y2=\"42.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"110\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"183.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">paper</text><rect x=\"51\" y=\"120\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"120\" x2=\"67.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"120\" x2=\"83.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"136.0\" x2=\"99\" y2=\"136.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"152.0\" x2=\"99\" y2=\"152.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"110\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"183.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">cites</text><rect x=\"551\" y=\"120\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"120\" x2=\"567.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"120\" x2=\"583.0\" y2=\"168\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"136.0\" x2=\"599\" y2=\"136.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"152.0\" x2=\"599\" y2=\"152.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"220\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"293.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"51\" y=\"230\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"230\" x2=\"67.0\" y2=\"278\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"230\" x2=\"83.0\" y2=\"278\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"246.0\" x2=\"99\" y2=\"246.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"262.0\" x2=\"99\" y2=\"262.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"330\" x=\"0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"403.8\" x=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">paper</text><rect x=\"51\" y=\"340\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"67.0\" y1=\"340\" x2=\"67.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"83.0\" y1=\"340\" x2=\"83.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"356.0\" x2=\"99\" y2=\"356.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"51\" y1=\"372.0\" x2=\"99\" y2=\"372.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"330\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"403.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">cites</text><rect x=\"551\" y=\"340\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"340\" x2=\"567.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"340\" x2=\"583.0\" y2=\"388\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"356.0\" x2=\"599\" y2=\"356.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"372.0\" x2=\"599\" y2=\"372.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"440\" x=\"500\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"513.8\" x=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">content</text><rect x=\"551\" y=\"450\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"567.0\" y1=\"450\" x2=\"567.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"583.0\" y1=\"450\" x2=\"583.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"466.0\" x2=\"599\" y2=\"466.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"551\" y1=\"482.0\" x2=\"599\" y2=\"482.0\" style=\"stroke:white;stroke-width:3\" /><rect y=\"440\" x=\"1000\" rx=\"10\" ry=\"10\" width=\"150\" height=\"90\" style=\"fill:#6829c2;stroke-width:0;\" /><text y=\"513.8\" x=\"1075.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\">population</text><rect x=\"1051\" y=\"450\" rx=\"4\" ry=\"4\" width=\"48\" height=\"48\" style=\" fill:#6829c2;stroke:#ffffff;stroke-width:3;\" /><line x1=\"1067.0\" y1=\"450\" x2=\"1067.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1083.0\" y1=\"450\" x2=\"1083.0\" y2=\"498\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1051\" y1=\"466.0\" x2=\"1099\" y2=\"466.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"1051\" y1=\"482.0\" x2=\"1099\" y2=\"482.0\" style=\"stroke:white;stroke-width:3\" /><line x1=\"150\" y1=\"43.0\" x2=\"573.0\" y2=\"43.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"573.0\" y1=\"41.0\" x2=\"573.0\" y2=\"100\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"573.0, 110 567.0, 100 579.0, 100 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"10.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"45.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = citing_paper_id</tspan></text><line x1=\"150\" y1=\"153.0\" x2=\"490\" y2=\"153.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 153.0 490, 147.0 490, 159.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"120.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"150.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = citing_paper_id</tspan><tspan y=\"160.0\" x=\"324.0\" font-size=\"7pt\" >Relationship: many-to-one</tspan></text><line x1=\"150\" y1=\"263.0\" x2=\"573.0\" y2=\"263.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"573.0\" y1=\"261.0\" x2=\"573.0\" y2=\"320\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"573.0, 330 567.0, 320 579.0, 320 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"230.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"265.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = cited_paper_id</tspan></text><line x1=\"150\" y1=\"373.0\" x2=\"490\" y2=\"373.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"500, 373.0 490, 367.0 490, 379.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"340.0\" x=\"249.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"370.0\" x=\"324.0\" font-size=\"7pt\" >paper_id = cited_paper_id</tspan><tspan y=\"380.0\" x=\"324.0\" font-size=\"7pt\" >Relationship: many-to-one</tspan></text><line x1=\"650\" y1=\"153.0\" x2=\"1073.0\" y2=\"153.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"1073.0\" y1=\"151.0\" x2=\"1073.0\" y2=\"430\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1073.0, 440 1067.0, 430 1079.0, 430 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"120.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"155.0\" x=\"824.0\" font-size=\"7pt\" >cited_paper_id = paper_id</tspan></text><line x1=\"650\" y1=\"373.0\" x2=\"1073.0\" y2=\"373.0\" style=\"stroke:#808080;;stroke-width:4\" /><line x1=\"1073.0\" y1=\"371.0\" x2=\"1073.0\" y2=\"430\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1073.0, 440 1067.0, 430 1079.0, 430 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"340.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"375.0\" x=\"824.0\" font-size=\"7pt\" >citing_paper_id = paper_id</tspan></text><line x1=\"650\" y1=\"483.0\" x2=\"990\" y2=\"483.0\" style=\"stroke:#808080;;stroke-width:4\" /><polygon points=\"1000, 483.0 990, 477.0 990, 489.0 \" style=\"fill:#808080;;stroke-width:0;\" /><rect y=\"450.0\" x=\"749.0\" rx=\"10\" ry=\"10\" width=\"150\" height=\"70\" style=\"fill:#6829c2;stroke-width:0;\" /><text dominant-baseline=\"middle\" text-anchor=\"middle\" fill=\"white\"><tspan y=\"485.0\" x=\"824.0\" font-size=\"7pt\" >paper_id = paper_id</tspan></text></svg></div>\n",
       "            </div>\n",
       "\n",
       "            <div style='margin-top: 15px;'>\n",
       "            <div style='margin-bottom: 10px; font-size: 1rem;'>staging</div>\n",
       "            <style>\n",
       "  th {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  td {\n",
       "    text-align: left !important;\n",
       "  }\n",
       "  th:nth-child(1) {\n",
       "    text-align: right;\n",
       "    border-right: 1px solid LightGray;\n",
       "  }\n",
       "  th.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.float {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  th.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "  td.int {\n",
       "    text-align: right !important;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "<table class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      \n",
       "        \n",
       "          <th class=\"int\"> </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">data frames </th>\n",
       "        \n",
       "      \n",
       "        \n",
       "          <th class=\"str\">staging table              </th>\n",
       "        \n",
       "      \n",
       "    </tr>\n",
       "    \n",
       "  </thead>\n",
       "  <tbody>\n",
       "    \n",
       "      <tr>\n",
       "        <th>0</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">population</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">POPULATION__STAGING_TABLE_1</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>1</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites, paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CITES__STAGING_TABLE_2</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>2</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">cites, paper</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CITES__STAGING_TABLE_3</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "      <tr>\n",
       "        <th>3</th>\n",
       "          \n",
       "            \n",
       "              <td class=\"str\">content</td>\n",
       "            \n",
       "          \n",
       "            \n",
       "              <td class=\"str\">CONTENT__STAGING_TABLE_4</td>\n",
       "            \n",
       "          \n",
       "      </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "population:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'cites'\n",
       "    on: \n",
       "    - (population.paper_id, cites.cited_paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'cites'\n",
       "    on: \n",
       "    - (population.paper_id, cites.citing_paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'content'\n",
       "    on: \n",
       "    - (population.paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "\n",
       "cites:\n",
       "  columns:\n",
       "  - cited_paper_id: join_key\n",
       "  - citing_paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'content'\n",
       "    on: \n",
       "    - (cites.citing_paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'paper'\n",
       "    on: \n",
       "    - (cites.citing_paper_id, paper.paper_id)\n",
       "    relationship: 'many-to-one'\n",
       "    lagged_targets: False\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "paper:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "cites:\n",
       "  columns:\n",
       "  - cited_paper_id: join_key\n",
       "  - citing_paper_id: join_key\n",
       "\n",
       "  joins:\n",
       "  - right: 'content'\n",
       "    on: \n",
       "    - (cites.cited_paper_id, content.paper_id)\n",
       "    relationship: 'many-to-many'\n",
       "    lagged_targets: False\n",
       "  - right: 'paper'\n",
       "    on: \n",
       "    - (cites.cited_paper_id, paper.paper_id)\n",
       "    relationship: 'many-to-one'\n",
       "    lagged_targets: False\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "paper:\n",
       "  columns:\n",
       "  - class_label: categorical\n",
       "  - paper_id: join_key\n",
       "\n",
       "content:\n",
       "  columns:\n",
       "  - word_cited_id: categorical\n",
       "  - paper_id: join_key"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = getml.data.DataModel(paper.to_placeholder(\"population\"))\n",
    "\n",
    "# We need two different placeholders for cites.\n",
    "dm.add(getml.data.to_placeholder(cites=[cites] * 2, content=content, paper=paper))\n",
    "\n",
    "dm.population.join(dm.cites[0], on=(\"paper_id\", \"cited_paper_id\"))\n",
    "\n",
    "dm.cites[0].join(dm.content, on=(\"citing_paper_id\", \"paper_id\"))\n",
    "\n",
    "dm.cites[0].join(\n",
    "    dm.paper,\n",
    "    on=(\"citing_paper_id\", \"paper_id\"),\n",
    "    relationship=getml.data.relationship.many_to_one,\n",
    ")\n",
    "\n",
    "dm.population.join(dm.cites[1], on=(\"paper_id\", \"citing_paper_id\"))\n",
    "\n",
    "dm.cites[1].join(dm.content, on=(\"cited_paper_id\", \"paper_id\"))\n",
    "\n",
    "dm.cites[1].join(\n",
    "    dm.paper,\n",
    "    on=(\"cited_paper_id\", \"paper_id\"),\n",
    "    relationship=getml.data.relationship.many_to_one,\n",
    ")\n",
    "\n",
    "dm.population.join(dm.content, on=\"paper_id\")\n",
    "\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hyperparameter Search\n",
    "To mimic the approach of the GNN paper, we conduct a small Hyperparameter search, training on the train data, validate on the validate data and use the untouched test data as holdout set to get an unbiased estimate of the true performance.\n",
    "For expediency, we make a grit search along two dimensions and keep the number of levels deliberately small:\n",
    " \n",
    "    num_features: 250, 300, 350\n",
    "    built-in aggregation sets: minimal, default, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = getml.preprocessors.Mapping()\n",
    "predictor = getml.predictors.XGBoostClassifier()\n",
    "\n",
    "actual_labels_val = paper[split == \"validation\"].class_label.to_numpy()\n",
    "actual_labels_test = paper[split == \"test\"].class_label.to_numpy()\n",
    "class_label = paper.class_label.unique()\n",
    "\n",
    "pipe1 = getml.pipeline.Pipeline(\n",
    "    data_model=dm, preprocessors=[mapping], predictors=[predictor]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_to_acc(prob, actual_labels, class_label) -> float:\n",
    "    ix_max = np.argmax(prob, axis=1)\n",
    "    predicted_labels = np.asarray([class_label[ix] for ix in ix_max])\n",
    "    return (actual_labels == predicted_labels).sum() / len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "The Mapping preprocessor is not supported in the community edition. Please upgrade to getML enterprise to use this. An overview of what is supported in the community edition can be found in the official getML documentation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m fast_prop \u001b[38;5;241m=\u001b[39m getml\u001b[38;5;241m.\u001b[39mfeature_learning\u001b[38;5;241m.\u001b[39mFastProp(\n\u001b[1;32m     10\u001b[0m     loss_function\u001b[38;5;241m=\u001b[39mgetml\u001b[38;5;241m.\u001b[39mfeature_learning\u001b[38;5;241m.\u001b[39mloss_functions\u001b[38;5;241m.\u001b[39mCrossEntropyLoss,\n\u001b[1;32m     11\u001b[0m     aggregation\u001b[38;5;241m=\u001b[39maggregation_set,\n\u001b[1;32m     12\u001b[0m     num_features\u001b[38;5;241m=\u001b[39mnum_feat,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m pipe1\u001b[38;5;241m.\u001b[39mfeature_learners \u001b[38;5;241m=\u001b[39m [fast_prop]\n\u001b[0;32m---> 17\u001b[0m \u001b[43mpipe1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m probs_val \u001b[38;5;241m=\u001b[39m pipe1\u001b[38;5;241m.\u001b[39mpredict(container\u001b[38;5;241m.\u001b[39mvalidation)\n\u001b[1;32m     20\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m prob_to_acc(probs_val, actual_labels_val, class_label)\n",
      "File \u001b[0;32m~/Documents/github/getml-demo/.venv/lib/python3.11/site-packages/getml/pipeline/pipeline.py:1295\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, population_table, peripheral_tables, validation_table, check)\u001b[0m\n\u001b[1;32m   1292\u001b[0m _check_df_types(population_table, peripheral_tables)\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check:\n\u001b[0;32m-> 1295\u001b[0m     warnings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperipheral_tables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warnings:\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo see the issues in full, run .check() on the pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/github/getml-demo/.venv/lib/python3.11/site-packages/getml/pipeline/pipeline.py:1106\u001b[0m, in \u001b[0;36mPipeline.check\u001b[0;34m(self, population_table, peripheral_tables)\u001b[0m\n\u001b[1;32m   1104\u001b[0m msg \u001b[38;5;241m=\u001b[39m comm\u001b[38;5;241m.\u001b[39mlog(sock)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccess!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1106\u001b[0m     \u001b[43mcomm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_engine_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m issues \u001b[38;5;241m=\u001b[39m Issues(comm\u001b[38;5;241m.\u001b[39mrecv_issues(sock))\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(issues) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/github/getml-demo/.venv/lib/python3.11/site-packages/getml/exceptions.py:148\u001b[0m, in \u001b[0;36mhandle_engine_exception\u001b[0;34m(msg, extra)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m EngineExceptionHandlerRegistry\u001b[38;5;241m.\u001b[39mhandlers:\n\u001b[1;32m    146\u001b[0m     handler(msg, extra\u001b[38;5;241m=\u001b[39mextra)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n",
      "\u001b[0;31mOSError\u001b[0m: The Mapping preprocessor is not supported in the community edition. Please upgrade to getML enterprise to use this. An overview of what is supported in the community edition can be found in the official getML documentation."
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "parameter_sweep = {}\n",
    "i = 0\n",
    "for num_feat in [250, 300, 350]:\n",
    "    for aggregation_set in [\n",
    "        getml.feature_learning.aggregations.FASTPROP.Minimal,\n",
    "        getml.feature_learning.aggregations.FASTPROP.Default,\n",
    "        getml.feature_learning.aggregations.FASTPROP.All,\n",
    "    ]:\n",
    "        fast_prop = getml.feature_learning.FastProp(\n",
    "            loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "            aggregation=aggregation_set,\n",
    "            num_features=num_feat,\n",
    "        )\n",
    "\n",
    "        pipe1.feature_learners = [fast_prop]\n",
    "\n",
    "        pipe1.fit(container.train)\n",
    "\n",
    "        probs_val = pipe1.predict(container.validation)\n",
    "        val_acc = prob_to_acc(probs_val, actual_labels_val, class_label)\n",
    "\n",
    "        parameter_sweep[i] = {\n",
    "            \"num_feat\": num_feat,\n",
    "            \"agg_set\": aggregation_set,\n",
    "            \"val_acc\": val_acc,\n",
    "        }\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_val_acc_comb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparameter_sweep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_acc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "best_val_acc_comb = list(\n",
    "    sorted(parameter_sweep.items(), key=lambda item: item[1][\"val_acc\"], reverse=True)\n",
    ")[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.874\n",
      "Number of features used: 300\n",
      "Aggregation set used: frozenset({'AVG', 'MIN', 'MAX', 'SUM', 'COUNT'})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on validation set: {best_val_acc_comb['val_acc']}\")\n",
    "print(f\"Number of features used: {best_val_acc_comb['num_feat']}\")\n",
    "print(f\"Aggregation set used: {best_val_acc_comb['agg_set']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as we identified the parameter combination that yields the highest accuracy on the validation set, let's use the same parameters on the hold out data to attain an unbiased estimate of the model's predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Checking data model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Checking data model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124a185842c4456aae45e21aeaa24d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The pipeline check generated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> issues labeled INFO and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> issues labeled WARNING.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The pipeline check generated \u001b[1;36m3\u001b[0m issues labeled INFO and \u001b[1;36m0\u001b[0m issues labeled WARNING.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To see the issues in full, run <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.check</span><span style=\"font-weight: bold\">()</span> on the pipeline.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "To see the issues in full, run \u001b[1;35m.check\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m on the pipeline.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33d37208b4e41ec970c400a988d3505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Trained pipeline.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Trained pipeline.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0:00:01.034566.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2746ffa55ef84a32a93888ef3938ea84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast_prop = getml.feature_learning.FastProp(\n",
    "    loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "    aggregation=best_val_acc_comb[\"agg_set\"],\n",
    "    num_features=best_val_acc_comb[\"num_feat\"],\n",
    ")\n",
    "\n",
    "pipe1.feature_learners = [fast_prop]\n",
    "\n",
    "pipe1.fit(container.train)\n",
    "\n",
    "probs_test = pipe1.predict(container.test)\n",
    "test_acc = prob_to_acc(probs_test, actual_labels_test, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.906\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on the test set: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook sought out to attain a new record predictive performance on the well known Cora data set by using exclusively getML's feature learning framework. To maximize comparability we mimicked the methodology of the current record holder.\n",
    "\n",
    "We replicated the exact data split used in their research and performed hyperparameter optimization in a similar manner. On the holdout dataset, we achieved an accuracy of 90.6%, which compares favorably to the previous record of 90.16%. Therefore, our solution, combining FastProp for automated feature engineering and XGBoost for classification, can now be considered the new state-of-the-art on this popular benchmark dataset.\n",
    "\n",
    "Remarkable is the ease of implementation. Requiring only minimal tweaking of parameters, getML beat an advanced Graph Neural Network algorithm. Cutting edge predictive performance is now within reach of every Data Scientist by simply incorporating getML in their prediction pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3,\n",
       "  {'num_feat': 300,\n",
       "   'agg_set': frozenset({'AVG', 'COUNT', 'MAX', 'MIN', 'SUM'}),\n",
       "   'val_acc': 0.874}),\n",
       " (6,\n",
       "  {'num_feat': 350,\n",
       "   'agg_set': frozenset({'AVG', 'COUNT', 'MAX', 'MIN', 'SUM'}),\n",
       "   'val_acc': 0.874}),\n",
       " (0,\n",
       "  {'num_feat': 250,\n",
       "   'agg_set': frozenset({'AVG', 'COUNT', 'MAX', 'MIN', 'SUM'}),\n",
       "   'val_acc': 0.872}),\n",
       " (4,\n",
       "  {'num_feat': 300,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'FIRST',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TREND'}),\n",
       "   'val_acc': 0.87}),\n",
       " (7,\n",
       "  {'num_feat': 350,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'FIRST',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TREND'}),\n",
       "   'val_acc': 0.866}),\n",
       " (1,\n",
       "  {'num_feat': 250,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'FIRST',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TREND'}),\n",
       "   'val_acc': 0.864}),\n",
       " (5,\n",
       "  {'num_feat': 300,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT DISTINCT OVER COUNT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'EWMA_1D',\n",
       "              'EWMA_1H',\n",
       "              'EWMA_1M',\n",
       "              'EWMA_1S',\n",
       "              'EWMA_30D',\n",
       "              'EWMA_365D',\n",
       "              'EWMA_7D',\n",
       "              'EWMA_90D',\n",
       "              'EWMA_TREND_1D',\n",
       "              'EWMA_TREND_1H',\n",
       "              'EWMA_TREND_1M',\n",
       "              'EWMA_TREND_1S',\n",
       "              'EWMA_TREND_30D',\n",
       "              'EWMA_TREND_365D',\n",
       "              'EWMA_TREND_7D',\n",
       "              'EWMA_TREND_90D',\n",
       "              'FIRST',\n",
       "              'KURTOSIS',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'NUM MAX',\n",
       "              'NUM MIN',\n",
       "              'Q1',\n",
       "              'Q10',\n",
       "              'Q25',\n",
       "              'Q5',\n",
       "              'Q75',\n",
       "              'Q90',\n",
       "              'Q95',\n",
       "              'Q99',\n",
       "              'SKEW',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TIME SINCE FIRST MAXIMUM',\n",
       "              'TIME SINCE FIRST MINIMUM',\n",
       "              'TIME SINCE LAST MAXIMUM',\n",
       "              'TIME SINCE LAST MINIMUM',\n",
       "              'TREND',\n",
       "              'VAR',\n",
       "              'VARIATION COEFFICIENT'}),\n",
       "   'val_acc': 0.862}),\n",
       " (8,\n",
       "  {'num_feat': 350,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT DISTINCT OVER COUNT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'EWMA_1D',\n",
       "              'EWMA_1H',\n",
       "              'EWMA_1M',\n",
       "              'EWMA_1S',\n",
       "              'EWMA_30D',\n",
       "              'EWMA_365D',\n",
       "              'EWMA_7D',\n",
       "              'EWMA_90D',\n",
       "              'EWMA_TREND_1D',\n",
       "              'EWMA_TREND_1H',\n",
       "              'EWMA_TREND_1M',\n",
       "              'EWMA_TREND_1S',\n",
       "              'EWMA_TREND_30D',\n",
       "              'EWMA_TREND_365D',\n",
       "              'EWMA_TREND_7D',\n",
       "              'EWMA_TREND_90D',\n",
       "              'FIRST',\n",
       "              'KURTOSIS',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'NUM MAX',\n",
       "              'NUM MIN',\n",
       "              'Q1',\n",
       "              'Q10',\n",
       "              'Q25',\n",
       "              'Q5',\n",
       "              'Q75',\n",
       "              'Q90',\n",
       "              'Q95',\n",
       "              'Q99',\n",
       "              'SKEW',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TIME SINCE FIRST MAXIMUM',\n",
       "              'TIME SINCE FIRST MINIMUM',\n",
       "              'TIME SINCE LAST MAXIMUM',\n",
       "              'TIME SINCE LAST MINIMUM',\n",
       "              'TREND',\n",
       "              'VAR',\n",
       "              'VARIATION COEFFICIENT'}),\n",
       "   'val_acc': 0.854}),\n",
       " (2,\n",
       "  {'num_feat': 250,\n",
       "   'agg_set': frozenset({'AVG',\n",
       "              'COUNT',\n",
       "              'COUNT DISTINCT',\n",
       "              'COUNT DISTINCT OVER COUNT',\n",
       "              'COUNT MINUS COUNT DISTINCT',\n",
       "              'EWMA_1D',\n",
       "              'EWMA_1H',\n",
       "              'EWMA_1M',\n",
       "              'EWMA_1S',\n",
       "              'EWMA_30D',\n",
       "              'EWMA_365D',\n",
       "              'EWMA_7D',\n",
       "              'EWMA_90D',\n",
       "              'EWMA_TREND_1D',\n",
       "              'EWMA_TREND_1H',\n",
       "              'EWMA_TREND_1M',\n",
       "              'EWMA_TREND_1S',\n",
       "              'EWMA_TREND_30D',\n",
       "              'EWMA_TREND_365D',\n",
       "              'EWMA_TREND_7D',\n",
       "              'EWMA_TREND_90D',\n",
       "              'FIRST',\n",
       "              'KURTOSIS',\n",
       "              'LAST',\n",
       "              'MAX',\n",
       "              'MEDIAN',\n",
       "              'MIN',\n",
       "              'MODE',\n",
       "              'NUM MAX',\n",
       "              'NUM MIN',\n",
       "              'Q1',\n",
       "              'Q10',\n",
       "              'Q25',\n",
       "              'Q5',\n",
       "              'Q75',\n",
       "              'Q90',\n",
       "              'Q95',\n",
       "              'Q99',\n",
       "              'SKEW',\n",
       "              'STDDEV',\n",
       "              'SUM',\n",
       "              'TIME SINCE FIRST MAXIMUM',\n",
       "              'TIME SINCE FIRST MINIMUM',\n",
       "              'TIME SINCE LAST MAXIMUM',\n",
       "              'TIME SINCE LAST MINIMUM',\n",
       "              'TREND',\n",
       "              'VAR',\n",
       "              'VARIATION COEFFICIENT'}),\n",
       "   'val_acc': 0.848})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    sorted(parameter_sweep.items(), key=lambda item: item[1][\"val_acc\"], reverse=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
