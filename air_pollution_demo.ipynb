{"metadata":{"celltoolbar":"Tags","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting air pollution\n\n### Why feature learning is better than brute-force feature engineering\n\nIn this notebook, we will train ML models to predict the PM2.5 concentration based on several external factors. PM2.5 are fine inhalable particles that pose an enormous health risk. We will compare getML to tsfresh, an open-source library that generates features for time series. tsfresh uses a brute-force approach to feature engineering, whereas getML uses feature learning. We find that getML generates significantly better predictions and consumes roughly 2% of the memory that tsfresh requires.\n\nSummary:\n\n- Prediction type: __Regression model__\n- Domain: __Environmental science__\n- Prediction target: __PM 2.5 concentration__ \n- Source data: __Multivariate time series__\n- Population size: __41757__\n\n_Author: Patrick Urbanke_","metadata":{"tags":["hide_input"]}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Background\n\nMany data scientists and AutoML tools use brute-force methods for feature engineering. These brute-force methods usually work as follows:\n\n- Generate a large number of hard-coded features\n- Use feature selection to pick a small percentage of these features\n\nBy contrast, [getML](https://getml.com/product) uses feature learning: Feature learning adapts machine learning approaches such as decision trees or gradient boosting to the problem of extracting features from relational data and time series.\n\nIn this notebook, we will benchmark getML against [tsfresh](https://tsfresh.readthedocs.io/en/latest/). tsfresh is a popular Python library that uses brute-force methods as described above to generate features for time series.\n\nAs our example dataset, we use a publicly available dataset on [air pollution in Beijing](https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data), China. The data set has been originally used in the following study:\n\nLiang, X., Zou, T., Guo, B., Li, S., Zhang, H., Zhang, S., Huang, H. and Chen, S. X. (2015). Assessing Beijing's PM2.5 pollution: severity, weather impact, APEC and winter heating. Proceedings of the Royal Society A, 471, 20150257.\n\nWe find that:\n\n- getML significantly outperforms tsfresh in terms of predictive accuracy (**R-squared of 60.9%** vs **R-squared of 48.7%**).\n- getML consumes **considerably less memory** than tsfresh (**0.08 GB** vs **3.63 GB**).\n\nOur findings indicate that feature learning algorithms are better at adapting to data sets and are also more scalable due to their lower memory requirement.","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### A web frontend for getML\n\nThe getML monitor is a frontend built to support your work with getML. The getML monitor displays information such as the imported data frames, trained pipelines and allows easy data and feature exploration. You can launch the getML monitor [here](/user/getml-getml-demo-z9ze1hcd/proxy/1709/).","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### Where is this running?\n\nYour getML live session is running inside a docker container on [mybinder.org](https://mybinder.org/), a service built by the Jupyter community and funded by Google Cloud, OVH, GESIS Notebooks and the Turing Institute. As it is a free service, this session will shut down after 10 minutes of inactivity.","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Analysis","metadata":{}},{"cell_type":"markdown","source":"Let's get started with the analysis and set-up your session:","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport psutil\nfrom urllib import request\nimport threading\nimport time\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import pearsonr\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n%matplotlib inline  \n\nimport getml\n\nprint(f\"getML API version: {getml.__version__}\\n\")\n\ngetml.engine.set_project('air_pollution')","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"getML API version: 0.12.0\n\nLoading existing project 'air_pollution'\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"## 1. Loading data","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Download from source\n\nWe begin by downloading the data from the UCI Machine Learning repository.","metadata":{}},{"cell_type":"code","source":"fname = \"PRSA_data_2010.1.1-2014.12.31.csv\"\n\nif not os.path.exists(fname):\n    fname, res = request.urlretrieve(\n        \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/\" + fname, \n        fname\n    )\n","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### 1.2 Prepare data for tsfresh and getML\n\nOur our goal is to predict the pm2.5 concentration from factors such as weather or time of day. However, there are some missing entries for pm2.5, so we get rid of them.","metadata":{}},{"cell_type":"code","source":"data_full_pandas = pd.read_csv(fname)\n\ndata_full_pandas = data_full_pandas[\n    data_full_pandas[\"pm2.5\"] == data_full_pandas[\"pm2.5\"]\n]","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"tsfresh requires a date column, so we build one.","metadata":{}},{"cell_type":"code","source":"def add_leading_zero(val):\n    if len(str(val)) == 1:\n        return \"0\" + str(val)\n    return str(val)\n\ndata_full_pandas[\"month\"] = [\n    add_leading_zero(val) for val in data_full_pandas[\"month\"]\n]\n\ndata_full_pandas[\"day\"] = [\n    add_leading_zero(val) for val in data_full_pandas[\"day\"]\n]\n\ndata_full_pandas[\"hour\"] = [\n    add_leading_zero(val) for val in data_full_pandas[\"hour\"]\n]\n\ndef make_date(year, month, day, hour):\n    return year + \"-\" + month + \"-\" + day + \" \" + hour + \":00:00\"\n\ndata_full_pandas[\"date\"] = [\n    make_date(str(year), month, day, hour) \\\n    for year, month, day, hour in zip(\n        data_full_pandas[\"year\"],\n        data_full_pandas[\"month\"],\n        data_full_pandas[\"day\"],\n        data_full_pandas[\"hour\"],\n    )\n]\n","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"tsfresh also requires the time series to have ids. Since there is only a single time series, that series has the same id.","metadata":{}},{"cell_type":"code","source":"data_full_pandas[\"id\"] = 1","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"The dataset now contains many columns that we do not need or that tsfresh cannot process. For instance, *cbwd* might actually contain useful information, but it is a categorical variable, which is difficult to handle for tsfresh, so we remove it.","metadata":{}},{"cell_type":"markdown","source":"We also want to split our data into a training and testing set.","metadata":{}},{"cell_type":"code","source":"data_train_pandas = data_full_pandas[data_full_pandas[\"year\"] < 2014]\ndata_test_pandas = data_full_pandas[data_full_pandas[\"year\"] == 2014]","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def remove_unwanted_columns(df):\n    del df[\"cbwd\"]\n    del df[\"year\"]\n    del df[\"month\"]\n    del df[\"day\"]\n    del df[\"hour\"]\n    del df[\"No\"]\n    return df\n\ndata_full_pandas = remove_unwanted_columns(data_full_pandas)\ndata_train_pandas = remove_unwanted_columns(data_train_pandas)\ndata_test_pandas = remove_unwanted_columns(data_test_pandas)","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_full_pandas","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"       pm2.5  DEWP  TEMP    PRES     Iws  Is  Ir                 date  id\n24     129.0   -16  -4.0  1020.0    1.79   0   0  2010-01-02 00:00:00   1\n25     148.0   -15  -4.0  1020.0    2.68   0   0  2010-01-02 01:00:00   1\n26     159.0   -11  -5.0  1021.0    3.57   0   0  2010-01-02 02:00:00   1\n27     181.0    -7  -5.0  1022.0    5.36   1   0  2010-01-02 03:00:00   1\n28     138.0    -7  -5.0  1022.0    6.25   2   0  2010-01-02 04:00:00   1\n...      ...   ...   ...     ...     ...  ..  ..                  ...  ..\n43819    8.0   -23  -2.0  1034.0  231.97   0   0  2014-12-31 19:00:00   1\n43820   10.0   -22  -3.0  1034.0  237.78   0   0  2014-12-31 20:00:00   1\n43821   10.0   -22  -3.0  1034.0  242.70   0   0  2014-12-31 21:00:00   1\n43822    8.0   -22  -4.0  1034.0  246.72   0   0  2014-12-31 22:00:00   1\n43823   12.0   -21  -3.0  1034.0  249.85   0   0  2014-12-31 23:00:00   1\n\n[41757 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pm2.5</th>\n      <th>DEWP</th>\n      <th>TEMP</th>\n      <th>PRES</th>\n      <th>Iws</th>\n      <th>Is</th>\n      <th>Ir</th>\n      <th>date</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>129.0</td>\n      <td>-16</td>\n      <td>-4.0</td>\n      <td>1020.0</td>\n      <td>1.79</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010-01-02 00:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>148.0</td>\n      <td>-15</td>\n      <td>-4.0</td>\n      <td>1020.0</td>\n      <td>2.68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010-01-02 01:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>159.0</td>\n      <td>-11</td>\n      <td>-5.0</td>\n      <td>1021.0</td>\n      <td>3.57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010-01-02 02:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>181.0</td>\n      <td>-7</td>\n      <td>-5.0</td>\n      <td>1022.0</td>\n      <td>5.36</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2010-01-02 03:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>138.0</td>\n      <td>-7</td>\n      <td>-5.0</td>\n      <td>1022.0</td>\n      <td>6.25</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2010-01-02 04:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43819</th>\n      <td>8.0</td>\n      <td>-23</td>\n      <td>-2.0</td>\n      <td>1034.0</td>\n      <td>231.97</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2014-12-31 19:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43820</th>\n      <td>10.0</td>\n      <td>-22</td>\n      <td>-3.0</td>\n      <td>1034.0</td>\n      <td>237.78</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2014-12-31 20:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43821</th>\n      <td>10.0</td>\n      <td>-22</td>\n      <td>-3.0</td>\n      <td>1034.0</td>\n      <td>242.70</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2014-12-31 21:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43822</th>\n      <td>8.0</td>\n      <td>-22</td>\n      <td>-4.0</td>\n      <td>1034.0</td>\n      <td>246.72</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2014-12-31 22:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43823</th>\n      <td>12.0</td>\n      <td>-21</td>\n      <td>-3.0</td>\n      <td>1034.0</td>\n      <td>249.85</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2014-12-31 23:00:00</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>41757 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We then load the data into the getML engine. We begin by setting a project.","metadata":{}},{"cell_type":"code","source":"getml.engine.set_project('air_pollution')","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Loading existing project 'air_pollution'\n","output_type":"stream"}]},{"cell_type":"code","source":"df_full = getml.data.DataFrame.from_pandas(data_full_pandas, name='full')\ndf_train = getml.data.DataFrame.from_pandas(data_train_pandas, name='train')\ndf_test = getml.data.DataFrame.from_pandas(data_test_pandas, name='test')\n\ndf_full[\"date\"] = df_full[\"date\"].as_ts()","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"We need to assign roles to the columns, such as defining the target column.","metadata":{}},{"cell_type":"code","source":"def set_roles(df):\n    df.set_role([\"date\"], getml.data.roles.time_stamp)\n    df.set_role([\"pm2.5\"], getml.data.roles.target)\n    df.set_role([\n        \"DEWP\", \n        \"TEMP\",\n        \"PRES\",\n        \"Iws\",\n        \"Is\",\n        \"Ir\"], getml.data.roles.numerical)\n\nset_roles(df_full)\nset_roles(df_train)\nset_roles(df_test)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"## 2. Tracking memory consumption\n\nA major issue about brute-force is their memory consumption. We would therefore like to be able to measure the memory consumption of different algorithms.\n\nWe will do so by tracking the overall system memory usage and then substracting the peak system memory usage from the initial memory usage. This gives a good approximation as long as we do not start any other memory-heavy processes while training.","metadata":{}},{"cell_type":"code","source":"class MemoryTracker():\n    \"\"\"\n    The MemoryTracker measures the system's memory consumption\n    once every second. It can be used to get an approximation of \n    the overall memory consumption of certain algorithms.\n    \"\"\"\n    \n    def __init__(self):\n        self._initial_usage = 0\n        self._max_usage = 0\n        \n        self._stop = False\n        \n        self.lock = threading.Lock()\n        \n        self.th = threading.Thread(\n            target=self._measure_memory_usage,\n        )\n        \n    def __del__(self):\n        self.stop()\n        \n    def _get_memory_usage(self):\n        return psutil.virtual_memory().used\n\n    def _measure_memory_usage(self):\n        while True:\n            time.sleep(1)\n            \n            self.lock.acquire()\n                                    \n            if self._stop:\n                self.lock.release()\n                break\n            \n            current_usage = self._get_memory_usage()\n            \n            if current_usage > self._max_usage:\n                self._max_usage = current_usage\n            \n            self.lock.release()\n\n    @property\n    def peak_consumption(self):\n        \"\"\"\n        The peak system memory consumption, in GB\n        \"\"\"\n        self.lock.acquire()\n        \n        p_con = self._max_usage - self._initial_usage\n        \n        self.lock.release()\n        \n        p_con /= 1e9\n        \n        return p_con\n    \n    def start(self):\n        \"\"\"\n        Starts measuring the memory consumption.\n        \"\"\"\n        self.lock.acquire()\n        \n        self._initial_usage = self._get_memory_usage()\n        \n        self._max_usage = self._initial_usage\n        \n        self._stop = False\n        \n        self.th = threading.Thread(\n            target=self._measure_memory_usage,\n        )\n        \n        self.th.start()\n        \n        self.lock.release()\n        \n    def stop(self):\n        \"\"\"\n        Stops measuring the memory consumption.\n        \"\"\"\n        self.lock.acquire()\n        self._stop = True\n        self.lock.release()","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"memory_tracker = MemoryTracker()","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"## 3. Predictive modelling\n\n\n### 3.1 Pipeline 1: Complex features, 7 days","metadata":{}},{"cell_type":"markdown","source":"For our first experiment, we will learn complex features and allow a memory of up to seven days. That means at every given point in time, the algorithm is allowed to look back seven days into the past.\n\ngetML uses relational learning to build construct the pipelines. Even though there is a simpler time series API, the relational API is more flexible which is why decide to use it.","metadata":{}},{"cell_type":"code","source":"population = getml.data.Placeholder('population')\n\nperipheral = getml.data.Placeholder('peripheral')\n\npopulation.join(\n    peripheral,\n    time_stamp='date',\n    memory=getml.data.time.days(7)\n)\n\npopulation","metadata":{"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"placeholder   other placeholder   allow lagged targets   horizon   \npopulation    peripheral          False                  0.0       \n\n\n\njoin keys used     memory   other join keys used   other time stamps used   \n                 604800.0                          date                     \n\n\n\njoin keys used   relationship   time stamps used   ...   \n                 many-to-many   date               ...   ","text/html":"<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>604800.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"},"metadata":{}}]},{"cell_type":"markdown","source":"We then set up the features. We will use two different feature learning algorithms, namely MultirelModel and RelboostModel. Because we want complex features, we set *max_length* and *max_depth* to 7.","metadata":{}},{"cell_type":"code","source":"aggregations = [\n    getml.feature_learning.aggregations.Avg,\n    getml.feature_learning.aggregations.Sum,\n    getml.feature_learning.aggregations.Min,\n    getml.feature_learning.aggregations.Max,\n    getml.feature_learning.aggregations.Median,\n    getml.feature_learning.aggregations.Stddev\n]\n\nmultirel = getml.feature_learning.MultirelModel(\n    aggregation=aggregations,\n    num_features=10,\n    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n    seed=4367,\n    max_length=7\n)\n\nrelboost = getml.feature_learning.RelboostModel(\n    num_features=10,\n    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n    seed=4367,\n    max_depth=7\n)\n\npredictor = getml.predictors.XGBoostRegressor()\n\npipe = getml.pipeline.Pipeline(\n    tags=['memory: 7d', 'complex features'],\n    population=population,\n    peripheral=[peripheral],\n    feature_learners=[multirel, relboost],\n    predictors=[predictor]\n)\n\npipe","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], \n         feature_selectors=[], include_categorical=False, \n         peripheral=['peripheral'], population='population', \n         predictors=['XGBoostRegressor'], \n         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)","text/html":"<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'complex features'], share_selected_features=0.5)</pre>"},"metadata":{}}]},{"cell_type":"markdown","source":"It is good practice to always check your data model first, even though `check(...)` is also called by `fit(...)`. That enables us to make last-minute changes.","metadata":{}},{"cell_type":"code","source":"pipe.check(df_train, [df_full])","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We now fit our data on the training set and evaluate our findings, both in-sample and out of sample.","metadata":{}},{"cell_type":"code","source":"memory_tracker.start()\npipe.fit(df_train, [df_full])\nmemory_tracker.stop()\n\nprint(\"Memory consumption: \")\nprint(memory_tracker.peak_consumption)","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n\nMultirelModel: Training features...\n[========================================] 100%\n\nRelboostModel: Training features...\n[========================================] 100%\n\nMultirelModel: Building features...\n[========================================] 100%\n\nRelboostModel: Building features...\n[========================================] 100%\n\nXGBoost: Training as predictor...\n[========================================] 100%\n\nTrained pipeline.\nTime taken: 0h:11m:1.75538\n\nMemory consumption: \n1.021763584\n","output_type":"stream"}]},{"cell_type":"code","source":"in_sample = pipe.score(df_train, [df_full])\nprint('In sample:', in_sample)\n\nout_of_sample = pipe.score(df_test, [df_full])\nprint('Out of sample:', out_of_sample)","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nMultirelModel: Building features...\n[========================================] 100%\n\nRelboostModel: Building features...\n[========================================] 100%\n\nIn sample: {'mae': [30.921433475676267], 'rmse': [43.9544175981943], 'rsquared': [0.7706751157318166]}\n\nMultirelModel: Building features...\n[========================================] 100%\n\nRelboostModel: Building features...\n[========================================] 100%\n\nOut of sample: {'mae': [40.097575759601405], 'rmse': [58.56721852677215], 'rsquared': [0.6085457300725953]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### 3.2 Pipeline 2: Complex features, 1 day","metadata":{}},{"cell_type":"code","source":"population = getml.data.Placeholder('population')\n\nperipheral = getml.data.Placeholder('peripheral')\n\npopulation.join(\n    peripheral,\n    time_stamp='date',\n    memory=getml.data.time.days(1)\n)\n\npopulation","metadata":{"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"placeholder   other placeholder   allow lagged targets   horizon   \npopulation    peripheral          False                  0.0       \n\n\n\njoin keys used    memory   other join keys used   other time stamps used   \n                 86400.0                          date                     \n\n\n\njoin keys used   relationship   time stamps used   ...   \n                 many-to-many   date               ...   ","text/html":"<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>86400.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"},"metadata":{}}]},{"cell_type":"code","source":"aggregations = [\n    getml.feature_learning.aggregations.Avg,\n    getml.feature_learning.aggregations.Sum,\n    getml.feature_learning.aggregations.Min,\n    getml.feature_learning.aggregations.Max,\n    getml.feature_learning.aggregations.Median,\n    getml.feature_learning.aggregations.Stddev\n]\n\nmultirel = getml.feature_learning.MultirelModel(\n    aggregation=aggregations,\n    num_features=10,\n    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n    seed=4367,\n    max_length=0\n)\n\nrelboost = getml.feature_learning.RelboostModel(\n    num_features=10,\n    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n    seed=4367,\n    max_depth=5\n)\n\npredictor = getml.predictors.XGBoostRegressor()\n\npipe = getml.pipeline.Pipeline(\n    tags=['memory: 1d', 'complex features'],\n    population=population,\n    peripheral=[peripheral],\n    feature_learners=[multirel, relboost],\n    predictors=[predictor]\n)\n\npipe","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], \n         feature_selectors=[], include_categorical=False, \n         peripheral=['peripheral'], population='population', \n         predictors=['XGBoostRegressor'], \n         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)","text/html":"<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel', 'RelboostModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'complex features'], share_selected_features=0.5)</pre>"},"metadata":{}}]},{"cell_type":"code","source":"pipe.check(df_train, [df_full])","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n","output_type":"stream"}]},{"cell_type":"code","source":"memory_tracker.start()\npipe.fit(df_train, [df_full])\nmemory_tracker.stop()\n\nprint(\"Memory consumption: \")\nprint(memory_tracker.peak_consumption)","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n\nMultirelModel: Training features...\n[========================================] 100%\n\nRelboostModel: Training features...\n[========================================] 100%\n\nMultirelModel: Building features...\n[========================================] 100%\n\nRelboostModel: Building features...\n[========================================] 100%\n\nXGBoost: Training as predictor...\n[========================================] 100%\n\nTrained pipeline.\nTime taken: 0h:2m:35.041272\n\nMemory consumption: \n0.01992704\n","output_type":"stream"}]},{"cell_type":"code","source":"in_sample = pipe.score(df_train, [df_full])\nprint('In sample:', in_sample)\n\nout_of_sample = pipe.score(df_test, [df_full])\nprint('Out of sample:', out_of_sample)","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\nMultirelModel: Building features...\n[========================================] 100%\n\nRelboostModel: Building features...\n[========================================] 100%\n\nIn sample: {'mae': [38.17490033531624], 'rmse': [54.7799460058], 'rsquared': [0.6442914910608807]}\n\nMultirelModel: Building features...\n[========================================] 100%\n\nRelboostModel: Building features...\n[========================================] 100%\n\nOut of sample: {'mae': [44.95119658580155], 'rmse': [66.09828658228155], 'rsquared': [0.5018899991896832]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### 3.3 Pipeline 3: Simple features, 7 days\n\nFor our third experiment, we will learn simple features and allow a memory of up to seven days.\n\nThis simplicity is accomplished by learning 20 features using MultirelModel with a *max_length* of 0. That means that MultirelModel is not allowed to learn any conditions. The resulting features can expected to be very similar to features produced by tsfresh.","metadata":{}},{"cell_type":"code","source":"population = getml.data.Placeholder('population')\n\nperipheral = getml.data.Placeholder('peripheral')\n\npopulation.join(\n    peripheral,\n    time_stamp='date',\n    memory=getml.data.time.days(7)\n)\n\npopulation","metadata":{"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"placeholder   other placeholder   allow lagged targets   horizon   \npopulation    peripheral          False                  0.0       \n\n\n\njoin keys used     memory   other join keys used   other time stamps used   \n                 604800.0                          date                     \n\n\n\njoin keys used   relationship   time stamps used   ...   \n                 many-to-many   date               ...   ","text/html":"<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>604800.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"},"metadata":{}}]},{"cell_type":"code","source":"aggregations = [\n    getml.feature_learning.aggregations.Avg,\n    getml.feature_learning.aggregations.Sum,\n    getml.feature_learning.aggregations.Min,\n    getml.feature_learning.aggregations.Max,\n    getml.feature_learning.aggregations.Median,\n    getml.feature_learning.aggregations.Stddev\n]\n\nmultirel = getml.feature_learning.MultirelModel(\n    aggregation=aggregations,\n    num_features=20,\n    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n    seed=4367,\n    max_length=0\n)\n\npredictor = getml.predictors.XGBoostRegressor()\n\npipe = getml.pipeline.Pipeline(\n    tags=['memory: 7d', 'simple features'],\n    population=population,\n    peripheral=[peripheral],\n    feature_learners=[multirel],\n    predictors=[predictor]\n)\n\npipe","metadata":{"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Pipeline(preprocessors=[], feature_learners=['MultirelModel'], \n         feature_selectors=[], include_categorical=False, \n         peripheral=['peripheral'], population='population', \n         predictors=['XGBoostRegressor'], \n         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)","text/html":"<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 7d', 'simple features'], share_selected_features=0.5)</pre>"},"metadata":{}}]},{"cell_type":"code","source":"pipe.check(df_train, [df_full])","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n","output_type":"stream"}]},{"cell_type":"code","source":"memory_tracker.start()\npipe.fit(df_train, [df_full])\nmemory_tracker.stop()\n\nprint(\"Memory consumption: \")\nprint(memory_tracker.peak_consumption)","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n\nMultirelModel: Training features...\n[========================================] 100%\n\nMultirelModel: Building features...\n[========================================] 100%\n\nXGBoost: Training as predictor...\n[========================================] 100%\n\nTrained pipeline.\nTime taken: 0h:1m:44.331903\n\nMemory consumption: \n0.25921536\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### 3.4 Pipeline 4: Simple features, 1 day\n\nFor our fourth experiment, we will learn simple features and allow a memory of up to one day.\n\nAs we will see, tsfresh consumes a lot of memory. Looking further into the past increases the memory requirement to the point that looking back to up to 7 days is not feasible on a normal desktop computer. For reasons we will discuss later, we want to replicate the tsfresh features using getML's greedy approach.","metadata":{}},{"cell_type":"code","source":"in_sample = pipe.score(df_train, [df_full])\nprint('In sample:', in_sample)\n\nout_of_sample = pipe.score(df_test, [df_full])\nprint('Out of sample:', out_of_sample)","metadata":{"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\nMultirelModel: Building features...\n[========================================] 100%\n\nIn sample: {'mae': [44.39174692957318], 'rmse': [62.05820701761394], 'rsquared': [0.5578533318605543]}\n\nMultirelModel: Building features...\n[========================================] 100%\n\nOut of sample: {'mae': [51.86212120127656], 'rmse': [71.42298768943652], 'rsquared': [0.4305880166321852]}\n","output_type":"stream"}]},{"cell_type":"code","source":"population = getml.data.Placeholder('population')\n\nperipheral = getml.data.Placeholder('peripheral')\n\npopulation.join(\n    peripheral,\n    time_stamp='date',\n    memory=getml.data.time.days(1)\n)\n\npopulation","metadata":{"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"placeholder   other placeholder   allow lagged targets   horizon   \npopulation    peripheral          False                  0.0       \n\n\n\njoin keys used    memory   other join keys used   other time stamps used   \n                 86400.0                          date                     \n\n\n\njoin keys used   relationship   time stamps used   ...   \n                 many-to-many   date               ...   ","text/html":"<table class=\"dataframe\"><thead><tr style=\"border-bottom:1pt solid LightGray;\"><th style=\"text-align: right;\">placeholder</th><th style=\"text-align: right;\">other placeholder</th><th style=\"text-align: right;\">allow lagged targets</th><th style=\"text-align: right;\">horizon</th><th style=\"text-align: right;\">join keys used</th><th style=\"text-align: right;\">memory</th><th style=\"text-align: right;\">other join keys used</th><th style=\"text-align: right;\">other time stamps used</th><th style=\"text-align: right;\">relationship</th><th style=\"text-align: right;\">time stamps used</th><th style=\"text-align: right;\">upper time stamps used</th></tr></thead><tbody><tr style=\"border-top:1pt solid LightGray;\"><td>population</td><td>peripheral</td><td>False</td><td>0.0</td><td></td><td>86400.0</td><td></td><td>date</td><td>many-to-many</td><td>date</td><td></td></tr></tbody></table>"},"metadata":{}}]},{"cell_type":"code","source":"aggregations = [\n    getml.feature_learning.aggregations.Avg,\n    getml.feature_learning.aggregations.Sum,\n    getml.feature_learning.aggregations.Min,\n    getml.feature_learning.aggregations.Max,\n    getml.feature_learning.aggregations.Median,\n    getml.feature_learning.aggregations.Stddev\n]\n\nmultirel = getml.feature_learning.MultirelModel(\n    aggregation=aggregations,\n    num_features=20,\n    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n    seed=4367,\n    max_length=0\n)\n\npredictor = getml.predictors.XGBoostRegressor()\n\npipe = getml.pipeline.Pipeline(\n    tags=['memory: 1d', 'simple features'],\n    population=population,\n    peripheral=[peripheral],\n    feature_learners=[multirel],\n    predictors=[predictor]\n)\n\npipe","metadata":{"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"Pipeline(preprocessors=[], feature_learners=['MultirelModel'], \n         feature_selectors=[], include_categorical=False, \n         peripheral=['peripheral'], population='population', \n         predictors=['XGBoostRegressor'], \n         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)","text/html":"<pre>Pipeline(preprocessors=[], feature_learners=['MultirelModel'], <br>         feature_selectors=[], include_categorical=False, <br>         peripheral=['peripheral'], population='population', <br>         predictors=['XGBoostRegressor'], <br>         tags=['memory: 1d', 'simple features'], share_selected_features=0.5)</pre>"},"metadata":{}}]},{"cell_type":"code","source":"pipe.check(df_train, [df_full])","metadata":{"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n","output_type":"stream"}]},{"cell_type":"code","source":"memory_tracker.start()\npipe.fit(df_train, [df_full])\nmemory_tracker.stop()\n\nprint(\"Memory consumption: \")\nprint(memory_tracker.peak_consumption)","metadata":{"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Checking data model...\nOK.\n\nMultirelModel: Training features...\n[========================================] 100%\n\nMultirelModel: Building features...\n[========================================] 100%\n\nXGBoost: Training as predictor...\n[========================================] 100%\n\nTrained pipeline.\nTime taken: 0h:1m:8.451705\n\nMemory consumption: \n0.17676288\n","output_type":"stream"}]},{"cell_type":"code","source":"in_sample = pipe.score(df_train, [df_full])\nprint('In sample:', in_sample)\n\nout_of_sample = pipe.score(df_test, [df_full])\nprint('Out of sample:', out_of_sample)","metadata":{"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\nMultirelModel: Building features...\n[========================================] 100%\n\nIn sample: {'mae': [44.076551880232735], 'rmse': [62.61924427999326], 'rsquared': [0.5377020375473408]}\n\nMultirelModel: Building features...\n[========================================] 100%\n\nOut of sample: {'mae': [48.43578703042721], 'rmse': [68.2086724841597], 'rsquared': [0.4713164136964429]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"### 3.5 Using tsfresh\n\ntsfresh is a rather low-level library. To make things a bit easier, we write a high-level wrapper.\n\nTo limit the memory consumption, we undertake the following steps:\n\n- We limit ourselves to a memory of 1 day from any point in time. This is necessary, because tsfresh duplicates records for every time stamp. That means that looking back 7 days instead of one day, the memory consumption would be  seven times as high.\n- We extract only tsfresh's MinimalFCParameters and IndexBasedFCParameters (the latter is a superset of TimeBasedFCParameters).\n\nIn order to make sure that tsfresh's features can be compared to getML's features, we also do the following:\n\n- We apply tsfresh's built-in feature selection algorithm.\n- Of the remaining features, we only keep the 20 features most correlated with the target (in terms of the absolute value of the correlation).\n- We add the original columns as additional features.\n\nWe do this, because we used getML to train 20 features, but have also kept the original columns.\n","metadata":{}},{"cell_type":"code","source":"# import tsfresh\n# from tsfresh.utilities.dataframe_functions import roll_time_series\n# from tsfresh.feature_selection.relevance import calculate_relevance_table\n","metadata":{"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class TSFreshBuilder():\n    \n    def __init__(self, num_features, memory, column_id, time_stamp, target):\n        \"\"\"\n        Scikit-learn style feature builder based on TSFresh.\n        \n        Args:\n            \n            num_features: The (maximum) number of features to build.\n            \n            memory: How much back in time you want to go until the\n                    feature builder starts \"forgetting\" data.\n                    \n            column_id: The name of the column containing the ids.\n            \n            time_stamp: The name of the column containing the time stamps.\n            \n            target: The name of the target column.\n        \"\"\"\n        self.num_features = num_features\n        self.memory = memory\n        self.column_id = column_id\n        self.time_stamp = time_stamp\n        self.target = target\n        \n        self.selected_features = []\n        \n    def _add_original_columns(self, original_df, df_selected):\n        for colname in original_df.columns:\n            df_selected[colname] = np.asarray(\n                original_df[colname])\n                    \n        return df_selected\n\n    def _extract_features(self, df):\n        df_rolled = roll_time_series(\n            df, \n            column_id=self.column_id, \n            column_sort=self.time_stamp,\n            max_timeshift=self.memory\n        )\n\n        extracted_minimal = tsfresh.extract_features(\n            df_rolled,\n            column_id=self.column_id, \n            column_sort=self.time_stamp,\n            default_fc_parameters=tsfresh.feature_extraction.MinimalFCParameters()\n        )\n        \n        extracted_index_based = tsfresh.extract_features(\n            df_rolled,\n            column_id=self.column_id, \n            column_sort=self.time_stamp,\n            default_fc_parameters=tsfresh.feature_extraction.settings.IndexBasedFCParameters()\n        )\n        \n        extracted_features = pd.concat(\n            [extracted_minimal, extracted_index_based], axis=1\n        )\n        del extracted_minimal\n        del extracted_index_based\n        \n        gc.collect()\n        \n        extracted_features[\n            extracted_features != extracted_features] = 0.0  \n        \n        extracted_features[\n            np.isinf(extracted_features)] = 0.0 \n        \n        return extracted_features\n        \n    def _print_time_taken(self, begin, end):\n\n        seconds = end - begin\n\n        hours = int(seconds / 3600)\n        seconds -= float(hours * 3600)\n\n        minutes = int(seconds / 60)\n        seconds -= float(minutes * 60)\n\n        seconds = round(seconds, 6)\n\n        print(\n            \"Time taken: \" + str(hours) + \"h:\" +\n            str(minutes) + \"m:\" + str(seconds)\n        )\n\n        print(\"\")\n        \n    def _remove_target_column(self, df):\n        colnames = np.asarray(df.columns)\n        \n        if self.target not in colnames:\n            return df\n        \n        colnames = colnames[colnames != self.target]\n        \n        return df[colnames]\n        \n    def _select_features(self, df, target):\n        df_selected = tsfresh.select_features(\n            df, \n            target\n        )\n        \n        colnames = np.asarray(df_selected.columns)\n\n        correlations = np.asarray([\n            np.abs(pearsonr(target, df_selected[col]))[0] for col in colnames\n        ])\n        \n        # [::-1] is somewhat unintuitive syntax,\n        # but it reverses the entire column.\n        self.selected_features = colnames[\n            np.argsort(correlations)\n        ][::-1][:self.num_features]\n\n        return df_selected[self.selected_features]\n        \n    def fit(self, df):\n        \"\"\"\n        Fits the features.\n        \"\"\"\n        begin = time.time()\n\n        target = np.asarray(df[self.target])\n        \n        df_without_target = self._remove_target_column(df)\n        \n        df_extracted = self._extract_features(\n            df_without_target)\n        \n        df_selected = self._select_features(\n            df_extracted, target)\n                \n        del df_extracted\n        gc.collect()\n        \n        df_selected = self._add_original_columns(df, df_selected)\n\n        end = time.time()\n        \n        self._print_time_taken(begin, end)\n        \n        return df_selected\n    \n    def transform(self, df):\n        \"\"\"\n        Transforms the raw data into a set of features.\n        \"\"\"\n        df_extracted = self._extract_features(df)\n        \n        df_selected = df_extracted[self.selected_features]\n        \n        del df_extracted\n        gc.collect()\n        \n        df_selected = self._add_original_columns(df, df_selected)\n                                         \n        return df_selected","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"data_train_pandas","metadata":{"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"       pm2.5  DEWP  TEMP    PRES     Iws  Is  Ir                 date  id\n24     129.0   -16  -4.0  1020.0    1.79   0   0  2010-01-02 00:00:00   1\n25     148.0   -15  -4.0  1020.0    2.68   0   0  2010-01-02 01:00:00   1\n26     159.0   -11  -5.0  1021.0    3.57   0   0  2010-01-02 02:00:00   1\n27     181.0    -7  -5.0  1022.0    5.36   1   0  2010-01-02 03:00:00   1\n28     138.0    -7  -5.0  1022.0    6.25   2   0  2010-01-02 04:00:00   1\n...      ...   ...   ...     ...     ...  ..  ..                  ...  ..\n35059   22.0   -19   7.0  1013.0  114.87   0   0  2013-12-31 19:00:00   1\n35060   18.0   -21   7.0  1014.0  119.79   0   0  2013-12-31 20:00:00   1\n35061   23.0   -21   7.0  1014.0  125.60   0   0  2013-12-31 21:00:00   1\n35062   20.0   -21   6.0  1014.0  130.52   0   0  2013-12-31 22:00:00   1\n35063   23.0   -20   7.0  1014.0  137.67   0   0  2013-12-31 23:00:00   1\n\n[33096 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pm2.5</th>\n      <th>DEWP</th>\n      <th>TEMP</th>\n      <th>PRES</th>\n      <th>Iws</th>\n      <th>Is</th>\n      <th>Ir</th>\n      <th>date</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>129.0</td>\n      <td>-16</td>\n      <td>-4.0</td>\n      <td>1020.0</td>\n      <td>1.79</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010-01-02 00:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>148.0</td>\n      <td>-15</td>\n      <td>-4.0</td>\n      <td>1020.0</td>\n      <td>2.68</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010-01-02 01:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>159.0</td>\n      <td>-11</td>\n      <td>-5.0</td>\n      <td>1021.0</td>\n      <td>3.57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2010-01-02 02:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>181.0</td>\n      <td>-7</td>\n      <td>-5.0</td>\n      <td>1022.0</td>\n      <td>5.36</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2010-01-02 03:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>138.0</td>\n      <td>-7</td>\n      <td>-5.0</td>\n      <td>1022.0</td>\n      <td>6.25</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2010-01-02 04:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35059</th>\n      <td>22.0</td>\n      <td>-19</td>\n      <td>7.0</td>\n      <td>1013.0</td>\n      <td>114.87</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2013-12-31 19:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35060</th>\n      <td>18.0</td>\n      <td>-21</td>\n      <td>7.0</td>\n      <td>1014.0</td>\n      <td>119.79</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2013-12-31 20:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35061</th>\n      <td>23.0</td>\n      <td>-21</td>\n      <td>7.0</td>\n      <td>1014.0</td>\n      <td>125.60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2013-12-31 21:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35062</th>\n      <td>20.0</td>\n      <td>-21</td>\n      <td>6.0</td>\n      <td>1014.0</td>\n      <td>130.52</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2013-12-31 22:00:00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35063</th>\n      <td>23.0</td>\n      <td>-20</td>\n      <td>7.0</td>\n      <td>1014.0</td>\n      <td>137.67</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2013-12-31 23:00:00</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>33096 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"builder = TSFreshBuilder(\n    num_features=20,\n    memory=24,\n    column_id=\"id\",\n    time_stamp=\"date\",\n    target=\"pm2.5\")","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"One of the issues about tsfresh is that is actually requires more memory than allowed by mybinder. We therefore have to uncomment the parts that relate to this.","metadata":{}},{"cell_type":"code","source":"# memory_tracker.start()\n# tsfresh_training = builder.fit(data_train_pandas)\n# memory_tracker.stop()\n\nprint(\"Memory consumption: \")\nprint(memory_tracker.peak_consumption)","metadata":{"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Memory consumption: \n0.17676288\n","output_type":"stream"}]},{"cell_type":"code","source":"# tsfresh_test = builder.transform(data_test_pandas)","metadata":{"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"tsfresh does not contain built-in machine learning algorithms. In order to ensure a fair comparison, we use the exact same machine learning algorithm we have also used for getML: An XGBoost regressor with all hyperparameters set to their default value.\n\nIn order to do so, we load the tsfresh features into the getML engine.","metadata":{}},{"cell_type":"code","source":"# df_tsfresh_training = getml.data.DataFrame.from_pandas(tsfresh_training, name='tsfresh_training')\n# df_tsfresh_test = getml.data.DataFrame.from_pandas(tsfresh_test, name='tsfresh_test')","metadata":{"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"As usual, we need to set roles:","metadata":{}},{"cell_type":"code","source":"def set_roles_tsfresh(df):\n    df[\"date\"] = df[\"date\"].as_ts()\n    df.set_role([\"pm2.5\"], getml.data.roles.target)\n    df.set_role([\"date\"], getml.data.roles.time_stamp)\n    df.set_role(df.unused_names, getml.data.roles.numerical)\n    df.set_role([\"id\"], getml.data.roles.unused_float)\n    return df\n\n# df_tsfresh_training = set_roles_tsfresh(df_tsfresh_training)\n# df_tsfresh_test = set_roles_tsfresh(df_tsfresh_test)","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"In this case, our pipeline is very simple. It only consists of a single XGBoostRegressor.","metadata":{}},{"cell_type":"code","source":"predictor = getml.predictors.XGBoostRegressor()\n\npipe = getml.pipeline.Pipeline(\n    tags=['tsfresh', 'memory: 1d'],\n    predictors=[predictor]\n)\n\npipe","metadata":{"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], \n         include_categorical=False, peripheral=[], population='POPULATION', \n         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], \n         share_selected_features=0.5)","text/html":"<pre>Pipeline(preprocessors=[], feature_learners=[], feature_selectors=[], <br>         include_categorical=False, peripheral=[], population='POPULATION', <br>         predictors=['XGBoostRegressor'], tags=['tsfresh', 'memory: 1d'], <br>         share_selected_features=0.5)</pre>"},"metadata":{}}]},{"cell_type":"code","source":"# pipe.check(df_tsfresh_training)","metadata":{"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# pipe.fit(df_tsfresh_training)","metadata":{"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# in_sample = pipe.score(df_tsfresh_training)\n# print('In sample:', in_sample)\n\n# out_of_sample = pipe.score(df_tsfresh_test)\n# print('Out of sample:', out_of_sample)","metadata":{"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"## 4. Discussion\n\nWe have seen that getML outperforms tsfresh by more than 10 percentage points in terms of R-squared. We now want to analyze why that is.\n\nThere are two possible hypotheses:\n\n- getML outperforms tsfresh, because it using feature learning and is able to produce more complex features.\n- getML outperforms tsfresh, because it makes better use of memory and is able to look back further.\n\nLet's summarize our findings:\n\n\nName       | Look-back | Feature complexity | R-squared | RMSE | Memory usage\n---------- | --------- | ------------------ | --------- | ---- | ------------ \nPipeline 1 |    7 days |            complex |     60.9% | 58.6 | 0.08 GB\nPipeline 2 |     1 day |            complex |     50.2% | 66.1 | 0.02 GB\nPipeline 3 |    7 days |             simple |     43.0% | 71.4 | 0.07 GB\nPipeline 4 |     1 day |             simple |     47.1% | 68.2 | 0.07 GB\ntsfresh    |     1 day |             simple |     48.7% | 67.4 | 3.63 GB\n\n\nWe have built simple features and complex features and we also differentiate between looking back 1 day and looking back 7 days. When we look back one day and allow only simple features, getML produces features that are very similar to tsfresh. It is therefore unsurprising that their performance is about on par with the performance of tsfresh. It is actually a bit worse, because getML uses a greedy algorithm and there is a price we pay for that. But since the greedy algorithms also allows us to build more complex feature the benefits of the greedy algorithm outweigh its costs.\n\nLet's also compare the memory consumption: Even Pipeline 1, which has the highest memory consumption of all of getML's pipelines, only consumes about 2.2% percent of the memory that tsfresh needs. This is in part due to the way tsfresh is implemented, but it is also an inherent problem: If your approach is to generate many features to then select a small share, you will need a lot of memory. In theory, it is possible to write a more memory-efficient implementation of tsfresh and then use a look-back of 7 days, but when we compare Pipeline 3 and Pipeline 4, we can conclude that it is unlikely that this would improve tsfresh's predictive performance.\n\nThe summary table shows that a combination of both of our hypotheses explains why getML outperforms tsfresh. Complex features do better than simple features when looking back one day. When looking back seven days, simple features actually get worse. But when you look back seven days and allow more complex features, you really get good results.\n\nThis suggests that getML outperforms tsfresh, because it can make more efficient use of memory and thus look back further. Because getML uses feature learning and can build more complex features it can make better use of the greater look-back window.","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"## 5. Conclusion\n\nWe have compared getML's feature learning algorithms to tsfresh's brute-force feature engineering approaches on a data set related to air pollution in China. We found that getML significantly outperforms tsfresh. These results are consistent with the view that feature learning is better than brute-force feature engineering.\n\nYou are encouraged to reproduce these results. You will need getML (https://getml.com/product) and tsfresh (https://tsfresh.readthedocs.io/en/latest/). You can download both for free.","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Next Steps\n\nIf you want to learn more about getML, here are some additional tutorials and articles that will help you:\n\n__Tutorials:__\n* [Loan default prediction: Introduction to relational learning](loans_demo.ipynb)\n* [Occupancy detection: A multivariate time series example](occupancy_demo.ipynb)  \n* [Expenditure categorization: Why relational learning matters](consumer_expenditures_demo.ipynb)\n* [Disease lethality prediction: Feature engineering and the curse of dimensionality](atherosclerosis_demo.ipynb)\n* [Traffic volume prediction: Feature engineering on multivariate time series](interstate94_demo.ipynb)\n* [Air pollution prediction: Why feature learning outperforms brute-force approaches](air_pollution_demo.ipynb) \n\n\n__User Guides__ (from our [documentation](https://docs.getml.com/latest/)):\n* [Feature learning with Multirel](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#multirel)\n* [Feature learning with Relboost](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#relboost)\n\n","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}},{"cell_type":"markdown","source":"# Get into contact\n\nIf you have any question schedule a [call with Alex](https://go.getml.com/meetings/alexander-uhlig/getml-demo), the co-founder of getML, or write us an [email](team@getml.com). Prefer a private demo of getML? Just contact us to make an appointment.","metadata":{}},{"cell_type":"markdown","source":" ","metadata":{}}]}